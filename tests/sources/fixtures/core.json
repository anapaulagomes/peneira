{
  "totalHits": 31,
  "limit": 10,
  "offset": 0,
  "results": [
    {
      "arxivId": null,
      "authors": [
        {
          "name": "Aghdassi, Seven Johannes Sam"
        },
        {
          "name": "Behnke, Michael"
        },
        {
          "name": "Gastmeier, Petra"
        },
        {
          "name": "Leistner, Rasmus"
        },
        {
          "name": "Pe\u00f1a Diaz, Luis Alberto"
        },
        {
          "name": "Piening, Brar"
        },
        {
          "name": "Pilarski, Georg"
        },
        {
          "name": "Rohde, Anna Maria"
        },
        {
          "name": "Schr\u00f6der, Christin"
        },
        {
          "name": "Thoma, Norbert"
        }
      ],
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/322846685"
      ],
      "createdDate": "2020-05-15T08:09:11",
      "dataProviders": [
        {
          "id": 1617,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/1617",
          "logo": "https://api.core.ac.uk/data-providers/1617/logo"
        }
      ],
      "abstract": "INTRODUCTION:\r\nOutbreaks of communicable diseases in hospitals need to be quickly detected in order to enable immediate control. The increasing digitalization of hospital data processing offers potential solutions for automated outbreak detection systems (AODS). Our goal was to assess a newly developed AODS.\r\n\r\nMETHODS:\r\nOur AODS was based on the diagnostic results of routine clinical microbiological examinations. The system prospectively counted detections per bacterial pathogen over time for the years 2016 and 2017. The baseline data covers data from 2013-2015. The comparative analysis was based on six different mathematical algorithms (normal/Poisson and score prediction intervals, the early aberration reporting system, negative binomial CUSUMs, and the Farrington algorithm). The clusters automatically detected were then compared with the results of our manual outbreak detection system.\r\n\r\nRESULTS:\r\nDuring the analysis period, 14 different hospital outbreaks were detected as a result of conventional manual outbreak detection. Based on the pathogens' overall incidence, outbreaks were divided into two categories: outbreaks with rarely detected pathogens (sporadic) and outbreaks with often detected pathogens (endemic). For outbreaks with sporadic pathogens, the detection rate of our AODS ranged from 83% to 100%. Every algorithm detected 6 of 7 outbreaks with a sporadic pathogen. The AODS identified outbreaks with an endemic pathogen were at a detection rate of 33% to 100%. For endemic pathogens, the results varied based on the epidemiological characteristics of each outbreak and pathogen.\r\n\r\nCONCLUSION:\r\nAODS for hospitals based on routine microbiological data is feasible and can provide relevant benefits for infection control teams. It offers in-time automated notification of suspected pathogen clusters especially for sporadically occurring pathogens. However, outbreaks of endemically detected pathogens need further individual pathogen-specific and setting-specific adjustments",
      "documentType": "research",
      "doi": "10.17169/refubium-26890",
      "downloadUrl": "https://core.ac.uk/download/322846685.pdf",
      "fieldOfStudy": null,
      "fullText": "RESEARCH ARTICLELean back and wait for the alarm? Testing anautomated alarm system for nosocomialoutbreaks to provide support for infectioncontrol professionalsChristin Schro\u00a8derID*, Luis Alberto Pe\u00f1a Diaz, Anna Maria RohdeID, Brar Piening, SevenJohannes Sam Aghdassi, Georg Pilarski, Norbert Thoma, Petra Gastmeier,Rasmus Leistner\u262f, Michael Behnke\u262fCharite\u00b4 \u2013 Universita\u00a8tsmedizin Berlin, Institute of Hygiene and Environmental Medicine, Berlin, Germany\u262f These authors contributed equally to this work.* christin.schroeder@charite.deAbstractIntroductionOutbreaks of communicable diseases in hospitals need to be quickly detected in order toenable immediate control. The increasing digitalization of hospital data processing offerspotential solutions for automated outbreak detection systems (AODS). Our goal was toassess a newly developed AODS.MethodsOur AODS was based on the diagnostic results of routine clinical microbiological examina-tions. The system prospectively counted detections per bacterial pathogen over time for theyears 2016 and 2017. The baseline data covers data from 2013\u20132015. The comparativeanalysis was based on six different mathematical algorithms (normal/Poisson and scoreprediction intervals, the early aberration reporting system, negative binomial CUSUMs, andthe Farrington algorithm). The clusters automatically detected were then compared with theresults of our manual outbreak detection system.ResultsDuring the analysis period, 14 different hospital outbreaks were detected as a result of con-ventional manual outbreak detection. Based on the pathogens\u2019 overall incidence, outbreakswere divided into two categories: outbreaks with rarely detected pathogens (sporadic) andoutbreaks with often detected pathogens (endemic). For outbreaks with sporadic patho-gens, the detection rate of our AODS ranged from 83% to 100%. Every algorithm detected 6of 7 outbreaks with a sporadic pathogen. The AODS identified outbreaks with an endemicpathogen were at a detection rate of 33% to 100%. For endemic pathogens, the results var-ied based on the epidemiological characteristics of each outbreak and pathogen.PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 1 / 15a1111111111a1111111111a1111111111a1111111111a1111111111OPEN ACCESSCitation: Schro\u00a8der C, Pe\u00f1a Diaz LA, Rohde AM,Piening B, Aghdassi SJS, Pilarski G, et al. (2020)Lean back and wait for the alarm? Testing anautomated alarm system for nosocomial outbreaksto provide support for infection controlprofessionals. PLoS ONE 15(1): e0227955. https://doi.org/10.1371/journal.pone.0227955Editor: Surbhi Leekha, University of MarylandSchool of Medicine, UNITED STATESReceived: April 26, 2019Accepted: January 5, 2020Published: January 24, 2020Copyright: \u00a9 2020 Schro\u00a8der et al. This is an openaccess article distributed under the terms of theCreative Commons Attribution License, whichpermits unrestricted use, distribution, andreproduction in any medium, provided the originalauthor and source are credited.Data Availability Statement: All relevant data areavailable from https://zenodo.org/record/3603309.Funding: This work was partly funded by grantsfrom the German Society of Hospital Hygiene(DGKH). The concept of the project won a scientificprice from Stiftung Charite\u00b4. The funders had norole in study design, data collection and analysis,decision to publish, or preparation of themanuscript.ConclusionAODS for hospitals based on routine microbiological data is feasible and can provide rele-vant benefits for infection control teams. It offers in-time automated notification of suspectedpathogen clusters especially for sporadically occurring pathogens. However, outbreaks ofendemically detected pathogens need further individual pathogen-specific and setting-spe-cific adjustments.IntroductionOutbreak detection of infectious disease is an important area of hospital infection control. Itis crucial to detect outbreaks as quickly as possible to limit, through early interventions, thepotential for adverse outcomes in affected patients. Technical limitations pose a challenge forestablishing a real-time detection system and early recognition of outbreaks [1\u20133]. In mostcases, prospective outbreak detection relies on manual review of pooled microbiologicalresults. This approach is currently being used successfully for rare multidrug-resistant organ-isms (MDRO)[3]. However, due to the higher number of susceptible organisms in comparisonto MDROs, this approach not correlate with the expected outbreak risk in hospitals, butremains widely established as a result of an expected outbreak in hospitals, but remains widelyestablished as a result of the high positive predictive value of very rare pathogens (e.g. withantimicrobial resistance) [4, 5]. The strength of this practical approach lies in the high positivepredictive value of very rare pathogens (e.g. with antimicrobial resistance) [4, 5]. When limitedhuman and laboratory resources are taken into consideration, the resulting low number offalse positive results makes this outbreak detection manageable.The increasing digitalization of hospital data offers increasing opportunities for prospectivedata analyses in modern hospitals [6]. This data can be used to systematically screen for unex-pected increases in pathogen detection and thereby make automated outbreak detection sys-tems possible, even for common pathogens [4, 7]. A challenge in finding valuable solutionsforautomated outbreak detection systems (AODS) is the comparability of the different analyticapproaches [3]. In order to assess and compare, a universally agreed on definition of \u201cout-break\u201d as a gold standard is needed, but is currently still lacking [8, 9].In this work, our aim was to develop an AODS and to compare its results with our manualapproach. Our AODS is based on mathematical methods and the source data was taken fromreal life hospital data.MethodOur AODS is based on regular, computer-based, automated screening and systematic analysesof routinely collected microbiological laboratory and patient location data. In this work, wetested various methods of statistical analysis and compared them to the results of our currentmanual practice for outbreak detection.DatabasesThe databases derived from real-time diagnostic results of the microbiology laboratory ofCharite\u00b4 Universita\u00a8tsmedizin Berlin. Taken as a whole, the hospital has more than 3,000 bedsbut is divided into three spatially separated hospital campuses. The individual campuses workmostly independently of each other and exchange patients only irregularly.Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 2 / 15Competing interests: The authors have declaredthat no competing interests exist.Abbreviations: Aberration, AODS notification thatthe number of detected pathogens per time intervalis above the expected detection frequencyregardless whether an outbreak has beenconfirmed; Algorithm, Statistical application thatevaluates the likelihood of an outbreak behindfluctuating detection frequencies of pathogensbased on the comparison to historical data; AODS,Automated outbreak detection system; CDI,Clostridium difficile infection; Cluster, Anaccumulation of phenotypically identical pathogenswithin a narrow area and time frame; EARS, Earlyaberration reporting system; NBC, Negativebinomial CUSUMs; Outbreak (manual), A cluster ofpatients with the phenotypically identical pathogenthat was considered to derive from nosocomialtransmission based on the judgment of the manualoutbreak detection system; PI-NV, Normaldistribution prediction intervals; PI-POI, Poissondistributed prediction intervals; Time interval, 14days of microbiological results that were analyzedas a single period; VRE, Vancomycin-resistantenterococci.The period of the series of new outbreaks investigated in this paper ranged from 01/01/2016 until 12/31/2017. The manual detection of outbreaks occurred prospectively. Eachoutbreak investigated occurred during this time. The corresponding outbreak records werereported in such a way that the outbreak was at the mid-point of the datasets. Each set con-tained data for a 12 month period. Thus, it was possible to show data before and after theoutbreak. Furthermore, the algorithms utilized by our AODS used historical databases fromthe same laboratory that cover a 3-year time span from 01/01/2013 and 31/12/2015. The his-torical databases were necessary to determine the baseline detection frequency of each patho-gen. Only in this way could the AODS determine a suspicious change in pathogen detectionfrequency during the period in question. Data that included the following 11 species was ana-lyzed: the Acinetobacter baumannii group (A. baumannii, A. pittii und A. nosocomialis), Citro-bacter spp., Clostridium difficile, Enterococcus faecium, Enterobacter spp., Escherichia coli (only3GCREB und CRE), Klebsiella spp., Pseudomonas aeruginosa, Salmonella spp., Serratia spp.,and Staphylococcus aureus. Daily microbiological laboratory data was compiled over a 14-dayperiod. A 14-day period was used because our physicians hold team meetings on a weeklybasis to discuss the data from the previous 14 days. This period, which was set by the physi-cians, is based on transmission time. [10]These pooled results were defined as a time interval.The Institutional Review Board \u2018Ethikkommission der Charite\u00b4\u2014Universita\u00a8tsmedizin Ber-lin\u2019 waived the requirement for data that is collected in alignment with the German ProtectionAgainst Infection Act. The data at hand serves explicitly for infection control purposes withinthe scope of this regulation.Outbreak definitionsEstablished outbreak definition. In order to assess the results of our AODS, we com-pared the results to those of our manual outbreak detection system. The established systemis comprised of pathogen-based daily manual review of bacteriological clinical and screen-ing results as well as of information on infected patients collected by trained infection con-trol physicians on their regular clinical rounds and is focused on MDROs. Whenever asuspicious increase of a certain pathogen is detected, our infection control physicians evalu-ate the likelihood of an outbreak. This begins with a review of the clinical and epidemiologi-cal data on the patients in question. If the likelihood of an outbreak remains high, furthermicrobiological examinations are performed. This includes the collection of clinical micro-biological material, the screening of patients in question as well as environmental examina-tions. A molecular biological assessment is later performed on the pathogens collected forclonality. If this is the case we consider an outbreak to be verified; if not the cluster is con-sidered a false alarm. The outbreak investigation is conducted by at least one infection con-trol resident and is supervised by an infection control attending physician. In addition,several infection control nurses provide basic clinical data and collect the microbiologicalsamples.AODS outbreak definition. For the analysis of the AODS, datasets were divided intoendemic and sporadic pathogens, based on the frequency of detection per time interval.The riteria for \u201cendemic\u201d was met, when the pathogen was detected in more than 33% ofanalyzed time intervals. The definition \u201csporadic\u201d, in contrast, was used for pathogens thatwere detected in less than 33% of analyzed time intervals. (Fig 1) An aberration was definedas a certain number of pathogens above the endemic level (marked as a colored bar in allfigures). An endemic level for each database was determined by the algorithms mentionedabove.Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 3 / 15In order to develop an AODS with few false positive alarms, we specified a definitionfor \u2018relevant outbreak alarm\u2019 with a high positive predictive value (PPV). Every alarm wasconsidered clinically relevant for datasets of sporadic pathogens. Such pathogens are rarelyseen, hence relevant and false positive alarms are rare and no correction for specificitywas necessary. Repeated detection of rare pathogens in different patients is, therefore,associated with ad hoc high positive predictive value. In order to ensure a timely alarm, thefirst (manually detected) outbreak time interval also needed to have triggered an AODSalarm.Datasets of endemic pathogens are substantially more complicated. They are associatedwith a high likelihood of false positive alarms which would result in too much work in compar-ison to the additional benefit for the daily routine. In order to correct for this lack of specificity,we determined that a method is appropriate if 50% or less of the time intervals outside the out-break were detected as aberrations. This eventually eliminates methods which have too manyalarms. In addition, the timeliness of the alarm was ensured by an additional requirement. Aswith sporadic datasets, the first time interval of the manually detected outbreak needed to havetriggered an AODS alarm. For datasets of endemic pathogens, only the combination of thesetwo requirements led to the conclusion. AODS detected the same outbreak as the manual out-break detection.Algorithmic methodsThere are five established categories of algorithms used to detect outbreaks. We utilized algo-rithms from three of these categories: prediction intervals, statistical process control, and sta-tistical modeling. To predict intervals, we used normal distribution prediction intervals(PI-NV), Poisson distribution (PI-POI), and score prediction intervals (PI-SCORE) [11]. Asmethods of statistical process control, we used the early aberration reporting system (EARS)Fig 1. Classification of outbreaks into two types. Datasets with endemically detected pathogens and datasets withsporadic pathogens. In the endemic dataset at least one pathogen occurred more than 30% of the time. In the sporadicdataset at least one pathogen occurred 30% or less of the time.https://doi.org/10.1371/journal.pone.0227955.g001Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 4 / 15[12, 13] and negative binomial CUSUMs (NBC) [14]. For statistical modeling, we used the Far-rington algorithm [15]. A more detailed description can be found in the supplement.SatScan [16] based on temporal scan statistics was not used for several reasons. Our systemwas planned as a daily routine tool for infection control professionals. Furthermore, the tech-nical requirements in our hospital led us to create an intranet application. Therefore, we cre-ated a graphical web user interface. At the time we developed our automated outbreakdetection system, Satscan did not provide such a solution.Previous publications have described the feasibility of machine learning for outbreak detec-tion [17]. The method employed by Miller et al. required the measurement of pathogen simi-larity, e.g. whole genome sequencing. Unfortunately, this data was not routinely available inour hospital during the study period.All 6 algorithms were used simultaneously. An aberration was detected if the number of iso-lates exceeded the threshold calculated by the 6 algorithms. Whether an outbreak was identi-fied correctly depended on the pathogen (endemic or sporadic). A detected aberration wasconsidered genuine, if it fulfilled the AODS outbreak definition from the section before. Tocompare the algorithm we calculated the \u201cdetection rate by the algorithms\u201d, i.e. \u201ccorrect identi-fied outbreaks\u201d divided by \u201call datasets\u201d multiplied by 100.All analyses were conducted in R [18]. The function \u201calgo.farrington\u201dwas used from thepackage surveillance [19].ResultsOur infection control team detected 14 outbreaks in the two years analyzed (Table 1 and S1\u2013S12 Figs). Seven outbreaks were found in datasets of pathogens classified as endemic (shortendemic datasets), seven in datasets of sporadic pathogens (short sporadic datasets). The 14outbreaks include six different bacterial species overall. The shortest outbreak duration was asingle time interval (14 days), the longest 17 time intervals (238 days). In median, an endemicoutbreak lasted 3 time intervals (mean: 6.14 time intervals) and a sporadic outbreak lasted inmedian 2 time intervals (mean: 2.00 time intervals).The respective courses of an endemic and sporadic pathogen are shown in Fig 2. Each barrepresents the pathogens detected in one time interval. White bars indicate that no aberrationwas found, colored bars that an aberration was found. The AODS-calculated thresholds areshown as dotted lines in the figures. The blue boxes show the time frame of the outbreak bythe manual method.For the endemic dataset shown, a pathogen was found in almost every time interval (24 of27). For the sporadic dataset at least one pathogen occurred in four time intervals.The first bar in the outbreak of the endemic dataset was detected as an aberration by 5 of 6algorithms. This met the first criterion for \u201coutbreak was found\u201d for an endemic dataset. For 3of the 6 algorithms (POI-PI, SCORE-PI and Farrington algorithm) almost all bars outside theblue box indicate an aberration. This violates the second criterion for the outbreak definitionof an endemic dataset. Hence, the endemic outbreak was detected by only two algorithms(NBC and NV-PI).All endemic outbreaks were detected by normal distribution prediction interval (Table 2).Poisson prediction interval, score prediction interval, and negative binomial CUSUMsdetected 6 of 7 outbreaks. Early aberration reporting system detected 5 of 7 outbreaks and theFarrington algorithm detected 1 of 7 outbreaks.Almost every first time interval in an endemic outbreak was detected, except in 4 cases. In 9of 42 cases of endemic outbreak, the algorithms detected too many false alarms. Six of themresulted from use of the Farrington algorithm.Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 5 / 15Every algorithm except negative binomial CUSUMs detected all sporadic outbreaks(Table 3).DiscussionWhen analyzing routine diagnostic microbiological data, automated outbreak detection sys-tems (AODS) offer the means of screening for outbreaks of both common as well as sporadicpathogens[4]. In this work, our aim was to assess an AODS we developed for our hospital. Themain approach was to compare our established manual outbreak detection system with theAODS under real-life conditions.Sporadic vs. endemicBased on a rough epidemiological pattern, we defined two types of outbreak analyses: one forpathogens detected sporadically [7, 11] and one for pathogens with high frequency of detec-tion. We termed such pathogens endemic pathogens. These pose a relevant detection problemas they often produce false positive alarms leading to a high risk of pseudo-outbreaks [20]. Incontrast, in the case of sporadically detected pathogens, the positive predictive value of an out-break alarm is very high. If very rare pathogens are detected in multiple patients in a closedspace (e.g. particular ward) within a short time (e.g. one month), an epidemiological correla-tion is highly likely. In this case, no complicated algorithmic analysis is necessary. The benefitof an automated system, then, lies in its immediate alarm. With endemic pathogens, outbreakinvestigations require close cooperation with the respective clinical department.Table 1. Overview of manually detected outbreaks in 2016 and 2017. Endemic outbreaks are indicated by Arabic numerals, sporadic outbreaks by Roman numerals.Outbreak Pathogen DrugResistanceStart Time Interval1 ofthe outbreakEnd Time Interval1 ofthe outbreakNumber of Isolates(involved in outbreak)Time intervals with >= 1 isolatesType ofdataset1 EnterococcusfaeciumVRE 9 20 7 22 Endemic22 EnterococcusfaeciumVRE 9 18 17 25 Endemic23 Staphylococcusaureus13 14 6 24 Endemic24 Clostridium difficile 14 14 2 15 Endemic25 Clostridium difficile 14 14 2 15 Endemic26 EnterococcusfaeciumVRE 14 16 10 22 Endemic27 EnterococcusfaeciumVRE 6 22 9 23 Endemic2I Klebsiella spp MDR 13 14 3 4 Sporadic3II Klebsiella spp MDR 14 16 6 6 Sporadic3III Escherichia coli XDR 13 16 3 3 Sporadic3IV Klebsiella spp 14 14 8 7 Sporadic3V AcinetobacterbaumanniiXDR 13 15 3 5 Sporadic3VI Clostridium difficile 14 14 3 7 Sporadic3VII Clostridium difficile 14 14 2 4 Sporadic3VRE, vancomycin-resistant enterococci. MDR, multidrug-resistant. XDR, extensively drug-resistant.1Time interval equals 14 days.2 Eendemic = Isolates found in more than 1/3 of time intervals investigated.3 Ssporadic = Isolates found in 1/3 time intervals or less.https://doi.org/10.1371/journal.pone.0227955.t001Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 6 / 15Microbiological detection of these common pathogens rarely triggers suspicion of an outbreakbased on the recurrence of the pathogen. However, it must be assumed that most outbreaksoccur with common pathogens. Hence, it is very likely that there is a large reporting bias favor-ing outbreaks with rare or MDR pathogens [21]. Highly discriminatory molecular analyticalmethods, e.g. whole genome sequencing, offer a possible future solution since pathogens canbe quickly evaluated if suspicious clusters occur [22]. Unfortunately, for the time being theseFig 2. Two examples of outbreaks detected manually vs. outbreaks detected by AODS. Left: Outbreak in an endemicdataset (outbreak 2, vancomycin-resistant E. faecium). Right: Outbreak in a sporadic dataset (outbreak I, Klebisella spp.,MDR). Depicted is the course of pathogen detection on the ward during a year when an outbreak was manually detected.The manually detected outbreak is in the center and is indicated by a light blue box. Each bar represents the number ofpathogens detected per time interval (14 days). If a bar is colored, an algorithm detected an aberration. Shown are the resultsfor all six algorithms (top down in different colors): normal prediction interval, Poisson prediction interval, score predictioninterval, early aberration report system, negative binomial CUSUMs, and the Farrington algorithm.https://doi.org/10.1371/journal.pone.0227955.g002Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 7 / 15methods are time consuming, expensive, and require specialists trained in bioinformatics.Therefore, they are not currently available as routine diagnostic methods at most hospitals andoften are applied only in situations where there exists high risks of further transmission or topatient health.Outbreaks of sporadically detected pathogensAll outbreaks with sporadic pathogens were detected by 5 of 6 algorithms. NBC missed anXDR E. coli- and XDR A. baumannii outbreak. In order to provide the infection control teamwith a real benefit in terms of reaction time, our definition of detection required an alarm atthe beginning of the outbreak. Even though the XDR A. baumannii outbreak was eventuallydetected, it happened only after a significant delay of more than one month (S4 Fig). The XDRE. coli outbreak was not detected by NBC at all (S2 Fig). In contrast to our results, Watkinset al. showed that NBC provides better detection rates and fewer false alarms than others, e.g.EARS [13]. Another simulation study demonstrated the superiority of NBC to EARS [23].Those studies, however, tested NBC for natural outbreaks of disease syndromes with a highnumber of patients, as in natural outbreaks of viral diseases[13]. It is questionable if the cir-cumstances of these studies are can be compared to our setting (hospital ward, bacterial patho-gen, low number of cases). Further studies are needed to assess the detection detection rates ofthese algorithms, in particular NBC, for outbreaks in hospital wards with sporadic bacteria.Outbreaks of endemic pathogensConcerning outbreaks of endemic pathogens, the algorithm\u2019s \u2018normal distribution predictioninterval\u2019 was superior to all others and detected every outbreak, whereas Farrington performedworst.Table 2. Detection rate for endemic datasets, stratified by results from the 6 algorithms used. The detection rate is shown for each algorithm (columns) and each out-break (rows).NormaldirstributionpredictionintervalPoissondirstributionpredictionintervalScorepredictionintervalEarlyaberrationreportingsystemNegativeBinomialCusumsFarrington Detection Rate of the outbreakFF L50 FF L50 FF L50 FF L50 FF L50 FF L50Outbreak 1(VRE)X X X X X X X X X X X 83%Outbreak 2(VRE)X X X X X X X X 33%Outbreak 3(Staphylo-coccus aureus)X X X X X X X X X X X X 100%Outbreak 4(CDIF)X X X X X X X 50%Outbreak 5(CDIF)X X X X X X X X X X X 83%Outbreak 6(VRE)X X X X X X X X X X X 83%Outbreak 7(VRE)X X X X X X X X X X 83%Detection rate of the alorithms 100% 86% 86% 71% 86% 14%FF (First Found), first outbreak time interval detected as aberration. L50,\ufffd50% of the time intervals outside the outbreak were detected as aberration. X, the conditionFF or L50 was met. An outbreak detection required that both conditions be met. Coloured background indicates that the outbreak was detected by our AutomatedOutbreak Detection System. VRE Vancomycin resitant Enterococci. CDIF Clostridum difficile.https://doi.org/10.1371/journal.pone.0227955.t002Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 8 / 15Despite Farrington\u2019s detection of 6 of 7 outbreaks, it produced too many false alarms. Ourresults concerning the Farrington algorithm stand in contrast to the published literature whichreport good performance by regression models like Farrington, e.g. in public health in France[24]. However, Farrington was designed to adjust for seasonality, which does not apply in ourdatasets. Moreover, regression models like Farrington do not perform well for small outbreaks(low number of patients) like those in our hospital and in most other hospital settings [25].Previously it was shown in a simulation study that Farrington has a low sensitivity [26]. There-fore, it is possible that the Farrington algorithm alone should not be the algorithm of choicefor regular hospital outbreaks.Poisson distribution, score distribution prediction interval as well as NBC performed simi-larly well and showed weaknesses only regarding a VR-E. faecium outbreak. In comparison,EARS missed one additional outbreak, one of two C. difficile outbreaks. The VR-E. faeciumoutbreak missed occurred during an increase in VR-E. faecium incidence that was slow overall.This most likely led to an increase in false alarms in Poisson distribution and score distribu-tion. NBC, however, reacted to this increase with fewer false alarms (higher specificity) buttriggered the alarm with an unacceptable delay of more than 1.5 months after the outbreakonset.Moreover, it should be acknowledged that in several respects, outbreaks with VRE areoutstanding examples of infection control practice. First, VR-E. faecium is currently a verycommon pathogen with significantly increasing incidence [27] in Germany. In our datasetscomprise four different outbreaks which represent the highest prevalence (up to 14 differentTable 3. Detection rate for sporadic datasets, stratified by results from the 6 algorithms used. The detection rate is shown for each algorithm (columns) and each out-break (rows).Normal dirstributionprediction intervalPoisson dirstributionprediction intervalScore predictionintervalEarly aberrationreporting systemNegativeBinomialCusumsFarrington Detection Rate ofthe outbreakFF FF FF FF FF FFOutbreak I(MDR Klebsiellaspp.)X X X X X X 100%Outbreak II(MDR Klebsiellaspp.)X X X X X X 100%Outbreak III(XDR Escherichiacoli)X X X X X 83%Outbreak IV(Klebsiella spp.)X X X X X X 100%Outbreak V(XDR Acinobacterbaumanii)X X X X X 83%Outbreak VI(CDIF)X X X X X X 100%Outbreak VII(CDIF)X X X X X X 100%Detection rate ofthe alorithms100% 100% 100% 100% 71% 100%FF (First Found), first outbreak time interval was detected as aberration. L50,\ufffd50% of the time intervals outside the outbreak were detected as aberration. X, thecondition FF was met. Coloured background indicates that the outbreak was detected by our Automated Outbreak Detection System. MDR multidrug resistant. XDRextensivily drug resistant. CDIF clostridium difficile.https://doi.org/10.1371/journal.pone.0227955.t003Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 9 / 15patients per time period). Second, different VRE isolates from hospital clusters are oftennot distinguishable using commonly available molecular methods [28]. Moreover, becauseenterococci are ubiquitous bacteria, transmission routes are highly complex and includevarious modes of introduction between different hospitals and wards, especially oncologywards with continually returning VRE patients [28, 29]. This eventually leads to low posit-ive predictive value for detected aberrations of clusters on oncology wards (or other highendemic settings). This is different particularly in other disciplines with low VRE preva-lence. Therefore, adjusted levels of specificity based on ward discipline are required, nota-bly for VRE in Germany, but possibly also for pathogens with similar epidemiologicalcharacteristics.Outbreaks of Clostridium difficile infections (CDI)Outbreaks of toxin-producing C. difficile are another problematic area of automated outbreakdetection. C. difficile is a ubiquitous bacterium; the associated diarrhea (CDI) usually followsextensive antimicrobial therapy [30]. Therefore, simple pathogen detection without clinicalverification of diarrhea is most likely not an adequate approach for CDI outbreak detection.Moreover, whole-genome outbreak studies showed that probably only 40% of nosocomialCDI clusters are clonal [31]. The rest are most probably independent events that follow anti-microbial therapy. They can appear as clusters due to ward-specific policies determiningwhich antimicrobial therapies are used. Therefore, on a high endemic ward, the positive pre-dictive value of a CDI outbreak alarm is low. Even more problematic, most laboratories exam-ine factors other than bacterial cultures, for example toxin production. This often renders itimpossible to determine post hoc clonal relatedness. We examined four different C. difficileclusters. Two of them were in sporadic situations and were detected by all algorithms (detec-tion rate 100%). Of the two other endemic clusters, one was detected with an acceptable detec-tion rate of 83% (outbreak 5). The other one (outbreak 4) was detected by only 50% of thealgorithms we tested. A noteworthy difference between these outbreaks was the steeperincrease in detection rates during outbreak 5 (compared to outbreak 4) and the associatedperiod prior the outbreak. Our results, therefore, showed that for CDI further adjustmentsneed to be made, in order determine the likelihood of a CDI outbreak.LimitationsOur AODS approach is pathogen-based and can only detect possible clonal outbreaks. Nogold standard for outbreak detection exists because there is no international consensus onthe definition of an outbreak [3, 4, 20]. Therefore, specificity could not be calculated for ourAODS. Hence, we have based our analysis on the comparison of the outbreak detection systemwe currently use and the AODS. Our manual outbreak detection system works prospectivelybut the AODS works retrospectively. This approach could have missed outbreaks. Hence, suchoutbreaks could be not analyzed by AODS. These Another limitation exists with regard toclonal typing which was not performed routinely. Therefore, it was not possible to detect thepotential for better detection rates of the AODS with respect to our manual outbreak detection.Future prospective studies that include state-of-the-art clonal typing methods are necessary inorder to assess further benefits of AODS.ConclusionOur work showed that an automated outbreak system for sporadic bacteria in hospitals canwork reliably in many cases. It can provide an early warning system and depends only ontimely reports of microbiological results. The greatest benefit of such an automated systemLean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 10 / 15lies in the automatic alarm for clusters of otherwise rare pathogens, especially in large hospi-tals. Regarding more common bacteria, the system resulted in a substantial improvement inone hospital\u2019s outbreak detection detection rates. However, the low positive predictive valueof those alarms illustrates the need for further adjustments for various other variables. Forexample, ward and pathogen-specific characteristics need to be taken into consideration inall analyses because they change the predictive value to a great extent. If outbreak isolates arestill retrievable, the alarm would lead to further molecular analyses of the isolates\u2019 genetic relat-edness. In most cases, this will not be feasible and a decision on the likelihood of a real out-break remains dependent on the expertise of the hospital epidemiologist. We believe thatcurrently available technology cannot replace an experienced hospital epidemiologist. How-ever, although it needs further development and evaluation in real life situations, our systemprovides fundamental work toward a system of automated outbreak detection.Supporting informationS1 Fig. Outbreak within a sporadic dataset (outbreak II). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S2 Fig. Outbreak within a sporadic dataset (outbreak III). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S3 Fig. Outbreak within a sporadic dataset (outbreak IV). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S4 Fig. Outbreak within a sporadic dataset (outbreak V). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 11 / 15S5 Fig. Outbreak within a sporadic dataset (outbreak VI). Shown is the course of patho-gen detection on the ward during a year when an outbreak was conventionally detected.The conventionally detected outbreak is centered and marked by a light blue box. Every barstands for the number of pathogens detected per time interval (14 days). If a bar is colored,an algorithm detected an aberration. Shown are the results for all six algorithms (top downin differing colors): normal prediction interval, poison prediction interval, score predictioninterval, early aberration report system, negative binomial CUSUMs and Farrington algo-rithm.(TIFF)S6 Fig. Outbreak within a sporadic dataset (outbreak VII). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S7 Fig. Outbreak within an endemic dataset (outbreak 1). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S8 Fig. Outbreak within an endemic dataset (outbreak 3). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S9 Fig. Outbreak within an endemic dataset (outbreak 4). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S10 Fig. Outbreak within an endemic dataset (outbreak 5). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differingLean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 12 / 15colors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S11 Fig. Outbreak within an endemic dataset (outbreak 6). Shown is the course of patho-gen detection on the ward during a year when an outbreak was conventionally detected. Theconventionally detected outbreak is centered and marked by a light blue box. Every barstands for the number of pathogens detected per time interval (14 days). If a bar is colored,an algorithm detected an aberration. Shown are the results for all six algorithms (top downin differing colors): normal prediction interval, poison prediction interval, score predictioninterval, early aberration report system, negative binomial CUSUMs and Farrington algo-rithm.(TIFF)S12 Fig. Outbreak within an endemic dataset (outbreak 7). Shown is the course of pathogendetection on the ward during a year when an outbreak was conventionally detected. The con-ventionally detected outbreak is centered and marked by a light blue box. Every bar stands forthe number of pathogens detected per time interval (14 days). If a bar is colored, an algorithmdetected an aberration. Shown are the results for all six algorithms (top down in differing col-ors): normal prediction interval, poison prediction interval, score prediction interval, earlyaberration report system, negative binomial CUSUMs and Farrington algorithm.(TIFF)S1 Text. Detailed algorithms description.(DOC)AcknowledgmentsWe wish to thank our infection control physicians for their daily routine work on our systemand their valuable feedback. These are: Peter Bischoff (MD), Christine Geffers (MD), SonjaHansen (MD), Julia Hermes (MD), Axel Kola (MD), Tobias Kramer (MD), Friederike Maech-ler (MD), Cornelius Remschmidt (MD), Florian Salm (MD), Beate Weikert (MD), MiriamWiese-Posselt (MD).Special thanks go also to our infection control nurses.Thanks to Gerald Brennan for proofreading.Author ContributionsConceptualization: Luis Alberto Pe\u00f1a Diaz, Brar Piening, Petra Gastmeier, Michael Behnke.Data curation: Luis Alberto Pe\u00f1a Diaz, Brar Piening.Funding acquisition: Rasmus Leistner, Michael Behnke.Methodology: Christin Schro\u00a8der.Project administration: Anna Maria Rohde, Seven Johannes Sam Aghdassi, Michael Behnke.Resources: Michael Behnke.Software: Christin Schro\u00a8der, Luis Alberto Pe\u00f1a Diaz, Georg Pilarski, Norbert Thoma, MichaelBehnke.Supervision: Petra Gastmeier, Rasmus Leistner, Michael Behnke.Validation: Anna Maria Rohde.Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 13 / 15Visualization: Christin Schro\u00a8der.Writing \u2013 original draft: Christin Schro\u00a8der, Rasmus Leistner.Writing \u2013 review & editing: Anna Maria Rohde, Brar Piening, Petra Gastmeier, Rasmus Leist-ner, Michael Behnke.References1. Snitkin ES, Zelazny AM, Thomas PJ, Stock F, Henderson DK, Palmore TN, et al. Tracking a hospitaloutbreak of carbapenem-resistant Klebsiella pneumoniae with whole-genome sequencing. Sciencetranslational medicine. 2012; 4(148):148ra16\u2013ra16.2. Bergin SM, Periaswamy B, Barkham T, Chua HC, Mok YM, Fung DSS, et al. An Outbreak of Strepto-coccus pyogenes in a Mental Health Facility: Advantage of Well-Timed Whole-Genome SequencingOver emm Typing. Infection control and hospital epidemiology. 2018:1\u20139.3. Baker MA, Huang SS, Letourneau AR, Kaganov RE, Peeples JR, Drees M, et al. Lack of comprehen-sive outbreak detection in hospitals. infection control & hospital epidemiology. 2016; 37(4):466\u20138.4. Leclere B, Buckeridge DL, Boelle PY, Astagneau P, Lepelletier D. Automated detection of hospital out-breaks: A systematic review of methods. PLoS One. 2017; 12(4):e0176438. https://doi.org/10.1371/journal.pone.0176438 PMID: 284414225. Buckeridge DL. Outbreak detection through automated surveillance: a review of the determinants ofdetection. Journal of biomedical informatics. 2007; 40(4):370\u20139. https://doi.org/10.1016/j.jbi.2006.09.003 PMID: 170953016. Murdoch TB, Detsky AS. The inevitable application of big data to health care. Jama. 2013; 309(13):1351\u20132. https://doi.org/10.1001/jama.2013.393 PMID: 235495797. Dessau RB, Steenberg P. Computerized surveillance in clinical microbiology with time series analysis.Journal of clinical microbiology. 1993; 31(4):857\u201360. PMID: 84633978. Buehler JW, Hopkins RS, Overhage JM, Sosin DM, Tong V. Framework for evaluating public health sur-veillance systems for early detection of outbreaks: recommendations from the CDC Working Group.MMWR Recommendations and reports: Morbidity and mortality weekly report Recommendations andreports. 2004; 53(Rr-5):1\u201311. PMID: 151291919. Rutjes AW, Reitsma JB, Coomarasamy A, Khan KS, Bossuyt PM. Evaluation of diagnostic tests whenthere is no gold standard. A review of methods. Health technology assessment (Winchester, England).2007; 11(50):iii, ix\u201351.10. Grundmann H, Barwolff S, Tami A, Behnke M, Schwab F, Geffers C, et al. How many infections arecaused by patient-to-patient transmission in intensive care units? Critical care medicine. 2005; 33(5):946\u201351. https://doi.org/10.1097/01.ccm.0000163223.26234.56 PMID: 1589131811. Nishiura H. Early detection of nosocomial outbreaks caused by rare pathogens: a case study employingscore prediction interval. Osong Public Health Res Perspect. 2012; 3(3):121\u20137. https://doi.org/10.1016/j.phrp.2012.07.010 PMID: 2415950312. Hutwagner L, Thompson W, Seeman GM, Treadwell T. The bioterrorism preparedness and responseEarly Aberration Reporting System (EARS). J Urban Health. 2003; 80(2 Suppl 1):i89\u201396. PMID:1279178313. Watkins RE, Eagleson S, Veenendaal B, Wright G, Plant AJ. Applying cusum-based methods for thedetection of outbreaks of Ross River virus disease in Western Australia. BMC Med Inform Decis Mak.2008; 8:37. https://doi.org/10.1186/1472-6947-8-37 PMID: 1870004414. Pelecanos AM, Ryan PA, Gatton ML. Outbreak detection algorithms for seasonal disease data: a casestudy using Ross River virus disease. BMC Med Inform Decis Mak. 2010; 10:74. https://doi.org/10.1186/1472-6947-10-74 PMID: 2110610415. Farrington CP, Andrews NJ, Beale AD, Catchpole MA. A Statistical Algorithm for the Early Detection ofOutbreaks of Infectious Disease. Journal of the Royal Statistical Society Series A (Statistics in Society).1996; 159(3):547\u201363.16. Kulldorff M, Heffernan R, Hartman J, Assuncao R, Mostashari F. A space-time permutation scan statis-tic for disease outbreak detection. PLoS medicine. 2005; 2(3):e59. https://doi.org/10.1371/journal.pmed.0020059 PMID: 1571906617. Miller JK, Chen J, Sundermann A, Marsh JW, Saul MI, Shutt KA, et al. Statistical outbreak detection byjoining medical records and pathogen similarity. J Biomed Inform. 2019; 91:103126. https://doi.org/10.1016/j.jbi.2019.103126 PMID: 30771483Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 14 / 1518. R Development Core Team. R: A language and environment for statistical computing. Vienna, Austria:R Foundation for Statistical Computing; 2019.19. Salmon M, Schumacher D, Hohle M. Monitoring Count Time Series in R: Aberration Detection in PublicHealth Surveillance. J Stat Softw. 2016; 70(10):1\u201335.20. Stoesser N, Sheppard AE, Moore C, Golubchik T, Parry C, Nget P, et al. Extensive within-host diversityin fecally carried extended-spectrum beta-lactamase-producing Escherichia coli: implications for trans-mission analyses. Journal of clinical microbiology. 2015:JCM. 00378\u201315.21. Gastmeier P, Stamm-Balderjahn S, Hansen S, Zuschneid I, Sohr D, Behnke M, et al. Where should onesearch when confronted with outbreaks of nosocomial infection? American journal of infection control.2006; 34(9):603\u20135. https://doi.org/10.1016/j.ajic.2006.01.014 PMID: 1709745822. Sabat AJ, Budimir A, Nashev D, Sa\u00b4-Le\u00e3o R, Van Dijl JM, Laurent F, et al. Overview of molecular typingmethods for outbreak detection and epidemiological surveillance. Eurosurveillance. 2013; 18(4):20380.https://doi.org/10.2807/ese.18.04.20380-en PMID: 2336938923. Fricker RD, Hegler BL Jr., Dunfee DA. Comparing syndromic surveillance detection methods: EARS\u2019versus a CUSUM-based methodology. Stat Med. 2008; 27(17):3407\u201329. https://doi.org/10.1002/sim.3197 PMID: 1824012824. Guillou A, Kratz M, Strat YL. An extreme value theory approach for the early detection of time clusters.A simulation-based assessment and an illustration to the surveillance of Salmonella. Statistics in medi-cine. 2014; 33(28):5015\u201327. https://doi.org/10.1002/sim.6275 PMID: 2506076825. Unkel S, Farrington C, Garthwaite PH, Robertson C, Andrews N. Statistical methods for the prospectivedetection of infectious disease outbreaks: a review. Journal of the Royal Statistical Society: Series A(Statistics in Society). 2012; 175(1):49\u201382.26. Bedubourg G, Le Strat Y. Evaluation and comparison of statistical methods for early temporal detectionof outbreaks: A simulation-based study. PLoS One. 2017; 12(7):e0181227. https://doi.org/10.1371/journal.pone.0181227 PMID: 2871548927. Remschmidt C, Schroder C, Behnke M, Gastmeier P, Geffers C, Kramer TS. Continuous increase ofvancomycin resistance in enterococci causing nosocomial infections in Germany\u201410 years of surveil-lance. Antimicrobial resistance and infection control. 2018; 7:54. https://doi.org/10.1186/s13756-018-0353-x PMID: 2976091228. Raven KE, Gouliouris T, Brodrick H, Coll F, Brown NM, Reynolds R, et al. Complex routes of nosoco-mial vancomycin-resistant Enterococcus faecium transmission revealed by genome sequencing. Clini-cal infectious diseases. 2017; 64(7):886\u201393. https://doi.org/10.1093/cid/ciw872 PMID: 2836294529. Ulrich N, Vonberg RP, Gastmeier P. Outbreaks caused by vancomycin-resistant Enterococcus faeciumin hematology and oncology departments: A systematic review. Heliyon. 2017; 3(12):e00473. https://doi.org/10.1016/j.heliyon.2017.e00473 PMID: 2932209930. Leffler DA, Lamont JT. Clostridium difficile infection. New England Journal of Medicine. 2015; 372(16):1539\u201348. https://doi.org/10.1056/NEJMra1403772 PMID: 2587525931. Eyre DW, Cule ML, Walker AS, Crook DW, Wilcox MH, Peto TE. Hospital and community transmissionof Clostridium difficile: a whole genome sequencing study. The Lancet. 2012; 380:S12.Lean back and wait for the alarm?PLOS ONE | https://doi.org/10.1371/journal.pone.0227955 January 24, 2020 15 / 15",
      "id": 43733655,
      "identifiers": [
        {
          "identifier": "10.17169/refubium-26890",
          "type": "DOI"
        },
        {
          "identifier": "322846685",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:refubium.fu-berlin.de:fub188/27130",
          "type": "OAI_ID"
        }
      ],
      "title": "Lean back and wait for the alarm? Testing an automated alarm system for nosocomial outbreaks to provide support for infection control professionals",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:refubium.fu-berlin.de:fub188/27130"
      ],
      "publishedDate": "2020-01-01T00:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://refubium.fu-berlin.de/bitstream/fub188/27130/1/2020_Schr%c3%b6der_etal.pdf"
      ],
      "updatedDate": "2022-05-19T21:49:00",
      "yearPublished": 2020,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/322846685.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/322846685"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/322846685/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/322846685/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/43733655"
        }
      ]
    },
    {
      "acceptedDate": "2012-03-30T00:00:00",
      "arxivId": null,
      "authors": [
        {
          "name": "Benjamin Miller"
        },
        {
          "name": "Brinsfield"
        },
        {
          "name": "Bush"
        },
        {
          "name": "Centers for Disease Control and Prevention"
        },
        {
          "name": "Centers for Disease Control and Prevention"
        },
        {
          "name": "Goldenberg"
        },
        {
          "name": "Greenko"
        },
        {
          "name": "Heidi Kassenborg"
        },
        {
          "name": "Hutwagner"
        },
        {
          "name": "Irvin"
        },
        {
          "name": "James D. Nordin"
        },
        {
          "name": "Jayne Griffith"
        },
        {
          "name": "Lazarus"
        },
        {
          "name": "Lazarus"
        },
        {
          "name": "Lober"
        },
        {
          "name": "Lombardo"
        },
        {
          "name": "Lu"
        },
        {
          "name": "Lucas"
        },
        {
          "name": "Lucas"
        },
        {
          "name": "Mansour Hadidi"
        },
        {
          "name": "Meselson"
        },
        {
          "name": "Mostashari"
        },
        {
          "name": "Platt"
        },
        {
          "name": "Richard Danila"
        },
        {
          "name": "Rodman"
        },
        {
          "name": "Tillett"
        },
        {
          "name": "Tsui"
        },
        {
          "name": "VanBrackle"
        },
        {
          "name": "Wagner"
        },
        {
          "name": "William Dunsmuir"
        },
        {
          "name": "Williams"
        }
      ],
      "contributors": [
        ""
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/201061167",
        "https://api.core.ac.uk/v3/outputs/260309287"
      ],
      "createdDate": "2012-07-08T14:42:47",
      "dataProviders": [
        {
          "id": 4786,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/4786",
          "logo": "https://api.core.ac.uk/data-providers/4786/logo"
        },
        {
          "id": 645,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/645",
          "logo": "https://api.core.ac.uk/data-providers/645/logo"
        },
        {
          "id": 150,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/150",
          "logo": "https://api.core.ac.uk/data-providers/150/logo"
        }
      ],
      "depositedDate": "2004-10-01T00:00:00",
      "abstract": "Detection algorithm using proxy data for a bioterrorism agent release and historical data for influenza was effective",
      "documentType": "",
      "doi": "10.3201/eid1010.030789",
      "downloadUrl": "https://core.ac.uk/download/pdf/8708595.pdf",
      "fieldOfStudy": "medicine",
      "fullText": "Conventional disease surveillance mechanisms that\nrely on passive reporting may be too slow and insensitive\nto rapidly detect a large-scale infectious disease outbreak;\nthe reporting time from a patient\u2019s initial symptoms to spe-\ncific disease diagnosis takes days to weeks. To meet this\nneed, new surveillance methods are being developed.\nReferred to as nontraditional or syndromic surveillance,\nthese new systems typically rely on prediagnostic data to\nrapidly detect infectious disease outbreaks, such as those\ncaused by bioterrorism. Using data from a large health\nmaintenance organization, we discuss the development,\nimplementation, and evaluation of a time-series syndromic\nsurveillance detection algorithm for influenzalike illness in\nMinnesota. \nR\napid identification of a bioterrorism-related outbreak\nposes challenges to traditional public health disease\nsurveillance (1). At the individual level, the nonspecific\nprodrome of many diseases caused by bioterrorism agents\nrequires the disease to be recognized by an astute clinician\n(2,3). At the population level, an intentional release of a\nbioterrorism agent may require that disease clusters of syn-\ndromes, such as influenzalike illnesses (ILI), be recog-\nnized through recently developed nontraditional\nsurveillance mechanisms, such as syndromic surveillance\n(4\u20137). For instance, increases in ILI shown by syndromic\nsurveillance could indicate undiagnosed inhalation anthrax\nor pneumonic plague. \nVarious data sources can be used to construct syn-\ndromic surveillance systems. Existing patient data sources,\nsuch as emergency room chief complaints, ambulance dis-\npatch data, and clinical diagnosis data, have been used\n(8\u201312). Metadata collection systems that incorporate emer-\ngency room syndromes, private practice billing codes\ngrouped into syndromes, and veterinary syndromes also\nexist (7). Other existing data sources that are potentially\nsuitable for syndromic surveillance include calls to poison\ncontrol centers, over-the-counter and prescription medica-\ntion sales (7,13), nurse help-line telephone logs (7,14), and\nabsenteeism in schools (7). In this study, we evaluate the\nuse of data from an ambulatory care clinic network to\ndetect increases of ILI using a time-series autoregressive\nand cumulative sum (CUSUM)\u2013based detection algorithm.\nMethods\nData Source\nData in this study are from the HealthPartners Medical\nGroup (HPMG), which is a family of nonprofit Minnesota\nhealthcare organizations that serves approximately\n240,000 patients in the Minneapolis-St. Paul Metropolitan\nArea. HPMG is a current partner in the National\nBioterrorism Syndromic Surveillance Demonstration\nProgram (12). \nInvestments in technology infrastructure allow HPMG\nto digitally record International Classification of Diseases,\nRevision 9 (ICD-9) data from patient visits to network clin-\nics within approximately 24 hours of a patient\u2019s initial visit.\nThe need to develop validated and standardized methods\nfor syndromic surveillance is a current challenge to the\nfield. A framework for evaluating syndromic surveillance\nsystems has been developed, which provides a general\napproach to comparing and contrasting aspects of syn-\ndromic surveillance systems (15). We have adapted some of\nthese recommendations and have identified the following\nsix criteria that should be satisfied before developing syn-\ndromic surveillance detection algorithms: 1) data are col-\nRESEARCH\nSyndromic Surveillance for\nInfluenzalike Illness in \nan Ambulatory Care Network \nBenjamin Miller,* Heidi Kassenborg,\u2020 William Dunsmuir,\u2021 Jayne Griffith,* Mansour Hadidi,* \nJames D. Nordin,\u00a7 and Richard Danila*\n1806 Emerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004\n*Minnesota Department of Health, Minneapolis, Minnesota, USA;\n\u2020Minnesota Department of Agriculture, St. Paul, Minnesota, USA;\n\u2021University of New South Wales, Sydney, Australia; and\n\u00a7HealthPartners Research Foundation, Minneapolis, Minnesota,\nUSAlected and should exist for reasons other than bioterrorism\nsurveillance; 2) data should be recorded and accessible in a\nrecognized, consistent, and electronic format;     3) data\nshould be available for analysis shortly after the patient\u2019s\ninitial visit; 4) sufficient historical data sources should be\navailable that represent a reasonably static and definable\npopulation; 5) syndromes should be validated against exist-\ning traditional data sources; and 6) thresholds set for these\nsystems should achieve high sensitivity and positive pre-\ndictive value. Based on the framework for evaluating syn-\ndromic surveillance systems, we assess the appropriateness\nof ambulatory-care encounter data from HPMG.\nTo satisfy the first criterion, these data are collected at\nHPMG shortly after the patient\u2019s initial visit; then identifi-\ncation is removed and the data transferred to the Minnesota\nDepartment of Health for analysis without additional work\nfor physicians, clinic staff, or patients. For each scheduled,\nsame-day, or urgent care patient encounter, ICD-9 codes\nare collected, recorded, and stored in a standardized elec-\ntronic format, which fulfills the second criterion. Multiple\nICD-9 codes may be recorded for each patient (e.g., 786.2\ncough and 780.6 fever). The ICD-9 format consistency\nallows for reliable syndrome classification and analysis.\nOther possible sources of data that have been reliably clas-\nsified into syndrome categories and could be used in this\ntype of time-series analysis include chief complaint text\nfields and Health Level 7 (HL-7) messaging data (16).\nICD-9 encounter data and nonidentifying demographic\ninformation are queried daily from the HPMG central\npatient database and sent to the Minnesota Department of\nHealth through secure file transfer protocol. Fulfilling the\nthird criterion, an advanced electronic patient-tracking sys-\ntem allows for >90% of the encounter data at HPMG to be\navailable in HPMG databases within 24 hours of the clin-\nic encounter. In addition to the daily transmitted data, his-\ntorical encounter data beginning in April 1999 are used in\nthe analysis. These historical data represent a consistently\ninsured population within the clinic network with minimal\nimmigration into or emigration from the HPMG network,\nthus satisfying the fourth criterion for this type of autore-\ngressive time-series analysis. Had HPMG experienced\nsubstantial changes in its insured population, the underly-\ning statistical assumptions necessary for this analysis\nwould have been violated (17). Validation against a tradi-\ntional data source, the fifth criterion, and the selection of\nan appropriate threshold, the sixth criterion, will be dis-\ncussed below in the Validation section. \nModels and Analysis\nWe used an autoregressive model (PROC AUTOREG)\nto model the square root of the daily counts of ILI to the\nHPMG clinics in a 3-year historical period (18). Sample\nSAS code with tests for autocorrelation and stepwise\nautoregression is provided in the online Appendix\n(http://www.cdc.gov/ncidod/EID/vol10/no10/03-\n0789_app.htm). The model closely resembles ordinary lin-\near regression, but instead of the usual regression model,\nthe following autoregressive error model is used:\nThe notation indicates that each \u03b5t is\nnormally and independently distributed with mean 0 and\nvariance \u03c32. By simultaneously estimating the regression\ncoefficients \u03b2 and the autoregressive error parameters \u03c6i,\nthe model corrects the regression estimates for autocorre-\nlation, a common problem in time-series data.\nIn the model, we include an indicator for weekend or\nweekday, an indicator of the day as a regular or national\nholiday, and indicators for a sine and cosine function for\nseasonal adjustment. The model also includes a seventh-\norder autoregressive error model, selected by stepwise\nregression. In each case, the terms contribute significantly\nto the fit of the model (p < 0.05). \nThe predicted residuals from this model are then ana-\nlyzed by using the cumulative sums method (PROC\nCUSUM) (18,19). Initially used in the manufacturing\nindustry, CUSUM has been used for Salmonella surveil-\nlance in the United States and for influenza surveillance in\nthe United Kingdom (20\u201322). The method has properties\nmaking it well suited for disease outbreak detection. It can\nquickly detect small shifts from the process mean, provide\nestimates of when the change occurred, and estimate the\nmagnitude of change (17,23\u201325). \nValidation\nBecause syndromic surveillance attempts to identify\ndisease outbreaks before a definitive diagnosis is made,\nassessing the validity of the ILI syndrome is difficult. The\nactual cause of many signals generated by this system may\nnever be known because many patients are never request-\ned to submit specimens for laboratory testing.\nWe assessed the validity of the HPMG ILI syndrome\ncategory by comparing ILI visits in the HPMG network to\ndeaths from pneumonia and influenza in the core seven-\ncounty Minneapolis-St. Paul metropolitan area over the\nsame time period. ICD-9 codes that describe ILI were\nselected (Table). We also associated increases in ILI with\nthe known onset of influenza season by comparing\ninfluenza isolates and hospital laboratory data.\nSystem Testing \nData pertaining to the incubation period for inhalation-\nal exposure to most potential bioterrorism agents are limit-\n) , 0 ( ~\n2 \u03c3 \u03b5 IN t\nEmerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004 1807\nSyndromic Surveillance for Influenzalike Illness\nt t t x y \u03c5 \u03b2 + \u2032 =\nt m t m t t t \u03b5 \u03c5 \u03d5 \u03c5 \u03d5 \u03c5 \u03d5 \u03c5 + \u2212 \u2212 \u2212 \u2212 = \u2212 \u2212 \u2212 ... 2 2 1 1\n) , 0 ( ~\n2 \u03c3 \u03b5 IN ted. Therefore, evaluation of this system used hypothetical\nscenarios in which additional ICD-9 counts were added to\nexisting clinical data to determine the number of excess\ncases necessary to trigger a signal. In an approach adapted\nfrom Goldenberg, our hypothetical scenario uses data\ngathered from the only documented large-scale aerosol\nrelease of weapons-grade Bacillus anthracis spores (13). \nIn April and May 1979, an unusual outbreak of inhala-\ntional anthrax occurred in the city of Sverdlovsk in the for-\nmer Union of Soviet Socialist Republics. The outbreak\nwas originally ascribed to consuming contaminated meat,\nbut investigation by Soviet and international scientists sub-\nsequently linked the outbreak to an accidental aerosolized\nrelease of anthrax spores from a nearby military facility\n(26). The inadvertent release, which may have contained\nas little as several milligrams of spores, caused 77 con-\nfirmed inhalational anthrax cases and 68 deaths in 43 days. \nTo test our model, we constructed three hypothetical\nscenarios on the basis of data available from the\nSverdlovsk release. We made several assumptions in con-\nstructing these scenarios. First, a point-source release pat-\ntern similar to that observed in Sverdlovsk occurs in the\ndowntown area of the Minneapolis-St. Paul metropolitan\narea during a weekday when most of the population is at\nwork. This scenario will effectively disperse exposed per-\nsons to most clinics in the HPMG network, if one assumes\nthat exposed persons will seek care at a clinic near their\nresidence. Second, a subset of those exposed to the release\nwill visit an HPMG clinic on the date of symptom onset\nand in a manner identical to those exposed in the\nSverdlovsk release. This assumption effectively replicates\nthe incubation periods experienced by those in the\nSverdlovsk release and adds these additional cases to the\ndaily totals of ILI observed in HPMG clinics. The third\nassumption increases the overall numbers of patients seek-\ning care in the HPMG network from this exposure to 308\nduring a 43-day period, four times the number of con-\nfirmed ill in the Sverdlovsk release. The anthrax release\nand the resulting increase in ILI were modeled for three\ndifferent time periods to determine the effect of season,\nday of the week, holidays, and naturally occurring ILI on\nthe ability to detect the outbreak.\nResults\nValidation\nThe seasonal variation in HPMG ICD-9 ILI counts is\nsimilar to the variation in deaths from pneumonia and\ninfluenza in the core seven-county Minneapolis-St. Paul\nmetropolitan area, as reported by the Minnesota\nDepartment of Health (Figure 1). To satisfy the fifth crite-\nrion for establishing syndromic surveillance, i.e., validat-\ning syndromes against existing traditional data sources,\ndeath data from April 10, 1999, to December 29, 2000,\nwere compared to ILI ICD-9 counts over the same period.\nVisual comparison of these data in Figure 1 suggests that\nICD-9 ILI counts rose several weeks before the peak in\ndeaths. ILI syndrome validity was determined to be\nacceptable, as Pearson correlation results were significant\nbetween weekly influenza and pneumonia deaths and ILI\nclinical encounters in the same week (0.41) and the previ-\nous week (0.41).\nFormal calculations of sensitivity and positive predic-\ntive value were not conducted in this study. Calculation of\nthe appropriate threshold used in the detection algorithm\nwas determined qualitatively by adjusting the model\nparameters to detect the onset of influenza season. Figure\n2 illustrates a large and continuous signal that was retro-\nspectively observed beginning on December 12, 2000, and\ncontinuing until December 25, 2000. This alarm corre-\nsponds to a large ILI outbreak in the Minneapolis-St. Paul\nmetropolitan area and was possibly associated with\nincreased influenza Aand respiratory syncytial virus infec-\ntion. A hospital in the HPMG network reported above\n1808 Emerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004\nRESEARCHaverage submission and testing of isolates corresponding\nto these organisms during December 2000 and January\n2001.\nSystem Testing\nThe hypothetical anthrax release was modeled at three\ndifferent time periods beginning June 26, 2001, December\n17, 2001, and April 1, 2002. The threshold for CUSUM in\neach scenario was calculated as 1.1812, which resulted in\nan average-run-length of 50. The outbreak that began in\nJune was detected on June 30, 4 days after the release, with\na CUSUM value of 3.09 and after 30 outbreak-associated\nILI patients (11.9% increase above expected) visited the\nHPMG clinic network (Figure 3). The December outbreak\nwas detected 7 days after the release with a CUSUM value\nof 2.33 and 130 outbreak-associated ILI patients (12.4%\nincrease above expected) (Figure 4). The April outbreak\nwas detected 5 days after the release with a CUSUM value\nof 2.00 and an additional 45 outbreak-associated patients\nwith ILI (11.7% increase above expected) recorded in the\nclinic network (Figure 5). \nDiscussion\nBased on the six criteria we propose, we have attempt-\ned to construct a time-series syndromic surveillance sys-\ntem capable of detecting a bioterrorism or other public\nhealth event against the background of normal ILI clinic\nvisits. Patient use patterns and seasonality have a consid-\nerable effect on the distribution of the dataset, an effect\nthat must be considered when designing the autoregressive\nmodel. \nBecause the HPMG network offers same-day schedul-\ning for its members, many patients do not seek care on the\nweekend, when only urgent care facilities are open. This\ndelay results in an increased caseload on Monday, a situa-\ntion that is further exacerbated on a 3-day weekend. The\ndistribution of data is also affected by limited clinic access\nassociated with holidays. The HPMG clinic network oper-\nates at a reduced capacity on New Year\u2019s Day, Memorial\nDay, Independence Day, Labor Day, Thanksgiving Day,\nChristmas Eve Day, and Christmas Day. These holidays\noften occur on different days of the week from year to year,\nand therefore generate lower-than-expected counts in the\ndataset. Additionally, ILI events occur with greater\nEmerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004 1809\nSyndromic Surveillance for Influenzalike Illness\nFigure 1. Weekly totals of HealthPartners Medical Group influen-\nzalike illness ICD-9 counts (solid line) and Minneapolis-St. Paul\nmetropolitan area weekly influenza and pneumonia deaths (bro-\nken line) April 10, 1999, through December 29, 2000. \nFigure 2. Cumulative sum (CUSUM) chart signaling a significant\nsignal corresponding to a confirmed influenza A outbreak occur-\nring December 2000 and January 2001. CUSUM decision interval\n(horizontal broken line); CUSUM chart signals 24 days earlier\nwhen the analysis is stratified by age: >65 years (dotted line) and\nall ages (solid line).\nFigure 3. Cumulative sum (CUSUM) control chart of a hypothetical\nanthrax release occurring June 26, 2001. CUSUM of the residuals\n(broken line) is charted over the observed number of influenzalike\n(ILI) visits to the HealthPartners Medical Group (gray bars) and the\nadditional outbreak-associated ILI cases (white bars). The system\nthreshold, the CUSUM decision interval (solid line), is exceeded on\nJune 30 and remains above threshold until July 9. With relatively\nlow levels of ILI occurring in the summer months, this scenario\ndemonstrates the ability of the system to detect increased ILI visits\non weekdays and over the Fourth of July holiday.frequency in the winter, which generates a seasonal effect\nassociated with the HPMG ICD-9 data.\nFigure 1 shows general agreement between the distri-\nbution of ILI in the HPMG clinic network and influenza\nand pneumonia deaths in the greater metropolitan area dur-\ning the same period. In the Minneapolis-St. Paul metropol-\nitan area, a lag of 1 to 2 weeks occurs between time of\ninitial signs and symptoms for ILI in HPMG clinics and an\nincrease in influenza and pneumonia related deaths. This\nlag is less than that noted in other studies (27). \nInfluenza season in Minnesota is variable; onset ranges\nfrom early October through mid-January. Figure 2 illus-\ntrates a large, sustained increase of ILI beginning\nDecember 12, 2000. The Minnesota Department of Health\nPublic Health Laboratory confirmed the season\u2019s first pos-\nitive influenza isolate on December 13, 2000. This signal\nsuggests that the rapid detection of ILI in the community is\nattainable by monitoring ICD-9 counts representative of\nILI in a clinic network. When persons >65 years of age\nwere separated into a distinct ILI syndrome category, a sta-\ntistically significant signal is observed from November 18\nto November 20. This increase in the >65-year category\nprecedes the relatively large signal in the general popula-\ntion by approximately 3 weeks, demonstrating the utility\nof analyzing subsets of the patients as possible sentinel\npopulations.\nThe ability of the system to detect additional bioterror-\nism-related cases is apparent in the hypothetical scenarios\nillustrated in Figures 3, 4, and 5. When background levels\nof ILI are relatively low, the system quickly detected addi-\ntional cases associated with the anthrax release. At best,\nthe system detected the outbreak only 2 days after the first\ncase-patients began to visit the clinics. In winter months,\nwhen background ILI is higher, the system was slower to\ndetect the outbreak-associated cases. In December 2001, a\n5-day delay occurred between the appearance of sympto-\nmatic patients to the clinics and the recognition of the out-\nbreak by the system. Twenty-five additional patients were\nseen at clinics on December 24, 2001, a holiday, and the\nsystem calculated a significant CUSUM alarm of 4.48. The\nability of this system to detect the outbreak-associated\ncases at different times of the year, on weekends, and on\nholidays shows that the autoregressive model adequately\ncontrols for variance and autocorrelation in the dataset. \nThese scenarios demonstrate that the system possesses\nthe ability to detect the cumulative sum of a small amount\nof additional counts. The practical success of this surveil-\nlance system is limited only by the availability and quality\nof the source data.\nConclusion\nWe have established criteria necessary for initiating\nsyndromic surveillance for ILI and have demonstrated the\neffectiveness of our detection algorithm by using proxy\ndata for a bioterrorism agent release and historical data for\ninfluenza. We believe that this approach to syndromic sur-\nveillance is useful in detecting increases in ILI. \nMr. Miller is an epidemiologist in the Acute Disease\nInvestigation and Control Section at the Minnesota Department\n1810 Emerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004\nRESEARCH\nFigure 4. Cumulative sum (CUSUM) control chart of a hypothetical\nanthrax release occurring December 17, 2001. CUSUM of the\nresiduals (broken line) is charted over the observed number of\ninfluenzalike (ILI) visits to the HealthPartners Medical Group (gray\nbars) and the additional outbreak-associated ILI cases (white\nbars). The system threshold, the CUSUM decision interval (solid\nline), is exceeded on December 24 and remains above threshold\nuntil December 30. With high levels of ILI occurring in the winter\nmonths, this scenario demonstrates the ability of the system to\ndetect increased ILI visits during influenza season and over the\nwinter holidays.\nFigure 5. Cumulative sum (CUSUM) control chart of a hypothetical\nanthrax release occurring April 1, 2002. CUSUM of the residuals\n(broken line) is charted over the observed number of influenzalike\n(ILI) visits to the HealthPartners Medical Group (gray bars) and the\nadditional outbreak-associated ILI cases (white bars). The system\nthreshold, the CUSUM decision interval (solid line), is exceeded\non April 6 and remains above threshold until April 15. In this sce-\nnario, an additional 45 cases of ILI over 5 days are necessary to\npush the CUSUM above threshold. This represents an 11.7%\nincrease in ILI during that time period. of Health in Minneapolis, Minnesota. He is a recent graduate of\nthe University of Minnesota\u2019s School of Public Health. His\nresearch interests include healthcare data assessment and devel-\nopment of nontraditional or syndromic surveillance systems.\nReferences\n1.  Baxter R, Rubin R, Steinberg C, Carroll C, Shapiro J, Yang A.\nAssessing core capacity for infectious disease surveillance. Falls\nChurch (VA): The Lewin Group, Inc.; 2000.\n2. Centers for Disease Control and Prevention. Notice to readers: ongo-\ning investigation of anthrax\u2014Florida, October 2001. MMWR Morb\nMortal Wkly Rep. 2001;50:877.\n3. Bush L, Abrams B, Beall A, Johnson C. Brief report: index case of\nfatal inhalational anthrax due to bioterrorism in the United States. N\nEngl J Med. 2001;345:1607\u201310.\n4. Lazarus R, Kleinman K, Dashevsky I, Adams C, Kludt P, DeMaria A\nJr, et al. Use of automated ambulatory-care encounter records for\ndetection of acute illness clusters, including potential bioterrorism\nevents. Emerg Infect Dis [serial on the Internet]. 2002 Aug. Available\nfrom http://www.cdc.gov/ncidod/EID/vol8no8/02-0239.htm\n5. Wagner M, Tsui F-C, Espino J, Dato V, Sitting D, Carucana R, et al.\nThe emerging science of very early detection of disease outbreaks.\nJournal of Public Health Management and Practice. 2001;7:50\u20138. \n6. K, Gunn J, Barry M, McKenna V, Dyer K, Sulis C. Using volume-\nbased surveillance for an outbreak early warning system. Acad Emerg\nMed. 2001;8:492. \n7. Lombardo J, Burkom H, Elbert E, Magruder S, Lewis SH, Pavlin J,\net al. A systems overview of the Electronic Surveillance System for\nthe Early Notification of Community-Based Epidemics (ESSENSE\nII). J Urban Health. 2003;80(2 Suppl 1):i32\u201342.\n8. Irvin CB, Nouhan PP, Rice K. Syndromic analysis of computerized\nemergency department patients\u2019 chief complaints: an opportunity for\nbioterrorism and influenza surveillance. Ann Emerg Med.\n2003;41:8:447\u201352.\n9. Lober WB, Trigg LJ, Karras BT, Bliss D, Ciliberti J, Duchin JS, et al.\nSyndromic surveillance using automated collection of computerized\ndischarge diagnosis. J Urban Health. 2003;80(2 Suppl 1):i97\u2013106.\n10. Mostashari F, Fine A, Das D, Adams J, Layton M. Use of ambulance\ndispatch data as an early warning system for communitywide influen-\nza-like illness, New York City. J Urban Health. 2003;80(2 Suppl\n1):i43\u20139.\n11. Greenko J, Mostashari F, Fine A, Layton M. Clinical evaluation of the\nEmergency Medical Services (EMS) Ambulance Dispatch-Based\nSyndromic Surveillance System, New York City. J Urban Health.\n2003;80(2 Suppl 1):i50\u20136.\n12. Platt R, Bocchino C, Caldwell B, Harmon R, Kleinman K, Ritzwoller\nDP, et al. Syndromic surveillance using minimum transfer of identifi-\nable data: the example of the National Bioterrorism Syndromic\nSurveillance Demonstration Program. J Urban Health. 2003;80(2\nSuppl 1):i25\u201331.\n13. Goldenberg A, Shmueli G, Caruana R, Fienberg S. Early statistical\ndetection of anthrax outbreaks by tracking over-the-counter medica-\ntion sales. Proc Natl Acad Sci U S A. 2002;99:5237\u201340.\n14. Rodman J, Frost F, Jakubowski W. Using nurse hot line calls for dis-\nease surveillance. Emerg Infect Dis [serial on the Internet]. [cited\n1998 Apr-Jun]. Available from http://www.cdc.gov/ncidod/eid/\nvol4no2/rodman.htm\n15. Centers for Disease Control and Prevention. Framework for evaluat-\ning public health surveillance systems for early detection of out-\nbreaks; recommendations from the CDC Working Group. MMWR\nRecomm Rep. 2004;53(No. RR-5).\n16. Tsui, FC, Espino JU, Dato VM, Gesteland PH, Hutman J, Wagner M.\nTechnical description of RODS: a real-time public health surveillance\nsystem. J Am Med Inform Assoc. 2003;10:399\u2013408.\n17. Hawkins DM, Olwell DH. Cumulative sum charts and charting for\nquality improvement. New York: Springer-Verlag; 1998. \n18. Statistical Analysis System. SAS PC and enterprise guide, version 8.0\nand 1.2. Cary (NC): SAS Institute; 2000.\n19. Lu C, Renyolds MR. Cusum charts for monitoring an autocorrelated\nprocess. Journal of Quality Technology. 2001:33:316\u201334.\n20. Tillett HE, Spencer IL. Influenza surveillance in England and Wales\nusing routine statistics. Journal of Hygiene. 1982:88:83\u201394.\n21. Williams SM, Parry BR, Schlup MMT. Quality control: an applica-\ntion of the CUSUM. BMJ. 1992:304:1359\u201361.\n22. Hutwagner LC, Maloney EK, Bean NH, Slutsker L, Martin SM.\nUsing laboratory-based surveillance data for prevention: an algorithm\nfor detecting Salmonella outbreaks. Emerg Infect Dis [serial on the\nInternet]. 1997 Jul-Sep 3. Available from http://www.cdc.gov/nci-\ndod/eid/vol3/no3/hutwagnr.htm\n23. Lucas JM. The design and use of V-Mask control schemes. Journal of\nQuality Technology. 1976:8:1\u201312.\n24. Lucas JM. Counted data CUSUM\u2019s. Technometrics. 1985:27:129\u201344.\n25. VanBrackle L, Williamson GD. A study of the average run length\ncharacteristics of the National Notifiable Disease Surveillance\nSystem. Stat Med. 1999;18:3309\u201319.\n26. Meselson M, Guillemin J, Hugh-Jones M, Langmuir A, Popova I,\nShelokov A, et al. The Sverdlovsk anthrax outbreak of 1979. Science.\n1994;266:1202\u20137.\n27. Lazarus R, Kleinman KP, Dashevsky I, DeMaria A, Platt R. Using\nautomated medical records for rapid identification of illness syn-\ndromes (syndromic surveillance): the example of lower respiratory\ninfection. BMC Public Health. 2001;1:9. Epub 2001 Oct 22.\nAddress for correspondence: Benjamin D. Miller, University of\nMinnesota Department of Health, 717 Delaware St. SE, Minneapolis,\nMN 55414, USA; fax: 612-676-5743; email: Benjamin.miller@\nhealth.state.mn.us\nEmerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004 1811\nSyndromic Surveillance for Influenzalike Illness\nUse of trade names is for identification only and does not imply\nendorsement by the Public Health Service or by the U.S.\nDepartment of Health and Human Services.",
      "id": 4042490,
      "identifiers": [
        {
          "identifier": "oai:doaj.org/article:26a8a1df73bf443cba4a98e50e9d2f83",
          "type": "OAI_ID"
        },
        {
          "identifier": "260309287",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:pubmedcentral.nih.gov:3323280",
          "type": "OAI_ID"
        },
        {
          "identifier": "2098488367",
          "type": "MAG_ID"
        },
        {
          "identifier": "8708595",
          "type": "CORE_ID"
        },
        {
          "identifier": "10.3201/eid1010.030789",
          "type": "DOI"
        },
        {
          "identifier": "201061167",
          "type": "CORE_ID"
        },
        {
          "identifier": "3323280",
          "type": "PUBMED_ID"
        }
      ],
      "title": "Syndromic Surveillance for Influenzalike Illness in Ambulatory Care Setting",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:doaj.org/article:26a8a1df73bf443cba4a98e50e9d2f83",
        "oai:pubmedcentral.nih.gov:3323280"
      ],
      "publishedDate": "2004-10-01T00:00:00",
      "publisher": "Centers for Disease Control and Prevention",
      "pubmedId": "3323280",
      "references": [
        {
          "id": 31548500,
          "title": "A study of the average run length characteristics of the National Notifiable Disease Surveillance System. Stat Med.",
          "authors": [],
          "date": "1999",
          "doi": null,
          "raw": "VanBrackle L, Williamson GD. A study of the average run length characteristics of the National Notifiable Disease Surveillance System. Stat Med. 1999;18:3309\u201319.",
          "cites": null
        },
        {
          "id": 31548465,
          "title": "A systems overview of the Electronic Surveillance System for the Early Notification of Community-Based Epidemics (ESSENSE II). J Urban Health. 2003;80(2 Suppl 1):i32\u201342.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Lombardo J, Burkom H, Elbert E, Magruder S, Lewis SH, Pavlin J, et al. A systems overview of the Electronic Surveillance System for the Early Notification of Community-Based Epidemics (ESSENSE II). J Urban Health. 2003;80(2 Suppl 1):i32\u201342.",
          "cites": null
        },
        {
          "id": 31548456,
          "title": "Assessing core capacity for infectious disease surveillance. Falls Church (VA):",
          "authors": [],
          "date": "2000",
          "doi": null,
          "raw": "Baxter R, Rubin R, Steinberg C, Carroll C, Shapiro J, Yang A. Assessing core capacity for infectious disease surveillance. Falls Church (VA): The Lewin Group, Inc.; 2000.",
          "cites": null
        },
        {
          "id": 31548458,
          "title": "Brief report: index case of fatal inhalational anthrax due to bioterrorism in the United States.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Bush L, Abrams B, Beall A, Johnson C. Brief report: index case of fatal inhalational anthrax due to bioterrorism in the United States. N Engl J Med. 2001;345:1607\u201310.",
          "cites": null
        },
        {
          "id": 31548480,
          "title": "Clinical evaluation of the Emergency Medical Services (EMS) Ambulance Dispatch-Based Syndromic Surveillance System,",
          "authors": [],
          "date": "2003",
          "doi": null,
          "raw": "Greenko J, Mostashari F, Fine A, Layton M. Clinical evaluation of the Emergency Medical Services (EMS) Ambulance Dispatch-Based Syndromic Surveillance System, New York City. J Urban Health. 2003;80(2 Suppl 1):i50\u20136.",
          "cites": null
        },
        {
          "id": 31548499,
          "title": "Counted data CUSUM\u2019s.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Lucas JM. Counted data CUSUM\u2019s. Technometrics. 1985:27:129\u201344.",
          "cites": null
        },
        {
          "id": 31548492,
          "title": "Cumulative sum charts and charting for quality improvement.",
          "authors": [],
          "date": "1998",
          "doi": null,
          "raw": "Hawkins DM, Olwell DH. Cumulative sum charts and charting for quality improvement. New York: Springer-Verlag; 1998.",
          "cites": null
        },
        {
          "id": 31548494,
          "title": "Cusum charts for monitoring an autocorrelated process.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Lu C, Renyolds MR. Cusum charts for monitoring an autocorrelated process. Journal of Quality Technology. 2001:33:316\u201334.",
          "cites": null
        },
        {
          "id": 31548488,
          "title": "Disease Control and Prevention. Framework for evaluating public health surveillance systems for early detection of outbreaks; recommendations from the CDC Working Group. MMWR Recomm Rep.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Centers for Disease Control and Prevention. Framework for evaluating public health surveillance systems for early detection of outbreaks; recommendations from the CDC Working Group. MMWR Recomm Rep. 2004;53(No. RR-5).",
          "cites": null
        },
        {
          "id": 31548457,
          "title": "Disease Control and Prevention. Notice to readers: ongoing investigation of anthrax\u2014Florida,",
          "authors": [],
          "date": "2001",
          "doi": null,
          "raw": "Centers for Disease Control and Prevention. Notice to readers: ongoing investigation of anthrax\u2014Florida, October 2001. MMWR Morb Mortal Wkly Rep. 2001;50:877.",
          "cites": null
        },
        {
          "id": 31548486,
          "title": "Early statistical detection of anthrax outbreaks by tracking over-the-counter medication sales.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Goldenberg A, Shmueli G, Caruana R, Fienberg S. Early statistical detection of anthrax outbreaks by tracking over-the-counter medication sales. Proc Natl Acad Sci U S A. 2002;99:5237\u201340.",
          "cites": null
        },
        {
          "id": 31548495,
          "title": "Influenza surveillance in England and Wales using routine statistics.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Tillett HE, Spencer IL. Influenza surveillance in England and Wales using routine statistics. Journal of Hygiene. 1982:88:83\u201394.",
          "cites": null
        },
        {
          "id": 31548496,
          "title": "Quality control: an application of the CUSUM.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Williams SM, Parry BR, Schlup MMT. Quality control: an application of the CUSUM. BMJ. 1992:304:1359\u201361.",
          "cites": null
        },
        {
          "id": 31548493,
          "title": "Statistical Analysis System. SAS PC and enterprise guide, version 8.0 and 1.2. Cary (NC):",
          "authors": [],
          "date": "2000",
          "doi": null,
          "raw": "Statistical Analysis System. SAS PC and enterprise guide, version 8.0 and 1.2. Cary (NC): SAS Institute; 2000.",
          "cites": null
        },
        {
          "id": 31548475,
          "title": "Syndromic analysis of computerized emergency department patients\u2019 chief complaints: an opportunity for bioterrorism and influenza surveillance. Ann Emerg Med.",
          "authors": [],
          "date": "2003",
          "doi": null,
          "raw": "Irvin CB, Nouhan PP, Rice K. Syndromic analysis of computerized emergency department patients\u2019 chief complaints: an opportunity for bioterrorism and influenza surveillance. Ann Emerg Med. 2003;41:8:447\u201352.",
          "cites": null
        },
        {
          "id": 31548476,
          "title": "Syndromic surveillance using automated collection of computerized discharge diagnosis. J Urban Health. 2003;80(2 Suppl 1):i97\u2013106.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Lober WB, Trigg LJ, Karras BT, Bliss D, Ciliberti J, Duchin JS, et al. Syndromic surveillance using automated collection of computerized discharge diagnosis. J Urban Health. 2003;80(2 Suppl 1):i97\u2013106.",
          "cites": null
        },
        {
          "id": 31548482,
          "title": "Syndromic surveillance using minimum transfer of identifiable data: the example of the National Bioterrorism Syndromic Surveillance Demonstration Program. J Urban Health. 2003;80(2 Suppl 1):i25\u201331.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Platt R, Bocchino C, Caldwell B, Harmon R, Kleinman K, Ritzwoller DP, et al. Syndromic surveillance using minimum transfer of identifiable data: the example of the National Bioterrorism Syndromic Surveillance Demonstration Program. J Urban Health. 2003;80(2 Suppl 1):i25\u201331.",
          "cites": null
        },
        {
          "id": 31548489,
          "title": "Technical description of RODS: a real-time public health surveillance system.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Tsui, FC, Espino JU, Dato VM, Gesteland PH, Hutman J, Wagner M. Technical description of RODS: a real-time public health surveillance system. J Am Med Inform Assoc. 2003;10:399\u2013408.",
          "cites": null
        },
        {
          "id": 31548498,
          "title": "The design and use of V-Mask control schemes.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Lucas JM. The design and use of V-Mask control schemes. Journal of Quality Technology. 1976:8:1\u201312.",
          "cites": null
        },
        {
          "id": 31548460,
          "title": "The emerging science of very early detection of disease outbreaks.",
          "authors": [],
          "date": null,
          "doi": null,
          "raw": "Wagner M, Tsui F-C, Espino J, Dato V, Sitting D, Carucana R, et al. The emerging science of very early detection of disease outbreaks. Journal of Public Health Management and Practice. 2001;7:50\u20138.",
          "cites": null
        },
        {
          "id": 31548505,
          "title": "The Sverdlovsk anthrax outbreak of",
          "authors": [],
          "date": "1979",
          "doi": null,
          "raw": "Meselson M, Guillemin J, Hugh-Jones M, Langmuir A, Popova I, Shelokov A, et al. The Sverdlovsk anthrax outbreak of 1979. Science. 1994;266:1202\u20137.",
          "cites": null
        },
        {
          "id": 31548478,
          "title": "Use of ambulance dispatch data as an early warning system for communitywide influenza-like illness,",
          "authors": [],
          "date": "2003",
          "doi": null,
          "raw": "Mostashari F, Fine A, Das D, Adams J, Layton M. Use of ambulance dispatch data as an early warning system for communitywide influenza-like illness, New York City. J Urban Health. 2003;80(2 Suppl 1):i43\u20139.",
          "cites": null
        },
        {
          "id": 31548459,
          "title": "Use of automated ambulatory-care encounter records for detection of acute illness clusters, including potential bioterrorism events. Emerg Infect Dis [serial on the Internet].",
          "authors": [],
          "date": "2002",
          "doi": null,
          "raw": "Lazarus R, Kleinman K, Dashevsky I, Adams C, Kludt P, DeMaria A Jr, et al. Use of automated ambulatory-care encounter records for detection of acute illness clusters, including potential bioterrorism events. Emerg Infect Dis [serial on the Internet]. 2002 Aug. Available from http://www.cdc.gov/ncidod/EID/vol8no8/02-0239.htm",
          "cites": null
        },
        {
          "id": 31548506,
          "title": "Using automated medical records for rapid identification of illness syndromes (syndromic surveillance): the example of lower respiratory infection. BMC Public Health. 2001;1:9. Epub",
          "authors": [],
          "date": "2001",
          "doi": null,
          "raw": "Lazarus R, Kleinman KP, Dashevsky I, DeMaria A, Platt R. Using automated medical records for rapid identification of illness syndromes (syndromic surveillance): the example of lower respiratory infection. BMC Public Health. 2001;1:9. Epub 2001 Oct 22. Address for correspondence: Benjamin D. Miller, University of Minnesota Department of Health, 717 Delaware St. SE, Minneapolis, MN 55414, USA; fax: 612-676-5743; email: Benjamin.miller@ health.state.mn.us Emerging Infectious Diseases \u2022 www.cdc.gov/eid \u2022 Vol. 10, No. 10, October 2004 1811 Syndromic Surveillance for Influenzalike Illness Use of trade names is for identification only and does not imply endorsement by the Public Health Service or by the U.S. Department of Health and Human Services.",
          "cites": null
        },
        {
          "id": 31548497,
          "title": "Using laboratory-based surveillance data for prevention: an algorithm for detecting Salmonella outbreaks. Emerg Infect Dis [serial on the Internet].",
          "authors": [],
          "date": "1997",
          "doi": null,
          "raw": "Hutwagner LC, Maloney EK, Bean NH, Slutsker L, Martin SM. Using laboratory-based surveillance data for prevention: an algorithm for detecting Salmonella outbreaks. Emerg Infect Dis [serial on the Internet]. 1997 Jul-Sep 3. Available from http://www.cdc.gov/ncidod/eid/vol3/no3/hutwagnr.htm",
          "cites": null
        },
        {
          "id": 31548487,
          "title": "Using nurse hot line calls for disease surveillance. Emerg Infect Dis [serial on the Internet]. [cited",
          "authors": [],
          "date": "1998",
          "doi": null,
          "raw": "Rodman J, Frost F, Jakubowski W. Using nurse hot line calls for disease surveillance. Emerg Infect Dis [serial on the Internet]. [cited 1998 Apr-Jun]. Available from http://www.cdc.gov/ncidod/eid/ vol4no2/rodman.htm",
          "cites": null
        },
        {
          "id": 31548462,
          "title": "Using volumebased surveillance for an outbreak early warning system. Acad Emerg Med.",
          "authors": [],
          "date": "2001",
          "doi": null,
          "raw": "K, Gunn J, Barry M, McKenna V, Dyer K, Sulis C. Using volumebased surveillance for an outbreak early warning system. Acad Emerg Med. 2001;8:492.",
          "cites": null
        }
      ],
      "sourceFulltextUrls": [
        "http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3323280"
      ],
      "updatedDate": "2021-06-26T08:20:23",
      "yearPublished": 2004,
      "journals": [
        {
          "title": "Emerging Infectious Diseases",
          "identifiers": [
            "issn:1080-6040",
            "1080-6040",
            "issn:1080-6059",
            "1080-6059"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/pdf/8708595.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/8708595"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/8708595/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/8708595/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/4042490"
        }
      ]
    },
    {
      "acceptedDate": "2016-06-18T00:00:00",
      "arxivId": null,
      "authors": [
        {
          "name": "Chuchu Ye"
        },
        {
          "name": "David L. Buckeridge"
        },
        {
          "name": "Dinglun Zhou"
        },
        {
          "name": "Honglong Zhang"
        },
        {
          "name": "Qiao Sun"
        },
        {
          "name": "Shengjie Lai"
        },
        {
          "name": "Weiping Zhu"
        },
        {
          "name": "Weizhong Yang"
        },
        {
          "name": "Yajia Lan"
        },
        {
          "name": "Yifei Fu"
        },
        {
          "name": "Zhongjie Li"
        }
      ],
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/81078684"
      ],
      "createdDate": "2017-04-28T11:59:41",
      "dataProviders": [
        {
          "id": 2612,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/2612",
          "logo": "https://api.core.ac.uk/data-providers/2612/logo"
        }
      ],
      "depositedDate": "2016-06-18T00:00:00",
      "abstract": null,
      "documentType": "research",
      "doi": "10.1186/s13104-016-2098-z",
      "downloadUrl": "https://core.ac.uk/download/pdf/81078684.pdf",
      "fieldOfStudy": "medicine",
      "fullText": "Ye et al. BMC Res Notes  (2016) 9:315 \nDOI 10.1186/s13104-016-2098-z\nRESEARCH ARTICLE\nSCM: a practical tool to\u00a0implement \nhospital-based syndromic surveillance\nChuchu Ye1\u2020, Zhongjie Li2\u2020, Yifei Fu1, Yajia Lan3, Weiping Zhu1, Dinglun Zhou3, Honglong Zhang2, \nShengjie Lai2,4, David L. Buckeridge5, Qiao Sun1* and Weizhong Yang2*\nAbstract \nBackground: Syndromic surveillance has been widely used for the early warning of infectious disease outbreaks, \nespecially in mass gatherings, but the collection of electronic data on symptoms in hospitals is one of the funda-\nmental challenges that must be overcome during operating a syndromic surveillance system. The objective of our \nstudy is to describe and evaluate the implementation of a symptom-clicking-module (SCM) as a part of the enhanced \nhospital-based syndromic surveillance during the 41st World Exposition in Shanghai, China, 2010.\nMethods: The SCM, including 25 targeted symptoms, was embedded in the sentinels\u2019 Hospital Information Systems \n(HIS). The clinicians used SCM to record these information of all the visiting patients, and data were collated and \ntransmitted automatically in daily batches. The symptoms were categorized into seven targeted syndromes using pre-\ndefined criteria, and statistical algorithms were applied to detect temporal aberrations in the data series.\nResults: SCM was deployed successfully in each sentinel hospital and was operated during the 184-day surveillance \nperiod. A total of 1,730,797 patient encounters were recorded by SCM, and 6.1 % (105,352 visits) met the criteria of \nthe seven targeted syndromes. Acute respiratory and gastrointestinal syndromes were reported most frequently, \naccounted for 92.1 % of reports in all syndromes, and the aggregated time-series presented an obvious day-of-week \nvariation over the study period. In total, 191 aberration signals were triggered, and none of them were identified as \noutbreaks after verification and field investigation.\nConclusions: SCM has acted as a practical tool for recording symptoms in the hospital-based enhanced syndromic \nsurveillance system during the 41st World Exposition in Shanghai, in the context of without a preexisting electronic \ntool to collect syndromic data in the HIS of the sentinel hospitals.\nKeywords: Syndromic surveillance, Infectious disease, Mass gatherings, Early warning, Outbreak detection\n\u00a9 2016 The Author(s). This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, \nand indicate if changes were made. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/\npublicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.\nBackground\nSurveillance systems play a fundamental role on the mon-\nitoring and detecting outbreaks of infectious diseases. \nSyndromic surveillance, or the use of near \u201creal-time\u201d \npre-diagnostic data and automated tools to detect and \ncharacterize unusual activity for further public health \ninvestigation, has been adopted in many countries to \naugment traditional surveillance for nearly two decades \n[1\u20133]. Syndromic surveillance systems usually employ \nstatistical algorithms to inspect unexpected changes in \nprodromic or pre-diagnostic data captured in electronic \nsystems from a variety of sources, with the premise that \naberrations in these data may provide an earlier indi-\ncation of a disease outbreak before the change can be \nobserved in confirmed diagnoses [4, 5]. Among the mul-\ntiple sources of pre-diagnostic data (such as emergency \ndepartment visits, ambulance trip logs, pharmacy sales, \nand work or school absentee rates), pre-diagnostic clini-\ncal syndromes among patients visiting hospitals are fre-\nquently used as a data source in syndromic surveillance \nsystems [6\u20138]. As syndromic surveillance is expected to \nOpen Access\nBMC Research Notes\n*Correspondence:  qsun@pdcdc.sh.cn; ywz126@vip.sina.com \n\u2020ChuchuYe and Zhongjie Li contributed equally to this work \n1 Research Base of Key Laboratory of Surveillance and Early-warning \non Infectious Disease in China CDC, Shanghai Pudong New Area Center \nfor Disease Control and Prevention, Shanghai, China\n2 Key Laboratory of Surveillance and Early-warning on Infectious Disease, \nChinese Center for Disease Control and Prevention, Beijing, China\nFull list of author information is available at the end of the article\nPage 2 of 9Ye et al. BMC Res Notes  (2016) 9:315 \ndetect an epidemic at a very early stage, the timely col-\nlection, collation and analysis of a large amount of syn-\ndrome data are key system components.\nIn most existing syndromic surveillance systems, a \ncommon strategy of obtaining data from hospitals is to \nautomatically collect the chief complaints of patients \nand to classify the data into syndromic categories using \nstandard codes or by natural language processing [9\u201311].\nSyndromic surveillance, however, faces huge challenge \nwhile the chief complaints have not been documented \nelectronically in the hospitals, which had been encoun-\ntered in Pudong New Area, Shanghai. The most of the \nhospitals in Pudong have an electric hospital informa-\ntion system (HIS) to record medical information. When \na patient visits a hospital, a social insurance card or a \nprovisional electronic card must be presented at the \nreception counter. Basic demographic information about \nthe patient is recorded in the HIS, such as gender, date \nof birth, address and historical medical record. The HIS \nthen generates a patient ID number, which is unique for \nthe visit, and the patient is subsequently seen by a doc-\ntor. Information on the patient can be tracked by the ID \nnumber, which can be used to access the HIS record, \nincluding lab test orders, test results, prescriptions, \nand diagnoses. However, the fundamental information \nfor syndromic surveillance-the chief complaints of the \npatient, are not routinely collected in HIS, as it is practi-\ncally recorded on paper at the stage of triage.\nThe 41st World Exposition was held in Shanghai city, \nChina, from May 1st to October 31st, 2010. It has been \nthe largest exposition in the history, with more than 73 \nmillion visitors from approximately 240 countries and \norganizations. A large flow of international visitors might \npose a potential public health risk of disease importation, \nas infectious disease transmission can be promoted by \nan increasing population flow and density or by the acci-\ndental or deliberate introduction of unusual pathogens. \nPudong New Area is the largest district of Shanghai city, \ncontaining 5.4 million residents and approximately 60\u00a0% \nareas of the World Exposition sites. A routine notifiable \ninfectious disease reporting system has been used, which \nonly collected information of specific kinds of infectious \ndisease diagnosed by the clinicians. To enhance the sen-\nsitivity and timeliness of disease outbreaks detection dur-\ning the Expo, a syndromic surveillance and early warning \nsystem, Pudong Syndromic surveillance and Early Warn-\ning System (PD-SEWS), was implemented in this district.\nTo allow automated electronic access to chief com-\nplaints for PD-SEWS in the 41st World Exposition held \nin Shanghai in 2010, we have piloted to introduce a \nnovel approach, the symptom-clicking-module (SCM), \nto gather syndrome data from hospitals, thereby ena-\nbling implementation of syndromic surveillance. Here, \nwe describe how SCM operated, and present the main \nresults of targeted syndromes, and compare the patterns \nof data among different levels of hospitals, as well as the \nday-of-week effect.\nMethods\nSurveillance sentinels and\u00a0targeted syndromes\nTwenty-one hospitals were selected as sentinel sites for \nPD-SEWS, including two tertiary hospitals, five second-\nary hospitals and fourteen primary hospitals. Hospitals \nwere chosen according to their location, catchment area, \nand patient volume [12]. In Pudong, a primary hospital \nis the smallest category of healthcare facility, provid-\ning primary medical services such as medical treatment, \nprevention, healthcare, and rehabilitation for a commu-\nnity with a population of <100,000 persons. The second-\nary hospitals provide general medical services, including \nmedical treatment, prevention, healthcare, and reha-\nbilitation for larger communities (population >100,000 \npersons). The tertiary hospitals are regional healthcare \ncenters providing specialized, high-complexity health-\ncare services for several districts. Most of the sentinel \nsites were closed to the Exposition venue, where was \nalso the part of Pudong with highest population density \n(Fig.\u00a01).\nThe concerning diseases during mass gatherings and \ntheir typical symptoms were listed according to litera-\nture review, and Delphi method was employed to con-\nsult 18 domestic epidemiologic and clinical professionals \nto score the disease severity, risk probabilities. Then a \ndisease-risk matrix was draw and 40 diseases were pri-\noritized in the surveillance, including local common \ndiseases and some highly concerned diseases of importa-\ntion. The 25 most common and typical symptoms of the \nFig. 1 The geographic location of sentinel hospitals at three different \nlevels in Pudong New Area, Shanghai, China, 2010\nPage 3 of 9Ye et al. BMC Res Notes  (2016) 9:315 \ntargeted diseases were enrolled and classified to seven \ntargeted syndromes: acute respiratory, acute gastroin-\ntestinal, rash with fever, neurological syndrome, hem-\norrhagic fever, botulism-like syndrome and acute viral \nhepatitis (Table\u00a01).\nData collection and\u00a0transmission\nThe SCM was developed and embedded in the HIS for \neach sentinel hospital, with the 25 symptoms presented \non the SCM interface as a 5\u00a0 \u00d7\u00a0 5 table which could be \nselected by single click on the screen (Fig.\u00a02). In addition, \nwe included an extra column to facilitate data entry and \nimprove data quality. If no symptoms in a row were pre-\nsented, the \u2018none of the left\u2019 could be clicked. A clinician \ncould therefore check each row of the table quickly. For \nexample, if a patient described the chief complaint as \n\u2018fever and cough\u2019, the clinician should click \u2018fever\u2019 in the \nfirst row and \u2018cough\u2019 in the second, as well as \u2018none of \nthe left\u2019 for the other three rows. Clinicians were pre-\nvented from moving to the next step of treatment (such \nas prescribing a medication) until they finished recording \nsymptoms by clicking the \u2018save\u2019 button (Fig.\u00a03).\nA record of symptoms in SCM was generated with a \nunique identity (ID) number and the basic demographic \ninformation registered in HIS. All data were stored in \nreal time and transmitted automatically to the Pudong \nPublic Health Database Center each day. A virtual pri-\nvate network (VPN) was used to connect securely with \nsentinel hospitals, and all data were supplied and ana-\nlyzed in an anonymous format, without access to per-\nsonal identifying information. For improving the data \nquality, duplicated records were rejected by checking the \nunique ID number, and if the data were not received from \na sentinel site, the Public Health Database Center would \nsend a notice to that hospital at 08:00 a.m. the next day. \nOnce the database center received the surveillance data, \nall of the patient records were automatically grouped \nand aggregated into the seven syndromes according to \nthe criteria listed in Table\u00a0 1. If one patient\u2019s symptoms \nreferred to more than one syndrome, then the encounter \nwould be counted separately for each syndrome.\nData analysis and\u00a0aberration detection\nWe developed an interface connecting to the Pudong \nPublic Health Database Center. The interface allowed \nauthorized users to generate customized time series of \ntotal visits for each syndrome stratified by gender, age, \nsyndrome, hospital, start dates and end dates. The cumu-\nlative sum (CUSUM) method, a control chart method \ncommonly used in syndromic surveillance [4, 13], was \napplied daily to analyze the aggregated data of all sentinel \nTable 1 The seven syndromes under\u00a0 surveillance in\u00a0 the \n41st exposition, Pudong New Area, Shanghai City, China, \n2010\nSyndrome Typical symptoms\nAcute respiratory syndrome Fever with at least one of the following: \ncough, sputum, hemoptysis, chest pain, \nbreathing difficulties\nAcute gastrointestinal \nsyndrome\nFever with at least one of the following: \nvomiting, diarrhea, pus/mucus in stool\nRash with fever Fever with at least one of the following: \nherpes, maculopapular rash\nNeurological syndrome Fever with at least one of the following: \nheadache, projectile vomiting, shock, \naltered consciousness, sudden body \npain\nHemorrhagic fever Fever with at least one of the following: \nskin or mucous congestion, petechiae, \nbleeding, bloody stool\nBotulism-like syndrome At least one of the following: sudden \nblurred vision, dysphagia\nAcute viral hepatitis At least one of the following: hepatosple-\nnomegaly, acute jaundice, lymphad-\nenopathy\nFig. 2 User interface of the symptom-clicking-module of PD-SEWS, Shanghai, China, 2010. All English words in the SCM were translated from \nChinese words\nPage 4 of 9Ye et al. BMC Res Notes  (2016) 9:315 \nhospitals for detecting abnormal temporal increases [14]. \nFor each targeted syndrome, CUSUM compared the pro-\nportion of syndrome counts in total visits in the current \nday (day 0) with the corresponding mean proportion and \nstandard deviation of the past 7\u00a0days (day-7 to day-1). A \nsignal was generated if the value of comparison exceeded \ntwo standard deviations.\nThe surveillance and response team of Pudong Center \nfor Disease Control and prevention (Pudong CDC) \nwould monitor the warning signals routinely. When \na signal was triggered, the verification would be con-\nducted immediately by analyzing and reviewing the data \nto identify any unusual cluster of gender, age, occupa-\ntion or hospital. Some signals would be verified and \ncompared with the data in the routine notifiable dis-\nease reporting system, which recorded the confirmed \npatients\u2019 detailed information. Potential epidemic asso-\nciation would be explored by calling the clinicians or \npatients. If the signal indicated a potential outbreak, \nfield investigation would be performed to obtain more \ndetailed epidemiological information and necessary \ncontrol measures would be conducted to prevent fur-\nther spread of the disease. Outbreak is defined as the \noccurrence of cases of disease in excess of what would \nnormally be expected in a defined geographical area \nand period, which was further quantitatively defined for \neach kind of disease in this study, so as to facilitate the \noutbreak confirmation and report. For example, an out-\nbreak of hand, foot and mouth (HFM) disease is defined \nas \u201cwithin 1\u00a0week, at least five HFM disease cases occur \nin the same setting-e.g. kindergarten or school-or at \nleast three cases of the disease occur in the same village \nor community\u201d [15].\nIn this study, the number of outpatients, the reporting \nfrequency and the proportion of each syndrome were \ncalculated. The average reporting frequencies of different \nFig. 3 Framework of syndromic surveillance in Pudong New Area, Shanghai, China, 2010\nPage 5 of 9Ye et al. BMC Res Notes  (2016) 9:315 \nsyndromes between weekdays and weekends were com-\npared using a Chi square test, and a P value <0.05 was \nconsidered to be statistically significant.\nPreparation for\u00a0system operation\nA series of training sessions on the system were con-\nducted for the clinicians in the sentinel hospitals before \nthe practical operation. This approach helped to ensure \nthat the clinicians would be familiar with SCM in HIS. \nThe estimated average time cost of recording a patient\u2019s \nsyndrome by SCM was 10\u00a0s, according to our field inves-\ntigation in the last week of the training. A pilot surveil-\nlance operation was conducted 2\u00a0weeks before the formal \nrunning of this syndromic surveillance system, and the \nstaff from Pudong CDC went to all the 21 sentinel hos-\npitals during this pilot period to provide help if needed.\nResults\nDuring the surveillance period (184\u00a0 days) from May \n1, 2010 to October 31, 2010, totally 1,730,797 patient \nencounters were collected through the SCM. Of these \nencounters, 105,352 (6.1\u00a0 %) were classified into the \nseven targeted syndromes under surveillance. The most \nfrequent syndromes were acute respiratory syndrome \n(59,793 encounters) and acute gastrointestinal syndrome \n(45,634 encounters), which together accounted for 92.1\u00a0% \nof total visitors in the seven targeted syndromes. Botu-\nlism-like syndrome and hemorrhagic fever syndrome had \nthe lowest frequencies, with only 187 and 131 encoun-\nters, respectively. Encounters classified as acute respira-\ntory, acute gastrointestinal, and neurological syndromes \nwere reported every day, whereas the other syndromes \n(including rash with fever, acute viral hepatitis, botulism-\nlike syndrome and hemorrhagic fever) were not found \nfrom 7 to 122\u00a0days during surveillance period (Table\u00a02).\nThe reporting frequencies for different syndromes var-\nied with the day of the week. Except for hemorrhagic \nfever, the frequency of all other six surveillance syndromes \nwere higher on the weekdays than that in weekends, but \nthe variation was only significant for acute gastrointesti-\nnal syndrome and acute viral hepatitis (Fig.\u00a04). Addition-\nally, in terms of the average reporting frequency of each \nsyndrome across the sentinel hospitals, we found that the \ntertiary and secondary hospitals overall contributed much \nmore than the primary hospitals, and the differences var-\nied with syndromes. For rash with fever syndrome, the \naverage reporting number in the tertiary hospitals was \n151 times of that in the primary ones. However, for acute \nviral hepatitis syndrome, the average reporting numbers \nin the three levels of hospital were closer (Table\u00a03).\nDuring the surveillance period, the CUSUM triggered \n191 signals, including 44 signals for acute respiratory \nsyndrome, 41 signals for neurological syndrome, and 30 \nsignals for acute gastrointestinal syndrome, and rash with \nfever syndrome, botulism-like syndrome, hemorrhagic \nfever and acute viral hepatitis had 22, 22, 17 and 15 sig-\nnals respectively. All of the signals had been verified, and \nfield investigation and control measures had been con-\nducted if a signal seemed to lead to an outbreak. Finally, \nnone of the signals were confirmed as outbreaks. Mean-\nwhile, there was no infectious disease outbreak or public \nhealth emergency was confirmed and reported by local \nCDC through the other routine surveillance system dur-\ning the same period.\nDiscussion\nThe SCM was implemented successfully and operated \nfor a surveillance period lasting 184\u00a0 days in Expo 2010, \nwhich made it feasible to collect syndromic data and \nclassify syndromes which was lacking in the HIS of sen-\ntinel hospitals. Approximately 6\u00a0% of patient encounters \nwere classified into the seven surveillance syndromes, \nwith the number of patients ranged from 131 in hemor-\nrhagic fever syndrome to 59,793 in acute respiratory syn-\ndrome. Frequency of reporting varied by days of week \nfor some syndromes, and the secondary and tertiary \nTable 2 Descriptive statistics of\u00a0visit counts for\u00a0the seven syndromes in\u00a0PD-SEWS, Shanghai, China, May 1st to\u00a0Oct 31st, \n2010\nQ1 first quartile value; Q3 third quartile value\nSyndrome Overall \nvisits\nProportion \nof\u00a0the total \nvisits (%)\nMean \nvisits \nper\u00a0day\nMinimum \nvisits \nper\u00a0day\nQ1 visits \nper\u00a0day\nMedian \nvisits \nper\u00a0day\nQ3 visits \nper\u00a0day\nMaximum \nvisits \nper\u00a0day\nDays \nwith\u00a0zero \nreporting\nAcute respiratory syndrome 59,793 3.45 325 143 273 310.5 356.5 642 0\nAcute gastrointestinal syndrome 45,634 2.64 248 123 196.8 249 295.8 398 0\nNeurological syndrome 6055 0.35 32.9 9 20 29 41 112 0\nRash with fever 1910 0.11 10.4 0 3.8 7.5 16 40 7\nAcute viral hepatitis 790 0.05 4.3 0 1 3 6 26 25\nBotulism-like syndrome 187 0.01 1 0 0 0 2 13 110\nHemorrhagic fever 131 0.01 0.7 0 0 0 1 7 122\nPage 6 of 9Ye et al. BMC Res Notes  (2016) 9:315 \nhospitals reported the majority of encounters in syn-\ndrome surveillance.\nIn recent years, enhanced surveillance is commonly \nimplemented during mass gatherings [16], and syndro-\nmic surveillance system has been established globally. \nIn some countries, more efforts are needed to improve \ndata collection to make the establishment of syndromic \nsurveillance more easily and cost-effectively [17, 18]. \nThe SCM in this study collated and analyzed syndromic \ndata in a standard format across reporting hospitals, and \nallowed direct and automatic classification of symptoms \ninto syndromes, avoiding to develop additional syndrome \nFig. 4 Box plot of average reporting number of each day of week by syndrome detected by PD-SEWS, Shanghai, China, 2010\nPage 7 of 9Ye et al. BMC Res Notes  (2016) 9:315 \nclassification software [19, 20]. Instead of directly collect-\ning the syndrome data subjectively decided by the clini-\ncians, SCM allowed clinicians to record the raw data of \nsymptoms on a patient, and the system automatically \ngrouped the encounters into corresponding surveillance \nsyndromes using pre-defined syndrome definitions. \nAdditionally, SCM was embedded into the HIS so that all \nthe basic information of the patients could be extracted \nfrom the registration data collected automatically. The \ndesign of SCM saves time during data collection and \nhelps to avoid errors due to manual syndrome classifica-\ntion, which is important and effective because the most \nexisting HIS in China without recording chief complaints \nof patients.\nWe found that acute respiratory and acute gastrointes-\ntinal syndromes were reported most frequently, which \nis consistent with other syndromic surveillance systems \n[21\u201323]. These syndromes cover the symptoms of some \ncommon diseases, such as influenza and viral diarrhea, \nwhich are also the main infectious diseases in Shang-\nhai during the study period. Moreover, the day-of-week \neffect in our data suggests the residents in study area \navoided to seek healthcare during weekend, possibly \nbecause hospitals could provide more medical services \non weekdays. Therefore, the aberration detection algo-\nrithm on the syndromic surveillance system should take \naccount of the day-of-week effect [22].\nThe variation in reporting across the different lev-\nels of hospital was also observed for each syndrome. \nWe found that most of the fever with rash cases were \nreported by one tertiary hospital, which was the big-\ngest children\u2019s hospital in Pudong. Fever with rash syn-\ndrome usually presented among the diseases such as \nmeasles, rubella or chicken pox with high incidences in \nchildren. The primary hospitals reported the least cases \nin all of the syndromes, but the difference seemed much \nsmaller for the acute viral hepatitis syndrome. This dif-\nference is probably because most of the chronic hepatitis \npatients sought medical services at the nearest primary \nhospital. Additionally, the SCM is a new data collection \nmodule embedded into the routine HIS at each hospital, \nand the clinicians might need some time to accustom his \nchange in their routine workflow. The strategy of con-\nducting pilot surveillance is widely adopted by syndro-\nmic surveillance practice during mass gathering, which is \nkey to improve the system\u2019s acceptability and ensure the \ndata quality, which has been also conducted in this study \n[22\u201324].\nIn this study, no one outbreak was confirmed among \nthe 191 signals generated by PD-SEWS during the \nExpo. Each signal, which represented an aberration on \nthe surveillance data, was required to be timely verified \nand investigated by the local staff of Center for Disease \nControl and Prevention, and control measures should be \nconducted rapidly once a signal seemed to lead to an out-\nbreak. That\u2019s the possible reason why no one signal was \nidentified as an outbreak finally. To enhance the routine \nsurveillance system by increasing the sensitive and timely \ndetection of outbreaks was the important objective of \nsyndromic surveillance, as well as to deal with each signal \nbefore it led to a real outbreak. The system would create \na lot of extra work for Public Health Utility, that\u2019s why we \nonly suggested adopting the enhanced syndromic surveil-\nlance system during the specific period, such as holding \nmass gatherings, instead of conducting it as routine work \nafter the Expo.\nThere were some limitations in our study. First, the \ncost-effectiveness of the SCM application was not evalu-\nated systematically, but we performed a pilot investiga-\ntion of the SCM\u2019s usability and acceptability in several \nhospitals at the beginning of the surveillance. In addition, \nwe have not systematically collected and evaluation the \nfeedbacks from the clinicians during the study period. \nNonetheless, according to the data collected by SCM and \nits operating results, it sounds acceptable for physicians \nto use during the special situation of a mass gathering. \nTable 3 Average reporting amount of\u00a0each syndrome per\u00a0hospital by\u00a0levels of\u00a0hospital in\u00a0Pudong New Area, Shanghai, \nChina, 2010\nSyndromes Average reporting amount by\u00a0hospital\u2019s level Ratio of\u00a0primary to\u00a0sec-\nondary and\u00a0tertiary \nhospital (a:b:c)Primary\n(a)\nSecondary\n(b)\nTertiary\n(c)\nAcute respiratory syndrome 707.4 8544.0 3585.0 1:12:5\nAcute gastrointestinal syndrome 756.0 5508.8 3753.0 1:7:5\nNeurological syndrome 63.7 920.6 280.0 1:14:4\nRash with fever 4.4 106.4 658.5 1:24:151\nAcute viral hepatitis 28.4 56.8 54.5 1:2:2\nBotulism-like syndrome 3.3 15.0 33.0 1:5:10\nHemorrhagic fever 3.0 9.2 21.5 1:3:7\nPage 8 of 9Ye et al. BMC Res Notes  (2016) 9:315 \nAnother limitation is that spatial cluster detection was \nnot conducted in our study. Some algorithms such as \nspace\u2013time scan statistic [25] have been applied to detect \nspatial aberration, but SCM without the sufficient geo-\ngraphic information of each patient to conduct this anal-\nysis. Additionally, as the CUSUM method was applied to \nthe aggregated data of all hospitals instead of each single \nsentinel site, this limited the ability to detect small out-\nbreaks. However, as the surveillance data for each senti-\nnel hospital (including three different levels of hospitals) \nwere not stable enough on the time series, which would \nlead to large amount of false alerts if performing the algo-\nrithms on single hospital level. Therefore, taking account \nof the balance between sensitivity and false alarm rate, \nwe applied CUSUM method to the total number of each \nsyndrome, and adopted a relatively lower threshold to \nensure the sensitivity. In addition, the system could auto-\nmatically demonstrate daily time series figure of surveil-\nlance data for each single hospital, which could assist in \nthe local epidemiologist to detect the potential smaller \noutbreak with manual manner.\nConclusions\nSCM has acted as a practical tool for recording symp-\ntoms in the hospital-based enhanced syndromic sur-\nveillance system during the 41st World Exposition in \nShanghai, in the context of without a preexisting elec-\ntronic tool to collect syndromic data in the HIS of the \nsentinel hospitals.\nAbbreviations\nSCM: symptom-clicking-module; HIS: hospital information system; PD-SEWS: \npudong syndromic surveillance and early warning system; FEP: front end pro-\ncessor; PDCDC: Pudong New Area Center for disease control and prevention; \nVPN: virtual private network; CUSUM: cumulative sum.\nAuthors\u2019 contributions\nQS, WY, YL and ZL made substantial contributions to the design of this study. \nCY, ZL, WZ and YF made contributions to acquisition of data, data collection \nsupervision. CY HZ and SL were involved in data analysis, interpretation of \ndata and preparation of the manuscript. CY, ZL, HZ, DZ and DB were involved \nin drafting the manuscript or revising it. All authors read and approved the \nfinal manuscript.\nAuthor details\n1 Research Base of Key Laboratory of Surveillance and Early-warning on Infec-\ntious Disease in China CDC, Shanghai Pudong New Area Center for Disease \nControl and Prevention, Shanghai, China. 2 Key Laboratory of Surveillance \nand Early-warning on Infectious Disease, Chinese Center for Disease Control \nand Prevention, Beijing, China. 3 Research Base of Key Laboratory of Surveil-\nlance and Early-warning on Infectious Disease in China CDC, West China \nSchool of Public Health, Sichuan University, Chengdu, China. 4 Department \nof Geography and Environment, University of Southampton, Southampton, \nUK. 5 McGill University, Montreal, Canada. \nAcknowledgements\nWe thank the clinicians in the sentinel hospitals for their assistance in data \ncollection.\nAvailability of data and materials\nOriginal data are available upon request from the first author.\nCompeting interests\nWe confirm that none of the authors have any competing interests.\nConsent for publication\nNot applicable as the manuscript does not contain any individual persons \ndata.\nEthics approval and consent to participate\nThe surveillance was approved by Shanghai Pudong New Area Center for \nDisease Control and Prevention Review Board. The patient information was \nanonymized and de-identified prior to analysis.\nFunding\nThis study was supported by the Grants from the National Science and \nTechnology Key Projects (No. 2009ZX10004-201, No. 2012ZX10004-201) and \nMinistry of Health, China (No. 201202006).\nThese funding offices had no involvement in the design, data collection \nanalysis, write up and decision for the results to be published.\nReceived: 2 December 2015   Accepted: 23 May 2016\nReferences\n 1. Chretien JP, Burkom HS, Sedyaningsih ER, Larasati RP, Lescano AG, Mun-\ndaca CC, et al. Syndromic surveillance: adapting innovations to develop-\ning settings. PLoS Med. 2008;5(3):e72.\n 2. Wu TS, Shih FY, Yen MY, Wu JS, Lu SW, Chang KC, et al. Establishing a \nnationwide emergency department-based syndromic surveillance \nsystem for better public health responses in Taiwan. Bmc Pub Health. \n2008;8:18.\n 3. Abubakar I, Gautret P, Brunette GW, Blumberg L, Johnson D, Poumerol G, \net al. Global perspectives for prevention of infectious diseases associated \nwith mass gatherings. Lancet Infect Dis. 2012;12(1):66\u201374.\n 4. Yan WR, Nie SF, Xu B, Dong HJ, Palm L, Diwan VK. Establishing a web-\nbased integrated surveillance system for early detection of infectious \ndisease epidemic in rural China: a field experimental study. BMC Med \nInform Decis Mak. 2012;12:4.\n 5. Khan K, McNabb SJ, Memish ZA, Eckhardt R, Hu W, Kossowsky D, et al. \nInfectious disease surveillance and modelling across geographic frontiers \nand scientific specialties. Lancet Infect Dis. 2012;12(3):222\u201330.\n 6. May LS, Griffin BA, Bauers NM, Jain A, Mitchum M, Sikka N, et al. \nEmergency department chief complaint and diagnosis data to detect \ninfluenza-like illness with an electronic medical record. West J Emerg \nMed. 2010;11(1):1\u20139.\n 7. Moore KM, Edgar BL, McGuinness D. Implementation of an auto-\nmated, real-time public health surveillance system linking emergency \ndepartments and health units: rationale and methodology. CJEM. \n2008;10(2):114\u20139.\n 8. Khan K, Freifeld CC, Wang J, Mekaru SR, Kossowsky D, Sonricker AL, et al. \nPreparing for infectious disease threats at mass gatherings: the case of \nthe Vancouver 2010 Olympic Winter Games. CMAJ. 2010;182(6):579\u201383.\n 9. Chapman WW, Christensen LM, Wagner MM, Haug PJ, Ivanov O, Dowl-\ning JN, et al. Classifying free-text triage chief complaints into syndro-\nmic categories with natural language processing. Artif Intell Med. \n2005;33(1):31\u201340.\n 10. South BR, Chapman WW, Delisle S, Shen S, Kalp E, Perl T, et al. Optimiz-\ning A syndromic surveillance text classifier for influenza-like illness: does \ndocument source matter? AMIA Annu Symp Proc. 2008;692\u20136.\n 11. May L, Chretien JP, Pavlin JA. Beyond traditional surveillance: applying \nsyndromic surveillance to developing settings\u2013opportunities and chal-\nlenges. BMC Pub Health. 2009;9:242.\nPage 9 of 9Ye et al. BMC Res Notes  (2016) 9:315 \n\u2022  We accept pre-submission inquiries \n\u2022  Our selector tool helps you to find the most relevant journal\n\u2022  We provide round the clock customer support \n\u2022  Convenient online submission\n\u2022  Thorough peer review\n\u2022  Inclusion in PubMed and all major indexing services \n\u2022  Maximum visibility for your research\nSubmit your manuscript at\nwww.biomedcentral.com/submit\nSubmit your next manuscript to BioMed Central \nand we will help you at every step:\n 12. Wang JF, Reis BY, Hu MG, Christakos G, Yang WZ, Sun Q, et al. Area \ndisease estimation based on sentinel hospital records. PLoS One. \n2011;6(8):e23428.\n 13. Fricker RD Jr, Hegler BL, Dunfee DA. Comparing syndromic surveillance \ndetection methods: EARS\u2019 versus a CUSUM-based methodology. Stat \nMed. 2008;27(17):3407\u201329.\n 14. Rogerson PA, Yamada I. Approaches to syndromic surveillance when \ndata consist of small regional counts. MMWR Morb Mortal Wkly Rep. \n2004;53(Suppl):79\u201385.\n 15. National health and family planning commission of China. Guideline for \nhand, foot and mouth disease outbreaks disposal (2012 edition). 2012. \nhttp://www.nhfpc.gov.cn/zhuzhan/wsbmgz/201304/2455757fe843447c\n8289e1431b20a1a9.shtml. Accessed 18 May 2016.\n 16. Thackway S, Churches T, Fizzell J, Muscatello D, Armstrong P. Should cities \nhosting mass gatherings invest in public health surveillance and plan-\nning? reflections from a decade of mass gatherings in Sydney, Australia. \nBMC Pub Health. 2009;9:324.\n 17. Ding Y, Fei Y, Xu B, Yang J, Yan W, Diwan VK, et al. Measuring costs of data \ncollection at village clinics by village doctors for a syndromic surveil-\nlance system\u2014a cross sectional survey from China. Bmc Health Serv Res. \n2015;15:287.\n 18. Fan Y, Wang Y, Jiang H, Yang W, Yu M, Yan W, et al. Evaluation of outbreak \ndetection performance using multi-stream syndromic surveillance \nfor influenza-like illness in rural Hubei Province, China: a temporal \nsimulation model based on healthcare-seeking behaviors. PLoS One. \n2014;9(11):e112255.\n 19. Lu HM, Chen H, Zeng D, King CC, Shih FY, Wu TS, et al. Multilingual chief \ncomplaint classification for syndromic surveillance: an experiment with \nChinese chief complaints. Int J Med Inform. 2009;78(5):308\u201320.\n 20. Chapman WW, Dowling JN, Wagner MM. Classification of emergency \ndepartment chief complaints into 7 syndromes: a retrospective analysis \nof 527,228 patients. Ann Emerg Med. 2005;46(5):445\u201355.\n 21. Dafni UG, Tsiodras S, Panagiotakos D, Gkolfinopoulou K, Kouvatseas G, \nTsourti Z, et al. Algorithm for statistical detection of peaks\u2013syndromic \nsurveillance system for the Athens 2004 Olympic Games. MMWR Morb \nMortal Wkly Rep. 2004;53(Suppl):86\u201394.\n 22. Meyer N, McMenamin J, Robertson C, Donaghy M, Allardice G, Cooper \nDA. Multi-data source surveillance system to detect a bioterrorism attack \nduring the G8 summit in Scotland. Epidemiol Infect. 2008;136(7):876\u201385.\n 23. Yan W, Palm L, Lu X, Nie S, Xu B, Zhao Q, et al. ISS\u2014an electronic syndro-\nmic surveillance system for infectious disease in rural China. PLoS One. \n2013;8(4):e62749.\n 24. Harcourt SE, Fletcher J, Loveridge P, Bains A, Morbey R, Yeates A, et al. \nDeveloping a new syndromic surveillance system for the London 2012 \nOlympic and Paralympic Games. Epidemiol Infect. 2012;140(12):2152\u20136.\n 25. Nordin JD, Goodman MJ, Kulldorff M, Ritzwoller DP, Abrams AM, Klein-\nman K, et al. Simulated anthrax attacks and syndromic surveillance. \nEmerg Infect Dis. 2005;11(9):1394\u20138.\n",
      "id": 40216850,
      "identifiers": [
        {
          "identifier": "2440482312",
          "type": "MAG_ID"
        },
        {
          "identifier": "81078684",
          "type": "CORE_ID"
        },
        {
          "identifier": "10.1186/s13104-016-2098-z",
          "type": "DOI"
        }
      ],
      "title": "SCM: a practical tool to implement hospital-based syndromic surveillance",
      "magId": "2440482312",
      "oaiIds": [],
      "publishedDate": "2016-01-01T00:00:00",
      "publisher": "Springer Nature",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "file:///data/core-remote/dit/data/Springer-OA/pdf/667/aHR0cDovL2xpbmsuc3ByaW5nZXIuY29tLzEwLjExODYvczEzMTA0LTAxNi0yMDk4LXoucGRm.pdf"
      ],
      "updatedDate": "2017-05-15T12:10:57",
      "yearPublished": 2016,
      "journals": [
        {
          "title": "BMC Research Notes",
          "identifiers": [
            "1756-0500"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/pdf/81078684.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/81078684"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/81078684/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/81078684/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/40216850"
        }
      ]
    },
    {
      "acceptedDate": "2010-11-25T00:00:00",
      "arxivId": null,
      "authors": [
        {
          "name": "Gatton, Michelle L"
        },
        {
          "name": "Pelecanos, Anita M"
        },
        {
          "name": "Ryan, Peter A"
        }
      ],
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/190732789",
        "https://api.core.ac.uk/v3/outputs/202361816",
        "https://api.core.ac.uk/v3/outputs/26310087",
        "https://api.core.ac.uk/v3/outputs/483423736",
        "https://api.core.ac.uk/v3/outputs/146959614"
      ],
      "createdDate": "2012-07-08T14:37:23",
      "dataProviders": [
        {
          "id": 4786,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/4786",
          "logo": "https://api.core.ac.uk/data-providers/4786/logo"
        },
        {
          "id": 2612,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/2612",
          "logo": "https://api.core.ac.uk/data-providers/2612/logo"
        },
        {
          "id": 645,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/645",
          "logo": "https://api.core.ac.uk/data-providers/645/logo"
        },
        {
          "id": 150,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/150",
          "logo": "https://api.core.ac.uk/data-providers/150/logo"
        },
        {
          "id": 3110,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/3110",
          "logo": "https://api.core.ac.uk/data-providers/3110/logo"
        },
        {
          "id": 310,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/310",
          "logo": "https://api.core.ac.uk/data-providers/310/logo"
        }
      ],
      "depositedDate": "2010-11-24T00:00:00",
      "abstract": "<p>Abstract</p> <p>Background</p> <p>Detection of outbreaks is an important part of disease surveillance. Although many algorithms have been designed for detecting outbreaks, few have been specifically assessed against diseases that have distinct seasonal incidence patterns, such as those caused by vector-borne pathogens.</p> <p>Methods</p> <p>We applied five previously reported outbreak detection algorithms to Ross River virus (RRV) disease data (1991-2007) for the four local government areas (LGAs) of Brisbane, Emerald, Redland and Townsville in Queensland, Australia. The methods used were the Early Aberration Reporting System (EARS) C1, C2 and C3 methods, negative binomial cusum (NBC), historical limits method (HLM), Poisson outbreak detection (POD) method and the purely temporal SaTScan analysis. Seasonally-adjusted variants of the NBC and SaTScan methods were developed. Some of the algorithms were applied using a range of parameter values, resulting in 17 variants of the five algorithms.</p> <p>Results</p> <p>The 9,188 RRV disease notifications that occurred in the four selected regions over the study period showed marked seasonality, which adversely affected the performance of some of the outbreak detection algorithms. Most of the methods examined were able to detect the same major events. The exception was the seasonally-adjusted NBC methods that detected an excess of short signals. The NBC, POD and temporal SaTScan algorithms were the only methods that consistently had high true positive rates and low false positive and false negative rates across the four study areas. The timeliness of outbreak signals generated by each method was also compared but there was no consistency across outbreaks and LGAs.</p> <p>Conclusions</p> <p>This study has highlighted several issues associated with applying outbreak detection algorithms to seasonal disease data. In lieu of a true gold standard, a quantitative comparison is difficult and caution should be taken when interpreting the true positives, false positives, sensitivity and specificity.</p",
      "documentType": "",
      "doi": "10.1186/1472-6947-10-74",
      "downloadUrl": "https://core.ac.uk/download/pdf/8501084.pdf",
      "fieldOfStudy": null,
      "fullText": "RESEARCH ARTICLE Open Access\nOutbreak detection algorithms for seasonal\ndisease data: a case study using ross river virus\ndisease\nAnita M Pelecanos\n1, Peter A Ryan\n2, Michelle L Gatton\n1*\nAbstract\nBackground: Detection of outbreaks is an important part of disease surveillance. Although many algorithms have\nbeen designed for detecting outbreaks, few have been specifically assessed against diseases that have distinct\nseasonal incidence patterns, such as those caused by vector-borne pathogens.\nMethods: We applied five previously reported outbreak detection algorithms to Ross River virus (RRV) disease data\n(1991-2007) for the four local government areas (LGAs) of Brisbane, Emerald, Redland and Townsville in\nQueensland, Australia. The methods used were the Early Aberration Reporting System (EARS) C1, C2 and C3\nmethods, negative binomial cusum (NBC), historical limits method (HLM), Poisson outbreak detection (POD)\nmethod and the purely temporal SaTScan analysis. Seasonally-adjusted variants of the NBC and SaTScan methods\nwere developed. Some of the algorithms were applied using a range of parameter values, resulting in 17 variants\nof the five algorithms.\nResults: The 9,188 RRV disease notifications that occurred in the four selected regions over the study period\nshowed marked seasonality, which adversely affected the performance of some of the outbreak detection\nalgorithms. Most of the methods examined were able to detect the same major events. The exception was the\nseasonally-adjusted NBC methods that detected an excess of short signals. The NBC, POD and temporal SaTScan\nalgorithms were the only methods that consistently had high true positive rates and low false positive and false\nnegative rates across the four study areas. The timeliness of outbreak signals generated by each method was also\ncompared but there was no consistency across outbreaks and LGAs.\nConclusions: This study has highlighted several issues associated with applying outbreak detection algorithms to\nseasonal disease data. In lieu of a true gold standard, a quantitative comparison is difficult and caution should be\ntaken when interpreting the true positives, false positives, sensitivity and specificity.\nBackground\nDisease surveillance and outbreak detection are funda-\nmental to the provision of adequate and timely public\nhealth services. There are a multitude of outbreak detec-\ntion algorithms that have been applied to a variety of\ndisease studies at different spatial scales. The United\nKingdom utilises a log-linear regression model via an\nnationwide automated system to detect abnormalities in\nthe occurrence of infectious diseases [1]. Hidden Mar-\nkov Models (HMMs) and Bayesian HMMs have been\nused for influenza epidemic detection [2] and hepatitis\nA disease surveillance respectively [3], while a com-\npound smoothing technique has been applied to Salmo-\nnella and Shigella notification data in Australia [4].\nApplication of space-time scan statistics to hospital\nemergency department visits have been used to antici-\npate disease outbreaks [5]. Other types of outbreak algo-\nrithms include time series methods, mean-regression\nmethods and autoregressive integrated moving average\n(ARIMA) models.\nAlthough many detection algorithms have been\nreported, there are few studies comparing methods,\nespecially using public health data. The extensively used\nEarly Aberration Reporting System (EARS) C1, C2 and\n* Correspondence: michelle.gatton@qimr.edu.au\n1Malaria Drug Resistance and Chemotherapy Laboratory, Queensland\nInstitute of Medical Research, Brisbane, Australia\nFull list of author information is available at the end of the article\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\n\u00a9 2010 Pelecanos et al; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative\nCommons Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and\nreproduction in any medium, provided the original work is properly cited.C3 algorithms have been assessed and compared using\nartificial simulations that mimic public health data [6-8]\nand semi-synthetic disease data [9]. The historical limits\nmethod (HLM) has also been assessed against the EARS\nC1, C2 and C3 methods using simulated data [6]. Wat-\nkins et al. [10] compared the sensitivity and timeliness\nof the EARS C1, C2 and C3 methods and a negative\nbinomial cusum outbreak detection method to detect\naberrations in Ross River virus (RRV) disease in\nWestern Australia.\nMosquito-borne diseases such as malaria, dengue,\nWest Nile virus, RRV disease and chikungunya have a\nstrong seasonal pattern in most regions of the world.\nThis seasonality potentially impacts on the utility of\nsome outbreak detection methodologies, specifically\nwhen the application is to detect aberrations beyond the\nusual seasonal pattern, instead of detecting the start of\nthe season. Here we apply a sub-set of five commonly\nused outbreak detection methodologies to seasonal dis-\nease data, using RRV disease as a case study, and com-\npare the ability of the methods to detect outbreaks\nabove the expected seasonal pattern in cases.\nMethods\nNotification and population data\nRRV disease notification data from January 1991 to\nDecember 2007 was supplied by Queensland Health.\nAccess to this data is restricted and is granted upon\nrequest on a case-by-case basis. The data from January\nto June 1991 were used as historical data only while\nreported data were from July 1991 to June 2007. In\nQueensland, Australia, serologically-confirmed RRV dis-\nease cases must be reported to Queensland Health,\nusually by the pathology testing laboratory. The notifica-\ntion data received for each de-identified patient included\nthe onset week of illness, age (0-29, 30-59 and \u226560\nyears), gender and local government area (LGA) of resi-\ndence. Notification data for patients residing in the\nLGAs of Brisbane, Emerald, Redland and Townsville\nwere selected for this study due to their contrasting\npopulation sizes and disease incidence rates. Patient\ndata were aggregated to represent total notifications by\nweek of onset of illness and LGA.\nAnnual population data for each LGA was obtained\nfrom the Australian Bureau of Statistics [11]. Popula-\ntions were categorised by age and gender to match the\ncategories used in the notification data.\nDefined signal period\nTo have a reference point to compare the methods, we\nestablished a defined signalling period (DSP). The aver-\nage number of notifications for each week was calcu-\nlated and the difference between the actual notifications\nand the average for each week was determined. Because\nthe peak RRV activity does not occur at exactly the\nsame time every year, we allowed the annual notification\ndata to be shifted by a maximum of 2 weeks in either\ndirection and recalculated the difference between the\naverage and shifted data. The optimal shift for each\nyear\u2019s data was determined by minimising the sum of\nsquares for the difference between the weekly notifica-\ntions and the average number of notifications for the\nsame week, using only data from weeks 51 to 27 (peak\ntransmission season) in the sums of squares calculation.\nThe data for the difference between the actual notifica-\ntions (incorporating the optimal shift) and the average\nnotifications formed the basis for defining a DSP. A\nDSP occurred if there were 4 or more consecutive posi-\ntive values (positive difference between the shifted actual\nand average notifications), continuing until a negative\nvalue was encountered. Preliminary investigation\nrevealed that allowing the data to be shifted +/-2 weeks\ndid not affect the number of DSP periods identified,\ninstead impacting only on the timing of the DSP. Incor-\nporation of data shifting sometimes resulted in the DSP\ncommencing 1-3 weeks earlier than corresponding DSPs\nwhere no data shifting procedure was applied.\nAlgorithms were individually compared to the DSP to\ndetermine their ability to detect outbreaks. Each out-\nbreak signal was classified as a true positive (TP) or a\nfalse positive (FP). To classify as a TP, the outbreak sig-\nnal from the algorithm had to overlap with a DSP. If the\nsignal did not overlap with a DSP it was categorised as a\nFP. The percentage of DSPs not detected by each algo-\nrithm, the false negative (FN) rate, was determined\nacross the entire year and also during the main trans-\nmission season (1 December - 30 April; Peak FN).\nOutbreak detection algorithms\nFive different types of outbreak detection algorithms\nwere investigated, and 17 algorithm variants were\napplied prospectively. The algorithms fell into two broad\ncategories; those that used historical data and those that\ndid not. Each method was independently applied to the\ndata for each of the four LGAs. A summary of the para-\nmeters used is contained in Additional file 1 Table S1.\nEARS algorithm\nThe EARS algorithms applied in this analysis were cal-\nculated as previously reported [7]. Using the data from\nthe Brisbane LGA, we explored the effect of altering k,\nan arbitrary constant chosen to explain the variation of\nthe mean of the baseline period. For all other LGAs we\nused k = 3 since this value appeared to adequately\nexplain the variation of the baseline mean without inhi-\nbiting the identification ofm a n yt r u es i g n a l s .A no u t -\nbreak event was declared when the cumulative sum for\na period exceeded the threshold value, h. In the absence\nof any previous data on the optimal value for h, we used\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 2 of 9values from 2 to 15. Since our data had a weekly inter-\nval, both the C2 and C3 algorithms were applied using a\none week guard band (GB), that is, a 1 week gap\nbetween the baseline and the week of investigation. The\nC1 algorithm was applied with no GB (no gap between\nthe baseline and week of investigation). Each of the\nEARS C1, C2 and C3 variants were applied with three\ndifferent baseline periods; 2, 4 and 8 weeks. EARS algo-\nrithms with baselines temporally close to the current\nweek of analysis are not largely influenced by seasonal\neffects [6], and thus were not adjusted for seasonality.\nNegative binomial cusum (NBC)\nThe NBC method (originally proposed in Hawkins &\nOlwell [12]) was developed to reduce the number of\nfalse positives generated by other cusum methods when\napplied to over-dispersed data [10]. We applied this\nalgorithm following the protocol of Watkins et al.[ 1 0 ]\nwith the \u201cout of control mean\u201d set to 3 and signal\nthreshold levels ranging from 2 to 15.\nThe NBC method does not account for seasonality\nand in lieu of published information about the impact of\nseasonality on the detection of outbreaks we conducted\nthe analysis independently using both raw and season-\nally adjusted data. The seasonally-adjusted variant of the\nalgorithm used transformed notification data:\nX\nY\nS i\njm\nj\n* , = ,w h e r eYj, m was the number of notifications\nin week j (j = 1,...,52) of year m (m = 1,...,17), i =5 2\n(m-1)+j,a n dS\nY\nY\nj\nmj m\nmjj m\n=\n=\n==\n1\n17\n1\n4\n1\n17\n1\n17\n1\n2\n\u03a3\n\u03a3\u03a3\n,\n, SS\nS .T h es t a n d a r d\nNBC method was applied using the transformed data,\nwith an out of control mean and outbreak threshold\nlevel of 2.\nHistorical limits method (HLM)\nThe HLM [13] incorporates historical data and accounts\nfor seasonality by design, unlike the cusum methods. An\noutbreak signal occurs when:\nx x 0 1\n2\n\uf06d\n\uf073\n\uf06d\n>+\nwhere x0 is the number of reported cases in the cur-\nrent period and \u03bc and sx are the mean and standard\ndeviation of the historical data. In this study the method\nhas been applied using weekly data from a) three conse-\ncutive periods (the current week, the preceding week\nand the subsequent week) over 5 years of historical data\n(total of 15 data points), and b) from five consecutive\nperiods (the current week plus 2 weeks either side) over\n5 years (25 data points).\nPoisson outbreak detection (POD) method\nThe POD method was applied using the procedure pre-\nviously reported [14]. Since our dataset commenced in\n1991, we started the analysis of outbreaks in 1996 using\n5 years of baseline data. From this point the number of\nyears of baseline data was increased year by year so that\nby 2001 the baseline data set contained 10 years of his-\ntoric data. From 2001 onwards, the preceding 10 years\nof data was used as a baseline. We applied the method\nusing 2-week and 4-week moving windows. An outbreak\nwas declared when the number of notifications exceeded\nthe 95\nth percentile of the Poisson cumulative distribu-\ntion for the current window.\nPurely temporal SaTScan\nSaTScan\u2122 is used for conducting spatial, temporal and\nspace-time analyses and is based on identifying maxi-\nmum likelihood clusters for a scanning window that\nmoves across space and/or time [15]. We used the soft-\nware to conduct a Poisson purely temporal prospective\nanalysis for each LGA to look for temporal windows\nwith high incidence rates. The program was implemen-\nted using weekly time units, a p-value cut-off of 0.05\nwith a maximum temporal cluster size of 60 days. The\nprospective analysis was conducted using the same his-\ntoric data as the POD method.\nTo adjust for seasonality within the SaTScan program,\nwe scaled the population sizes. The factor used to scale\nthe population sizes was dictated by the average inci-\ndence rate for a given week. This average incidence rate\nduring the 17 year study period was calculated for each\nweek of the year, as was the total average incidence (the\naverage of the 52-weekly average incidence rates). The\nscaled populations used in SaTScan were then calcu-\nlated as:\npopulation annual population average incidence for week  i i =\u00d7 ( () ( ) /. total average incidence\nWhen the weekly average incidence was zero, the\nannual population was used since the choice of popula-\ntion was irrelevant. Scaling the weekly populations had\nthe effect of increasing the population during the high\ntransmission season, thereby drawing the incidence rate\ncloser to the average baseline level.\nResults\nOver the study period 35,019 notifications for RRV dis-\nease were reported for the state of Queensland. Of these\nnotifications 9,188 (26.2%) were from people living\nwithin Brisbane, Redland, Emerald and Townsville\nLGAs. These four LGAs represented approximately 32%\nof the Queensland population. Brisbane had the largest\nnumber of notifications along with the largest popula-\ntion (Table 1).\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 3 of 9Parameter selection\nThe EARS algorithms required 3 parameters to be\nspecified: h, k and baseline period. To examine the\nresponsiveness of the EARS C1, C2 and C3 algorithms\nto the values chosen for the baseline period and k,w e\napplied each variant to the data from Brisbane. We\nused h =2 ,a sp r e v i o u s l yr e p o r t e d[ 1 0 ] ,ab a s e l i n e\nperiod of 4 or 8 weeks and 3 \u2264 k \u2264 6 (Table 2). The\nfrequency of miscellaneous signals lasting only 1 or 2\nweeks was higher for all EARs algorithms using the\nshorter 4-week baseline period, compared to the 8-\nweek baseline. Within each algorithm, the frequency\nand duration of signals tended to decrease as k\nincreased (Table 2).\nWe investigated how the alteration of h and k levels in\nthe C2 algorithm affected the number of outbreak sig-\nnals, as well as the timing for the start of the signal.\nThe 4 week baseline was used. Altering the h values\nbetween 2 and 15 and k values between 1 and 5 made\nlittle difference to the number of short (\u22643 week) signals\ndetected (data not shown). The start date of the signal\nwas not noticeably different, although h values greater\nthan 7 tended to delay the start of a signal by one week,\nparticularly when coupled with higher values of k (data\nnot shown).\nThe NBC algorithm was adversely affected by the sea-\nsonality in the data. Using an out of control mean of 2,\nit produced signals at the start of each transmission sea-\nson (data not shown). This problem was reduced by\nusing an out of control mean of 3, however many seaso-\nnal signals were still produced particularly for h = 2 and\nh = 4 (data not shown). To overcome this we developed\na seasonally-adjusted version of the algorithm. This\nadjusted algorithm failed to produce many alert signals\nusing 4 weeks of baseline data, instead requiring a\nlonger baseline period of 8 weeks.\nComparison of methods\nGiven the preliminary analysis that centred on para-\nmeter selection for the Brisbane LGA described above,\n17 variants of the 5 base algorithms were applied to the\nRRV data for Brisbane, Emerald, Redland and Towns-\nville LGAs (Figure 1 and 2). The EARS C3 algorithm\nwas not applied due to its similarity of results with the\nEARS C2 algorithm (Table 2). The EARS C1 and C2\nand NBC algorithms were applied using k =3 .\nEach of the methods examined was typically able to\ndetect the same outbreaks. The exceptions were the sea-\nsonally-adjusted NBC methods that detected many short\nsignals (Figure 1 and 2). The POD algorithm using a 4-\nTable 1 RRV disease notifications (July 1991 - December 2007) and population sizes for Brisbane, Emerald, Redland\nand Townsville, as well as for all of Queensland\nLGA Total Notifications Est. resident popn (1991) Est. resident popn (2007)\nBrisbane 5,189 769,087 992,176\nEmerald 257 9,842 15,364\nRedland 836 82,818 131,332\nTownsville 2,906 86,245 102,020\nQueensland 35,019 2,977,772 4,181,431\nTable 2 Summary of signals generated by EARS C1, C2 and C3 cusum methods\nMethod & parameters No. signals of specified duration Details of signals lasting \u22654 wks\n1 wk 2 wks 3 wks \u22654 wks\nC1 4 wk BL k = 3 5 6 1 5 1992 (wk 5-11), 1996 (3-12), 2003 (10-20), 2004 (4-14), 2007 (38-45)\nC1 4 wk BL k = 4 5 4 0 5 1992 (wk 5-9), 1996 (5-9), 2003 (10-18), 2004 (4-7), 2007 (38-43)\nC2 4 wk BL k = 4 7 5 2 5 1992 (wk 5-13), 1996 (5-14), 2003 (11-25), 2004 (4-17), 2006 (2-7)\nC2 4 wk BL k = 5 7 1 1 4 1992 (wk 5-12), 1996 (5-13), 2003 (11-23), 2004 (4-15)\nC2 4 wk BL k = 6 5 2 1 4 1992 (wk 5-11), 1996 (5-12), 2003 (11-21), 2004 (4-8)\nC3 4 wk BL k = 5 8 1 2 4 1992 (wk 5-12), 1996 (5-12), 2003 (11-15), 2004 (4-15)\nC1 8 wk BL k = 3 6 3 1 3 1992 (wk 5-13), 1996 (5-14), 2003 (11-19)\nC1 8 wk BL k = 4 6 0 0 3 1992 (wk 5-10), 1996 (5-11), 2003 (11-15)\nC2 8 wk BL k = 4 0 4 0 6 1992 (wk 5-15), 1996 (5-18), 2001 (13-16), 2003 (11-21), 2004 (11-14), 2006 (2-8)\nC2 8 wk BL k = 5 1 4 0 3 1992 (wk 5-13), 1996 (5-16), 2003 (11-18)\nC3 8 wk BL k = 4 0 4 0 6 1992 (wk 5-15), 1996 (5-18), 2001 (13-16), 2003 (11-21), 2004 (11-14), 2006 (2-8)\nC3 8 wk BL k = 5 1 4 0 3 1992 (wk 5-13), 1996 (5-16), 2003 (11-18)\nParameter values applied were h = 2 with 4 or 8 weeks of baseline (BL) data and 3 \u2264 k \u2264 6.\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 4 of 9week moving window returned less outbreak periods\nthan its 2-week moving window counterpart, which\ntended to often have several segmented signals instead\no fo n el o n g e rs i g n a l .T h e r ew a sl i t t l ed i f f e r e n c ei nt h e\nnumber of outbreaks detected by the HLM when 15\nweeks of baseline data was used compared to 25 weeks\nof baseline data.\nIn this study, the DSPs were considered to be the\nbenchmark against which the performance of algorithms\nwas compared (Table 3 and 4). Overall, the largest out-\nbreaks tended to be detected by most of the methods\n(Figure 1 and 2). In Emerald, the LGA with the smallest\npopulation and number of notifications, all of the\nmethods had high FN rates ranging from 45% to 100%\n(Table 4). In larger LGAs the peak FN rate was usually\nlower than the FN over the entire year (Table 3 and 4).\nThe NBC, POD and temporal SaTScan algorithms were\nthe only methods that had TP rates >70%, FP (\u22652\nweeks) rates <20% and peak FN rates <20% (Table 3\nand 4), although they did not obtain these results across\nevery LGA.\nThe timing of signals was compared between algo-\nrithms for the two largest outbreaks to occur in each\nLGA after 1995 (Table 5). Overall there was little con-\nsistency between the algorithms that first detected out-\nbreaks. For instance, the HLM method was last to\nFigure 1 Notifications, defined signal periods (DSP) and outbreak alerts for Brisbane and Redland LGAs. Note that the scaling of the\nhorizontal axes for number of notifications differs between subfigures. The grey shaded regions represent the years that no analysis could be\nperformed due to the requirement of 5 years of historical data. HLM-A: HLM (15 wk BL); HLM-B: HLM (25 wk BL); C1-A: C1-4 wk BL (h = 2); C1-B:\nC1-8 wk BL (h = 2); C2-A: C2-4 wk BL (h = 4); C2-B: C2-4 wk BL (h = 6); C2-C: C2-8 wk BL (h = 4); C2-D: C2-8 wk BL (h = 6); NBC-A: NBC-4 wk BL\nno GB (h = 6); NBC-B: NBC-4 wk BL 1 wk GB (h = 6); NBC-C: NBC-8 wk BL no GB (h = 8); NBC-D: NBC-8 wk BL 1 wk GB (h = 8); NBC-E:\nSeasonally-adjusted NBC 8 wk BL 1 wk GB (h = 8); NBC-F: Seasonally-adjusted NBC 8 wk BL 2 wk GB (h = 8); POD-A: Poisson 2 wk Window; POD-\nB: Poisson 4 wk Window.\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 5 of 9detect both outbreaks in Brisbane and the 1996 out-\nbreak in Redland, but first to detect the 2001 outbreak\nin Redland. Similarly the C1 and C2 algorithms detected\nthe 1996 Redland outbreak before the other algorithms,\nbut failed to detect the 1997 outbreak in Townsville and\nthe 2007 outbreak in Emerald.\nDiscussion\nDetection of outbreaks is an important part of disease\nsurveillance for public health. Algorithms for outbreak\ndetection should ideally provide early declarations of\ntrue signals but have low numbers of false positives.\nO n ew a yt oi m p r o v et h ef a l s ep o s i t i v er a t e so fa l g o -\nrithms is to increase the threshold limits. However, by\nraising the threshold, it generally takes longer to detect\nan outbreak [16].\nOur results for the influence of the EARS methods\nparameter choice on outbreak detection using seasonal\ndisease data reflect those previously reported [9,17]. Spe-\ncifically, an increase in k was associated with a decrease\nin the frequency and duration of signals, and a longer\nbaseline period produced fewer short (\u22643 weeks) signals.\nSince an increase in k reflected the need to have larger\ndeviations away from the baseline mean to trigger a sig-\nn a l ,w ef o u n dt h a tu s eo fal a r g e rk made it more diffi-\ncult to detect outbreaks with a slow amplification phase.\nThe underlying seasonality in the data appeared to be\nproblematic for the NBC algorithm, particularly when\nusing an out of control mean of 2. Normalising the data\nto remove the regular seasonality stopped the annual\nsignals associated with the start of the main transmis-\nsion season, but instead produced many short signals.\n\u0003\nFigure 2 Notifications, defined signal periods (DSP) and outbreak alerts for Townsville and Emerald LGAs. Note that the scaling of the\nhorizontal axes for number of notifications differs between subfigures. The grey shaded regions represent the years that no analysis could be\nperformed due to the requirement of 5 years of historical data. Algorithm codes are as outline in Figure 1.\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 6 of 9Table 3 Summary of performance of outbreak detection algorithms for RRV data from Brisbane and Townsville\nMethod LGA\nBrisbane Townsville\nTP FP FN (n = 19) Peak FN (n = 9) TP FP FN (n = 23) Peak FN (n = 11)\nHLM-A 40.0 10.0 54.5 62.5 12.9 19.4 50.0 60.0\n(n = 11) (n = 8) (n = 8) (n = 5)\nHLM-B 42.1 5.3 54.5 50.0 20.0 24.0 50.0 60.0\n(n = 11) (n = 8) (n = 8) (n = 5)\nC1-A 41.2 41.2 68.4 44.4 23.3 37.2 56.5 36.4\nC1-B 46.2 30.8 68.4 44.4 35.0 45.0 69.6 45.5\nC2-A 53.3 33.3 57.9 33.3 36.4 54.6 65.2 36.4\nC2-B 58.3 16.7 63.2 22.2 31.6 36.8 73.9 45.5\nC2-C 60.0 40.0 63.2 22.2 27.8 44.4 73.9 45.5\nC2-D 60.0 30.0 68.4 33.3 41.7 33.3 78.3 54.5\nNBC-A 81.8 9.1 52.6 22.2 57.1 19.1 56.5 18.1\nNBC-B 73.3 13.3 42.1 11.1 57.9 31.6 56.5 18.1\nNBC-C 88.9 11.1 52.6 0.0 57.1 42.9 60.9 18.1\nNBC-D 72.7 27.3 47.4 33.3 53.3 40.0 60.9 18.1\nNBC-E 40.6 34.4 47.4 33.3 44.8 13.8 47.8 36.4\nNBC-F 40.6 37.5 47.4 33.3 46.9 21.9 39.1 27.3\nPOD-A 61.5 23.1 36.4 12.5 69.2 23.1 37.5 0.0\n(n = 11) (n = 8) (n = 8) (n = 5)\nPOD-B 70.0 20.0 36.4 12.5 75.0 25.0 37.5 0.0\n(n = 11) (n = 8) (n = 8) (n = 5)\nSaTScan 62.5 25.0 45.5 25.0 44.4 44.4 50.0 20.0\n(n = 11) (n = 8) (n = 8) (n = 5)\nTrue positive (TP) values represent the percentage of signals that overlapped with a DSP, false positives (FP) are categorised as the percentage of signals lasting\n\u22652 weeks which do not overlap with a DSP, false negatives (FN) are the percentage of all DSPs that were not detected by the algorithm, and peak FN is the\npercentage of DSPs starting between 1 December and 30 April that were not detected by the algorithm. Algorithm codes are the same as detailed in Figure 1.\nTable 4 Summary of performance of outbreak detection algorithms for RRV data from Emerald and Redland\nMethod LGA\nEmerald Redland\nTP FP FN (n = 11) Peak FN (n = 11) TP FP FN (n = 11) Peak FN (n = 8)\nHLM-A 14.3 11.4 60.0 60.0 29.7 2.7 0.0 0.0\n(n = 10) (n = 10) (n = 9) (n = 6)\nHLM-B 14.7 11.8 60.0 60.0 29.0 7.9 0.0 0.0\n(n = 10) (n = 10) (n = 9) (n = 6)\nC1-A 7.4 13.0 63.7 63.7 19.0 10.3 45.5 25.0\nC1-B 18.2 12.1 54.5 54.5 23.1 19.2 54.5 37.5\nC2-A 38.5 30.8 45.5 45.5 33.3 33.3 45.5 25.0\nC2-B 50.0 0.0 63.7 63.7 50.0 16.7 54.5 37.5\nC2-C 33.3 41.7 63.7 63.7 46.7 33.3 36.4 12.5\nC2-D 50.0 0.0 72.7 72.7 44.4 22.2 63.6 50.0\nNBC-A 0.0 0.0 100.0 100.0 100.0 0.0 63.6 50.0\nNBC-B 100.0 0.0 90.9 90.9 87.5 0.0 36.4 12.5\nNBC-C 0.0 0.0 100.0 100.0 100.0 0.0 27.3 0.0\nNBC-D 100.0 0.0 90.9 90.9 88.9 0.0 27.3 0.0\nNBC-E 100.0 0.0 90.9 90.9 20.0 55.0 63.6 75.0\nNBC-F 100.0 0.0 90.9 90.9 23.8 61.9 54.5 62.5\nPOD-A 50.0 0.0 90.0 90.0 87.5 12.5 33.3 16.7\n(n = 10) (n = 10) (n = 9) (n = 6)\nPOD-B 75.0 0.0 70.0 70.0 71.4 14.3 33.3 16.7\n(n = 10) (n = 10) (n = 9) (n = 6)\nSaTScan 44.4 55.6 50.0 50.0 85.7 14.3 22.2 0 (n = 6)\n(n = 10) (n = 10) (n = 9)\nReported values are as per Table 3.\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 7 of 9An alternative approach for adjusting for seasonality\nmay be needed for this algorithm.\nThe HLM algorithm was sensitive to the frequency\nand magnitude of outbreaks detected in the previous 5\nyears. RRV disease outbreaks in Brisbane tended to\noccur at 2-3 year intervals, with the largest outbreaks\noccurring in 1993 and 1996. Because the later part of\nthe study period tended to have smaller and less\nfrequent outbreaks, there was a lack of consistency in\nthe signals produced by the HLM algorithm, relative to\nthe number of notifications in each outbreak. This issue\nwas also apparent in Townsville.\nThe primary aim of this study was to investigate the\nperformance of outbreak detection algorithms applied to\nseasonal data. Comparing the results was problematic,\ns i n c et h i sr e q u i r e dad e f i n i t i o no fat r u eo u t b r e a ko ra\ngold standard. To overcome the subjective nature asso-\nciated with visually identifying outbreaks, we defined the\nDSP and used it to determine the percent of signals that\nw e r eT P ,F Pa n dF N .I ts h o u l db en o t e dt h a tt h eD S P\ndefinition was arbitrary, and although it required four\nweeks or more of above average notifications, there was\nno minimum difference required between the actual and\naverage notifications to define a signal. The four week\ncriterion helped focus this study on outbreaks of public\nhealth importance for a relatively benign endemic mos-\nq u i t o - b o r n ed i s e a s ew i t hn oc urative treatment or vac-\ncine by disregarding outbreak signals of a short duration.\nThis may not be appropriate for other seasonal diseases.\nMost notifications of RRV disease occur during sum-\nmer and autumn (December to April), imitating the\ndynamics of the mosquito vector. Therefore identifica-\ntion of the outbreaks during this period is a higher\npriority than for smaller outbreaks, which occur during\nthe cooler months or at the end of the transmission sea-\nson. In the three largest LGAs examined, the FN rate\nwas generally lower when only outbreaks occurring\nbetween December and April were considered. It is\nlikely that the TP and FP rates will follow a similar pat-\ntern, but this needs to be confirmed. Although we inves-\ntigated the timeliness of each algorithm for the largest\noutbreaks in each LGA, there was no one method that\nconsistently detected the outbreaks first. This may be\ndue to differences in the characteristics of individual\noutbreaks such as rate of increase in notifications or the\nabsolute number of notifications involved.\nThis study has highlighted several issues associated\nwith applying outbreak detection algorithms to seasonal\ndisease data. Outbreaks of significant size were identified\nby most of the algorithms applied. However some algo-\nrithms were prone to short, sporadic signals, particularly\nwhen applied to smaller populations with relatively few\nnotifications. We also noted differences in the ability of\nthe algorithms to detect outbreaks with a slower ampli-\nfication stage compared to explosive outbreaks. This is a\nfeature that may result in some methods working well\non some disease data but not others. In lieu of a true\ngold standard, a quantitative comparison is problemati-\ncal and caution should be used when interpreting TPs,\nFPs, sensitivity and specificity.\nTable 5 Timing of signals for the two largest outbreaks\nin each LGA after 1995\nMethod LGA\nBrisbane Townsville Redland Emerald\n1996 1998/99 1997 2000 1996 2001 1997 2007\nDSP 5-21 50-4 6-20 2-11 7-18 1-15 1-7 5-9\n9-24\nHLM-A 10 ND 12 2-6 14-17 4-8 1-5 6-9\n12-13\n17-21\nHLM-B 10 20 12 2-6 14-17 4-8 1-5 6-9\n12 11\n18-21\nC1-A 3-12 46-47 12 2-8 5-7 5 1-2 ND\n50 9-10\n14\nC1-B 5-14 46-48 ND 2-9 5-11 5 1-5 ND\n50\nC2-A 5-16 47-3 ND 2-15 5-16 5-8 1-4 ND\n7-8\nC2-B 5-15 47-48 ND 2-15 5-7 5-7 1-3 ND\n50-51 9-15\nC2-C 5-21 47-4 ND 2-16 5-16 5-9 1-6 ND\n7-12\nC2-D 5-21 47-48 ND 2-16 5-15 5-8 1-6 ND\n50-3\nNBC-A 5-13 7 4 2-7 ND ND ND ND\n9-12 6-12\nNBC-B 5-15 1-16 4-15 2-8 10-15 5-8 2-3 ND\nNBC-C 5-16 1-17 6-16 2-9 10-16 8 ND ND\nNBC-D 5-17 51-19 6-17 2-11 9-18 6-14 3-5 ND\nNBC-E 6-17 47-7 9-12 2-8 ND ND ND 9-10\nNBC-F 6-20 47-8 9-15 2-9 ND ND ND 9-11\nPOD-A 6-22 1-4 4 2-8 13-18 5-9 2-6 ND\n7 6-10 11-12\n14-21 12-13 14-15\n23 15 17-18\nPOD-B 7-24 1-7 4-15 2-9 14-20 5-15 1-8 ND\n14-23 17-18\n20\nSaTScan 5-24 50-23 6-19 2-12 9-21 4-18 1-11 3-17\nTable entries are the weeks where an outbreak signal occurred, with Week 1\nstarting 1 January each year. ND, none detected.\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 8 of 9Additional material\nAdditional file 1: Parameters used in each algorithm. Summary\ndescription of the historical or baseline data used in each of the\nalgorithms tested, along with information for the threshold values and\nguard bands used for the cusum algorithms.\nAcknowledgements\nThe authors thank Queensland Health for providing the RRV disease data.\nThe study was funded by Program Grant #496601 from the National Health\nand Medical Research Council of Australia. PAR and MLG were supported by\nNHMRC Career Development Awards.\nAuthor details\n1Malaria Drug Resistance and Chemotherapy Laboratory, Queensland\nInstitute of Medical Research, Brisbane, Australia.\n2Mosquito Control\nLaboratory, Queensland Institute of Medical Research, Brisbane, Australia.\nAuthors\u2019 contributions\nAMP implemented the algorithms, analysed the results and drafted the\nmanuscript.\nPAR assisted with interpretation of the results and review of the manuscript.\nMLG designed the study, assisted with reviewing the results and drafted the\nmanuscript.\nAll authors read and approved the final manuscript.\nCompeting interests\nThe authors declare that they have no competing interests.\nReceived: 22 June 2010 Accepted: 24 November 2010\nPublished: 24 November 2010\nReferences\n1. Farrington CP, Andrews NJ, Beale AD, Catchpole MA: A statistical algorithm\nfor the early detection of outbreaks of infectious disease. J R Stat Soc Ser\nA Stat Soc 1996, 159(3):547-563.\n2. Rath TM, Carreras M, Sebastiani P: Automated detection of Influenza\nepidemics with Hidden Markov Models. Lect Notes Comput Sc 2003,\n521-532.\n3. Watkins RE, Eagleeson S, Veenendaal B, Wright G, Plant AJ: Disease\nsurveillance using a hidden Markov model. BMC Med Inform Decis Mak\n2009, 9(39).\n4. Stern L, Lightfoot D: Automated outbreak detection: a quantitative\nretrospective analysis. Epidemiol Infect 1999, 122:103-110.\n5. Kulldorf M, Heffernan R, Hartman J, Assuncao R, Mostashari F: A space-time\npermutation scan statistic for disease outbreak detection. Plos Med 2005,\n2(3):216-224.\n6. Hutwagner L, Browne T, Matthew SG, Fleischauer AT: Comparing\naberration detection methods with simulated data. Emerg Infect Dis 2005,\n11(2):314-316.\n7. Hutwagner LC, Thompson WW, Seeman GM, Treadwell T: A simulation\nmodel for assessing aberration detection methods used in public health\nsurveillance for systems with limited baselines. Stat Med 2005,\n24:543-550.\n8. Fricker RDJ: Comparing syndromic surveillance detection methods: EARS\u2019\nversus a CUSUM-based methodology. Stat Med 2008, 27:3407-3429.\n9. Wang X, Zeng D, Seale H, Li S, Cheng H, Luan R, He X, Pang X, Dou X,\nWang Q: Comparing early outbreak detection algorithms based on their\noptimized parameter value. J Biomed Inform 2009.\n10. Watkins RE, Eagleeson S, Veenendaal B, Wright G, Plant AJ: Applying\ncusum-based methods for the detection of outbreak of Ross River virus\ndisesase in Western Australia. BMC Med Inform Decis Mak 2008, 8(37).\n11. Australian Bureau of Statistics: 3235.0 - Population by age and sex,\nAustralia, 2007. [http://www.abs.gov.au/ausstats/abs@.nsf/DetailsPage/\n3235.02006?OpenDocument].\n12. Hawkins DM, Olwell DH: Cumulative sum charts and charting for quality\nimprovement. New York: Springer-Verlag; 1998.\n13. Stroup DF, Williamson GD, Herndon JL, Karon J: Detection of aberrations\nin the occurrence of notifiable diseases surveillance data. Stat Med 1989,\n8(323-329).\n14. Gatton ML, Kelly-Hope LA, Kay BH, Ryan PA: Spatial-temporal analysis of\nRoss River virus disease pattern in Queensland, Australia. Am J Trop Med\nHyg 2004, 71(5):629-635.\n15. SaTScan: software for the spatial, temporal and space-time scan\nstatistics. [http://www.satscan.org].\n16. Chang WR, McLean IP: CUSUM: a tool for early feedback about\nperformance? BMC Med Res Methodol 2006, 6(8).\n17. Murphy SP, Burkom H: Recombinant temporal aberration detection\nalgorithms for enhanced biosurveillance. J Am Med Inform Assn 2008,\n15(1):77-86.\nPre-publication history\nThe pre-publication history for this paper can be accessed here:\nhttp://www.biomedcentral.com/1472-6947/10/74/prepub\ndoi:10.1186/1472-6947-10-74\nCite this article as: Pelecanos et al.: Outbreak detection algorithms for\nseasonal disease data: a case study using ross river virus disease. BMC\nMedical Informatics and Decision Making 2010 10:74.\nSubmit your next manuscript to BioMed Central\nand take full advantage of: \n\u2022 Convenient online submission\n\u2022 Thorough peer review\n\u2022 No space constraints or color \ufb01gure charges\n\u2022 Immediate publication on acceptance\n\u2022 Inclusion in PubMed, CAS, Scopus and Google Scholar\n\u2022 Research which is freely available for redistribution\nSubmit your manuscript at \nwww.biomedcentral.com/submit\nPelecanos et al. BMC Medical Informatics and Decision Making 2010, 10:74\nhttp://www.biomedcentral.com/1472-6947/10/74\nPage 9 of 9",
      "id": 3874832,
      "identifiers": [
        {
          "identifier": "483423736",
          "type": "CORE_ID"
        },
        {
          "identifier": "146959614",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:pubmedcentral.nih.gov:3004813",
          "type": "OAI_ID"
        },
        {
          "identifier": "oai:eprints.qut.edu.au:75113",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1186/1472-6947-10-74",
          "type": "DOI"
        },
        {
          "identifier": "8501084",
          "type": "CORE_ID"
        },
        {
          "identifier": "26310087",
          "type": "CORE_ID"
        },
        {
          "identifier": "3004813",
          "type": "PUBMED_ID"
        },
        {
          "identifier": "info:doi/10.1186%2f1472-6947-10-74",
          "type": "OAI_ID"
        },
        {
          "identifier": "2014967299",
          "type": "MAG_ID"
        },
        {
          "identifier": "190732789",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:doaj.org/article:9dd068bd4c724073850185440416fd20",
          "type": "OAI_ID"
        },
        {
          "identifier": "202361816",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:eprints.qut.edu.au:217981",
          "type": "OAI_ID"
        }
      ],
      "title": "Outbreak detection algorithms for seasonal disease data: a case study using ross river virus disease",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:doaj.org/article:9dd068bd4c724073850185440416fd20",
        "oai:pubmedcentral.nih.gov:3004813",
        "oai:eprints.qut.edu.au:75113",
        "oai:eprints.qut.edu.au:217981",
        "info:doi/10.1186%2f1472-6947-10-74"
      ],
      "publishedDate": "2010-01-01T00:00:00",
      "publisher": "BioMed Central",
      "pubmedId": "3004813",
      "references": [],
      "sourceFulltextUrls": [
        "http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3004813",
        "file:///data/remote/core/dit/data/Springer-OA/pdf/fc1/aHR0cDovL2xpbmsuc3ByaW5nZXIuY29tLzEwLjExODYvMTQ3Mi02OTQ3LTEwLTc0LnBkZg==.pdf",
        "http://doaj.org/search?source=%7B%22query%22%3A%7B%22bool%22%3A%7B%22must%22%3A%5B%7B%22term%22%3A%7B%22id%22%3A%229dd068bd4c724073850185440416fd20%22%7D%7D%5D%7D%7D%7D",
        "https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/1472-6947-10-74?site=bmcmedinformdecismak.biomedcentral.com",
        "http://creativecommons.org/licenses/by/2.0),"
      ],
      "updatedDate": "2024-06-09T10:02:50",
      "yearPublished": 2010,
      "journals": [
        {
          "title": null,
          "identifiers": [
            "1472-6947",
            "issn:1472-6947"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/pdf/8501084.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/8501084"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/8501084/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/8501084/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/3874832"
        }
      ]
    },
    {
      "arxivId": null,
      "authors": [
        {
          "name": "Buckeridge, David L."
        },
        {
          "name": "Fu, Yifei"
        },
        {
          "name": "Lai, Shengjie"
        },
        {
          "name": "Lan, Yajia"
        },
        {
          "name": "Li, Zhongjie"
        },
        {
          "name": "Sun, Qiao"
        },
        {
          "name": "Yang, Weizhong"
        },
        {
          "name": "Ye, Chuchu"
        },
        {
          "name": "Zhang, Honglong"
        },
        {
          "name": "Zhou, Dinglun"
        },
        {
          "name": "Zhu, Weiping"
        }
      ],
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/46577051"
      ],
      "createdDate": "2016-10-19T17:45:09",
      "dataProviders": [
        {
          "id": 34,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/34",
          "logo": "https://api.core.ac.uk/data-providers/34/logo"
        }
      ],
      "abstract": "Background: syndromic surveillance has been widely used for the early warning of infectious disease outbreaks, especially in mass gatherings, but the collection of electronic data on symptoms in hospitals is one of the fundamental challenges that must be overcome during operating a syndromic surveillance system. The objective of our study is to describe and evaluate the implementation of a symptom-clicking-module (SCM) as a part of the enhanced hospital-based syndromic surveillance during the 41st World Exposition in Shanghai, China, 2010.Methods: the SCM, including 25 targeted symptoms, was embedded in the sentinels\u2019 Hospital Information Systems (HIS). The clinicians used SCM to record these information of all the visiting patients, and data were collated and transmitted automatically in daily batches. The symptoms were categorized into seven targeted syndromes using pre-defined criteria, and statistical algorithms were applied to detect temporal aberrations in the data series.Results: SCM was deployed successfully in each sentinel hospital and was operated during the 184-day surveillance period. A total of 1,730,797 patient encounters were recorded by SCM, and 6.1 % (105,352 visits) met the criteria of the seven targeted syndromes. Acute respiratory and gastrointestinal syndromes were reported most frequently, accounted for 92.1 % of reports in all syndromes, and the aggregated time-series presented an obvious day-of-week variation over the study period. In total, 191 aberration signals were triggered, and none of them were identified as outbreaks after verification and field investigation.Conclusions: SCM has acted as a practical tool for recording symptoms in the hospital-based enhanced syndromic surveillance system during the 41st World Exposition in Shanghai, in the context of without a preexisting electronic tool to collect syndromic data in the HIS of the sentinel hospitals",
      "documentType": "research",
      "doi": "10.1186/s13104-016-2098-z",
      "downloadUrl": "",
      "fieldOfStudy": null,
      "fullText": "Ye et al. BMC Res Notes  (2016) 9:315 DOI 10.1186/s13104-016-2098-zRESEARCH ARTICLESCM: a practical tool to\u00a0implement hospital-based syndromic surveillanceChuchu Ye1\u2020, Zhongjie Li2\u2020, Yifei Fu1, Yajia Lan3, Weiping Zhu1, Dinglun Zhou3, Honglong Zhang2, Shengjie Lai2,4, David L. Buckeridge5, Qiao Sun1* and Weizhong Yang2*Abstract Background: Syndromic surveillance has been widely used for the early warning of infectious disease outbreaks, especially in mass gatherings, but the collection of electronic data on symptoms in hospitals is one of the funda-mental challenges that must be overcome during operating a syndromic surveillance system. The objective of our study is to describe and evaluate the implementation of a symptom-clicking-module (SCM) as a part of the enhanced hospital-based syndromic surveillance during the 41st World Exposition in Shanghai, China, 2010.Methods: The SCM, including 25 targeted symptoms, was embedded in the sentinels\u2019 Hospital Information Systems (HIS). The clinicians used SCM to record these information of all the visiting patients, and data were collated and transmitted automatically in daily batches. The symptoms were categorized into seven targeted syndromes using pre-defined criteria, and statistical algorithms were applied to detect temporal aberrations in the data series.Results: SCM was deployed successfully in each sentinel hospital and was operated during the 184-day surveillance period. A total of 1,730,797 patient encounters were recorded by SCM, and 6.1 % (105,352 visits) met the criteria of the seven targeted syndromes. Acute respiratory and gastrointestinal syndromes were reported most frequently, accounted for 92.1 % of reports in all syndromes, and the aggregated time-series presented an obvious day-of-week variation over the study period. In total, 191 aberration signals were triggered, and none of them were identified as outbreaks after verification and field investigation.Conclusions: SCM has acted as a practical tool for recording symptoms in the hospital-based enhanced syndromic surveillance system during the 41st World Exposition in Shanghai, in the context of without a preexisting electronic tool to collect syndromic data in the HIS of the sentinel hospitals.Keywords: Syndromic surveillance, Infectious disease, Mass gatherings, Early warning, Outbreak detection\u00a9 2016 The Author(s). This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.BackgroundSurveillance systems play a fundamental role on the mon-itoring and detecting outbreaks of infectious diseases. Syndromic surveillance, or the use of near \u201creal-time\u201d pre-diagnostic data and automated tools to detect and characterize unusual activity for further public health investigation, has been adopted in many countries to augment traditional surveillance for nearly two decades [1\u20133]. Syndromic surveillance systems usually employ statistical algorithms to inspect unexpected changes in prodromic or pre-diagnostic data captured in electronic systems from a variety of sources, with the premise that aberrations in these data may provide an earlier indi-cation of a disease outbreak before the change can be observed in confirmed diagnoses [4, 5]. Among the mul-tiple sources of pre-diagnostic data (such as emergency department visits, ambulance trip logs, pharmacy sales, and work or school absentee rates), pre-diagnostic clini-cal syndromes among patients visiting hospitals are fre-quently used as a data source in syndromic surveillance systems [6\u20138]. As syndromic surveillance is expected to Open AccessBMC Research Notes*Correspondence:  qsun@pdcdc.sh.cn; ywz126@vip.sina.com \u2020ChuchuYe and Zhongjie Li contributed equally to this work 1 Research Base of Key Laboratory of Surveillance and Early-warning on Infectious Disease in China CDC, Shanghai Pudong New Area Center for Disease Control and Prevention, Shanghai, China2 Key Laboratory of Surveillance and Early-warning on Infectious Disease, Chinese Center for Disease Control and Prevention, Beijing, ChinaFull list of author information is available at the end of the articlePage 2 of 9Ye et al. BMC Res Notes  (2016) 9:315 detect an epidemic at a very early stage, the timely col-lection, collation and analysis of a large amount of syn-drome data are key system components.In most existing syndromic surveillance systems, a common strategy of obtaining data from hospitals is to automatically collect the chief complaints of patients and to classify the data into syndromic categories using standard codes or by natural language processing [9\u201311].Syndromic surveillance, however, faces huge challenge while the chief complaints have not been documented electronically in the hospitals, which had been encoun-tered in Pudong New Area, Shanghai. The most of the hospitals in Pudong have an electric hospital informa-tion system (HIS) to record medical information. When a patient visits a hospital, a social insurance card or a provisional electronic card must be presented at the reception counter. Basic demographic information about the patient is recorded in the HIS, such as gender, date of birth, address and historical medical record. The HIS then generates a patient ID number, which is unique for the visit, and the patient is subsequently seen by a doc-tor. Information on the patient can be tracked by the ID number, which can be used to access the HIS record, including lab test orders, test results, prescriptions, and diagnoses. However, the fundamental information for syndromic surveillance-the chief complaints of the patient, are not routinely collected in HIS, as it is practi-cally recorded on paper at the stage of triage.The 41st World Exposition was held in Shanghai city, China, from May 1st to October 31st, 2010. It has been the largest exposition in the history, with more than 73 million visitors from approximately 240 countries and organizations. A large flow of international visitors might pose a potential public health risk of disease importation, as infectious disease transmission can be promoted by an increasing population flow and density or by the acci-dental or deliberate introduction of unusual pathogens. Pudong New Area is the largest district of Shanghai city, containing 5.4 million residents and approximately 60\u00a0% areas of the World Exposition sites. A routine notifiable infectious disease reporting system has been used, which only collected information of specific kinds of infectious disease diagnosed by the clinicians. To enhance the sen-sitivity and timeliness of disease outbreaks detection dur-ing the Expo, a syndromic surveillance and early warning system, Pudong Syndromic surveillance and Early Warn-ing System (PD-SEWS), was implemented in this district.To allow automated electronic access to chief com-plaints for PD-SEWS in the 41st World Exposition held in Shanghai in 2010, we have piloted to introduce a novel approach, the symptom-clicking-module (SCM), to gather syndrome data from hospitals, thereby ena-bling implementation of syndromic surveillance. Here, we describe how SCM operated, and present the main results of targeted syndromes, and compare the patterns of data among different levels of hospitals, as well as the day-of-week effect.MethodsSurveillance sentinels and\u00a0targeted syndromesTwenty-one hospitals were selected as sentinel sites for PD-SEWS, including two tertiary hospitals, five second-ary hospitals and fourteen primary hospitals. Hospitals were chosen according to their location, catchment area, and patient volume [12]. In Pudong, a primary hospital is the smallest category of healthcare facility, provid-ing primary medical services such as medical treatment, prevention, healthcare, and rehabilitation for a commu-nity with a population of <100,000 persons. The second-ary hospitals provide general medical services, including medical treatment, prevention, healthcare, and reha-bilitation for larger communities (population >100,000 persons). The tertiary hospitals are regional healthcare centers providing specialized, high-complexity health-care services for several districts. Most of the sentinel sites were closed to the Exposition venue, where was also the part of Pudong with highest population density (Fig.\u00a01).The concerning diseases during mass gatherings and their typical symptoms were listed according to litera-ture review, and Delphi method was employed to con-sult 18 domestic epidemiologic and clinical professionals to score the disease severity, risk probabilities. Then a disease-risk matrix was draw and 40 diseases were pri-oritized in the surveillance, including local common diseases and some highly concerned diseases of importa-tion. The 25 most common and typical symptoms of the Fig. 1 The geographic location of sentinel hospitals at three different levels in Pudong New Area, Shanghai, China, 2010Page 3 of 9Ye et al. BMC Res Notes  (2016) 9:315 targeted diseases were enrolled and classified to seven targeted syndromes: acute respiratory, acute gastroin-testinal, rash with fever, neurological syndrome, hem-orrhagic fever, botulism-like syndrome and acute viral hepatitis (Table\u00a01).Data collection and\u00a0transmissionThe SCM was developed and embedded in the HIS for each sentinel hospital, with the 25 symptoms presented on the SCM interface as a 5\u00a0 \u00d7\u00a0 5 table which could be selected by single click on the screen (Fig.\u00a02). In addition, we included an extra column to facilitate data entry and improve data quality. If no symptoms in a row were pre-sented, the \u2018none of the left\u2019 could be clicked. A clinician could therefore check each row of the table quickly. For example, if a patient described the chief complaint as \u2018fever and cough\u2019, the clinician should click \u2018fever\u2019 in the first row and \u2018cough\u2019 in the second, as well as \u2018none of the left\u2019 for the other three rows. Clinicians were pre-vented from moving to the next step of treatment (such as prescribing a medication) until they finished recording symptoms by clicking the \u2018save\u2019 button (Fig.\u00a03).A record of symptoms in SCM was generated with a unique identity (ID) number and the basic demographic information registered in HIS. All data were stored in real time and transmitted automatically to the Pudong Public Health Database Center each day. A virtual pri-vate network (VPN) was used to connect securely with sentinel hospitals, and all data were supplied and ana-lyzed in an anonymous format, without access to per-sonal identifying information. For improving the data quality, duplicated records were rejected by checking the unique ID number, and if the data were not received from a sentinel site, the Public Health Database Center would send a notice to that hospital at 08:00 a.m. the next day. Once the database center received the surveillance data, all of the patient records were automatically grouped and aggregated into the seven syndromes according to the criteria listed in Table\u00a0 1. If one patient\u2019s symptoms referred to more than one syndrome, then the encounter would be counted separately for each syndrome.Data analysis and\u00a0aberration detectionWe developed an interface connecting to the Pudong Public Health Database Center. The interface allowed authorized users to generate customized time series of total visits for each syndrome stratified by gender, age, syndrome, hospital, start dates and end dates. The cumu-lative sum (CUSUM) method, a control chart method commonly used in syndromic surveillance [4, 13], was applied daily to analyze the aggregated data of all sentinel Table 1 The seven syndromes under\u00a0 surveillance in\u00a0 the 41st exposition, Pudong New Area, Shanghai City, China, 2010Syndrome Typical symptomsAcute respiratory syndrome Fever with at least one of the following: cough, sputum, hemoptysis, chest pain, breathing difficultiesAcute gastrointestinal syndromeFever with at least one of the following: vomiting, diarrhea, pus/mucus in stoolRash with fever Fever with at least one of the following: herpes, maculopapular rashNeurological syndrome Fever with at least one of the following: headache, projectile vomiting, shock, altered consciousness, sudden body painHemorrhagic fever Fever with at least one of the following: skin or mucous congestion, petechiae, bleeding, bloody stoolBotulism-like syndrome At least one of the following: sudden blurred vision, dysphagiaAcute viral hepatitis At least one of the following: hepatosple-nomegaly, acute jaundice, lymphad-enopathyFig. 2 User interface of the symptom-clicking-module of PD-SEWS, Shanghai, China, 2010. All English words in the SCM were translated from Chinese wordsPage 4 of 9Ye et al. BMC Res Notes  (2016) 9:315 hospitals for detecting abnormal temporal increases [14]. For each targeted syndrome, CUSUM compared the pro-portion of syndrome counts in total visits in the current day (day 0) with the corresponding mean proportion and standard deviation of the past 7\u00a0days (day-7 to day-1). A signal was generated if the value of comparison exceeded two standard deviations.The surveillance and response team of Pudong Center for Disease Control and prevention (Pudong CDC) would monitor the warning signals routinely. When a signal was triggered, the verification would be con-ducted immediately by analyzing and reviewing the data to identify any unusual cluster of gender, age, occupa-tion or hospital. Some signals would be verified and compared with the data in the routine notifiable dis-ease reporting system, which recorded the confirmed patients\u2019 detailed information. Potential epidemic asso-ciation would be explored by calling the clinicians or patients. If the signal indicated a potential outbreak, field investigation would be performed to obtain more detailed epidemiological information and necessary control measures would be conducted to prevent fur-ther spread of the disease. Outbreak is defined as the occurrence of cases of disease in excess of what would normally be expected in a defined geographical area and period, which was further quantitatively defined for each kind of disease in this study, so as to facilitate the outbreak confirmation and report. For example, an out-break of hand, foot and mouth (HFM) disease is defined as \u201cwithin 1\u00a0week, at least five HFM disease cases occur in the same setting-e.g. kindergarten or school-or at least three cases of the disease occur in the same village or community\u201d [15].In this study, the number of outpatients, the reporting frequency and the proportion of each syndrome were calculated. The average reporting frequencies of different Fig. 3 Framework of syndromic surveillance in Pudong New Area, Shanghai, China, 2010Page 5 of 9Ye et al. BMC Res Notes  (2016) 9:315 syndromes between weekdays and weekends were com-pared using a Chi square test, and a P value <0.05 was considered to be statistically significant.Preparation for\u00a0system operationA series of training sessions on the system were con-ducted for the clinicians in the sentinel hospitals before the practical operation. This approach helped to ensure that the clinicians would be familiar with SCM in HIS. The estimated average time cost of recording a patient\u2019s syndrome by SCM was 10\u00a0s, according to our field inves-tigation in the last week of the training. A pilot surveil-lance operation was conducted 2\u00a0weeks before the formal running of this syndromic surveillance system, and the staff from Pudong CDC went to all the 21 sentinel hos-pitals during this pilot period to provide help if needed.ResultsDuring the surveillance period (184\u00a0 days) from May 1, 2010 to October 31, 2010, totally 1,730,797 patient encounters were collected through the SCM. Of these encounters, 105,352 (6.1\u00a0 %) were classified into the seven targeted syndromes under surveillance. The most frequent syndromes were acute respiratory syndrome (59,793 encounters) and acute gastrointestinal syndrome (45,634 encounters), which together accounted for 92.1\u00a0% of total visitors in the seven targeted syndromes. Botu-lism-like syndrome and hemorrhagic fever syndrome had the lowest frequencies, with only 187 and 131 encoun-ters, respectively. Encounters classified as acute respira-tory, acute gastrointestinal, and neurological syndromes were reported every day, whereas the other syndromes (including rash with fever, acute viral hepatitis, botulism-like syndrome and hemorrhagic fever) were not found from 7 to 122\u00a0days during surveillance period (Table\u00a02).The reporting frequencies for different syndromes var-ied with the day of the week. Except for hemorrhagic fever, the frequency of all other six surveillance syndromes were higher on the weekdays than that in weekends, but the variation was only significant for acute gastrointesti-nal syndrome and acute viral hepatitis (Fig.\u00a04). Addition-ally, in terms of the average reporting frequency of each syndrome across the sentinel hospitals, we found that the tertiary and secondary hospitals overall contributed much more than the primary hospitals, and the differences var-ied with syndromes. For rash with fever syndrome, the average reporting number in the tertiary hospitals was 151 times of that in the primary ones. However, for acute viral hepatitis syndrome, the average reporting numbers in the three levels of hospital were closer (Table\u00a03).During the surveillance period, the CUSUM triggered 191 signals, including 44 signals for acute respiratory syndrome, 41 signals for neurological syndrome, and 30 signals for acute gastrointestinal syndrome, and rash with fever syndrome, botulism-like syndrome, hemorrhagic fever and acute viral hepatitis had 22, 22, 17 and 15 sig-nals respectively. All of the signals had been verified, and field investigation and control measures had been con-ducted if a signal seemed to lead to an outbreak. Finally, none of the signals were confirmed as outbreaks. Mean-while, there was no infectious disease outbreak or public health emergency was confirmed and reported by local CDC through the other routine surveillance system dur-ing the same period.DiscussionThe SCM was implemented successfully and operated for a surveillance period lasting 184\u00a0 days in Expo 2010, which made it feasible to collect syndromic data and classify syndromes which was lacking in the HIS of sen-tinel hospitals. Approximately 6\u00a0% of patient encounters were classified into the seven surveillance syndromes, with the number of patients ranged from 131 in hemor-rhagic fever syndrome to 59,793 in acute respiratory syn-drome. Frequency of reporting varied by days of week for some syndromes, and the secondary and tertiary Table 2 Descriptive statistics of\u00a0visit counts for\u00a0the seven syndromes in\u00a0PD-SEWS, Shanghai, China, May 1st to\u00a0Oct 31st, 2010Q1 first quartile value; Q3 third quartile valueSyndrome Overall visitsProportion of\u00a0the total visits (%)Mean visits per\u00a0dayMinimum visits per\u00a0dayQ1 visits per\u00a0dayMedian visits per\u00a0dayQ3 visits per\u00a0dayMaximum visits per\u00a0dayDays with\u00a0zero reportingAcute respiratory syndrome 59,793 3.45 325 143 273 310.5 356.5 642 0Acute gastrointestinal syndrome 45,634 2.64 248 123 196.8 249 295.8 398 0Neurological syndrome 6055 0.35 32.9 9 20 29 41 112 0Rash with fever 1910 0.11 10.4 0 3.8 7.5 16 40 7Acute viral hepatitis 790 0.05 4.3 0 1 3 6 26 25Botulism-like syndrome 187 0.01 1 0 0 0 2 13 110Hemorrhagic fever 131 0.01 0.7 0 0 0 1 7 122Page 6 of 9Ye et al. BMC Res Notes  (2016) 9:315 hospitals reported the majority of encounters in syn-drome surveillance.In recent years, enhanced surveillance is commonly implemented during mass gatherings [16], and syndro-mic surveillance system has been established globally. In some countries, more efforts are needed to improve data collection to make the establishment of syndromic surveillance more easily and cost-effectively [17, 18]. The SCM in this study collated and analyzed syndromic data in a standard format across reporting hospitals, and allowed direct and automatic classification of symptoms into syndromes, avoiding to develop additional syndrome Fig. 4 Box plot of average reporting number of each day of week by syndrome detected by PD-SEWS, Shanghai, China, 2010Page 7 of 9Ye et al. BMC Res Notes  (2016) 9:315 classification software [19, 20]. Instead of directly collect-ing the syndrome data subjectively decided by the clini-cians, SCM allowed clinicians to record the raw data of symptoms on a patient, and the system automatically grouped the encounters into corresponding surveillance syndromes using pre-defined syndrome definitions. Additionally, SCM was embedded into the HIS so that all the basic information of the patients could be extracted from the registration data collected automatically. The design of SCM saves time during data collection and helps to avoid errors due to manual syndrome classifica-tion, which is important and effective because the most existing HIS in China without recording chief complaints of patients.We found that acute respiratory and acute gastrointes-tinal syndromes were reported most frequently, which is consistent with other syndromic surveillance systems [21\u201323]. These syndromes cover the symptoms of some common diseases, such as influenza and viral diarrhea, which are also the main infectious diseases in Shang-hai during the study period. Moreover, the day-of-week effect in our data suggests the residents in study area avoided to seek healthcare during weekend, possibly because hospitals could provide more medical services on weekdays. Therefore, the aberration detection algo-rithm on the syndromic surveillance system should take account of the day-of-week effect [22].The variation in reporting across the different lev-els of hospital was also observed for each syndrome. We found that most of the fever with rash cases were reported by one tertiary hospital, which was the big-gest children\u2019s hospital in Pudong. Fever with rash syn-drome usually presented among the diseases such as measles, rubella or chicken pox with high incidences in children. The primary hospitals reported the least cases in all of the syndromes, but the difference seemed much smaller for the acute viral hepatitis syndrome. This dif-ference is probably because most of the chronic hepatitis patients sought medical services at the nearest primary hospital. Additionally, the SCM is a new data collection module embedded into the routine HIS at each hospital, and the clinicians might need some time to accustom his change in their routine workflow. The strategy of con-ducting pilot surveillance is widely adopted by syndro-mic surveillance practice during mass gathering, which is key to improve the system\u2019s acceptability and ensure the data quality, which has been also conducted in this study [22\u201324].In this study, no one outbreak was confirmed among the 191 signals generated by PD-SEWS during the Expo. Each signal, which represented an aberration on the surveillance data, was required to be timely verified and investigated by the local staff of Center for Disease Control and Prevention, and control measures should be conducted rapidly once a signal seemed to lead to an out-break. That\u2019s the possible reason why no one signal was identified as an outbreak finally. To enhance the routine surveillance system by increasing the sensitive and timely detection of outbreaks was the important objective of syndromic surveillance, as well as to deal with each signal before it led to a real outbreak. The system would create a lot of extra work for Public Health Utility, that\u2019s why we only suggested adopting the enhanced syndromic surveil-lance system during the specific period, such as holding mass gatherings, instead of conducting it as routine work after the Expo.There were some limitations in our study. First, the cost-effectiveness of the SCM application was not evalu-ated systematically, but we performed a pilot investiga-tion of the SCM\u2019s usability and acceptability in several hospitals at the beginning of the surveillance. In addition, we have not systematically collected and evaluation the feedbacks from the clinicians during the study period. Nonetheless, according to the data collected by SCM and its operating results, it sounds acceptable for physicians to use during the special situation of a mass gathering. Table 3 Average reporting amount of\u00a0each syndrome per\u00a0hospital by\u00a0levels of\u00a0hospital in\u00a0Pudong New Area, Shanghai, China, 2010Syndromes Average reporting amount by\u00a0hospital\u2019s level Ratio of\u00a0primary to\u00a0sec-ondary and\u00a0tertiary hospital (a:b:c)Primary(a)Secondary(b)Tertiary(c)Acute respiratory syndrome 707.4 8544.0 3585.0 1:12:5Acute gastrointestinal syndrome 756.0 5508.8 3753.0 1:7:5Neurological syndrome 63.7 920.6 280.0 1:14:4Rash with fever 4.4 106.4 658.5 1:24:151Acute viral hepatitis 28.4 56.8 54.5 1:2:2Botulism-like syndrome 3.3 15.0 33.0 1:5:10Hemorrhagic fever 3.0 9.2 21.5 1:3:7Page 8 of 9Ye et al. BMC Res Notes  (2016) 9:315 Another limitation is that spatial cluster detection was not conducted in our study. Some algorithms such as space\u2013time scan statistic [25] have been applied to detect spatial aberration, but SCM without the sufficient geo-graphic information of each patient to conduct this anal-ysis. Additionally, as the CUSUM method was applied to the aggregated data of all hospitals instead of each single sentinel site, this limited the ability to detect small out-breaks. However, as the surveillance data for each senti-nel hospital (including three different levels of hospitals) were not stable enough on the time series, which would lead to large amount of false alerts if performing the algo-rithms on single hospital level. Therefore, taking account of the balance between sensitivity and false alarm rate, we applied CUSUM method to the total number of each syndrome, and adopted a relatively lower threshold to ensure the sensitivity. In addition, the system could auto-matically demonstrate daily time series figure of surveil-lance data for each single hospital, which could assist in the local epidemiologist to detect the potential smaller outbreak with manual manner.ConclusionsSCM has acted as a practical tool for recording symp-toms in the hospital-based enhanced syndromic sur-veillance system during the 41st World Exposition in Shanghai, in the context of without a preexisting elec-tronic tool to collect syndromic data in the HIS of the sentinel hospitals.AbbreviationsSCM: symptom-clicking-module; HIS: hospital information system; PD-SEWS: pudong syndromic surveillance and early warning system; FEP: front end pro-cessor; PDCDC: Pudong New Area Center for disease control and prevention; VPN: virtual private network; CUSUM: cumulative sum.Authors\u2019 contributionsQS, WY, YL and ZL made substantial contributions to the design of this study. CY, ZL, WZ and YF made contributions to acquisition of data, data collection supervision. CY HZ and SL were involved in data analysis, interpretation of data and preparation of the manuscript. CY, ZL, HZ, DZ and DB were involved in drafting the manuscript or revising it. All authors read and approved the final manuscript.Author details1 Research Base of Key Laboratory of Surveillance and Early-warning on Infec-tious Disease in China CDC, Shanghai Pudong New Area Center for Disease Control and Prevention, Shanghai, China. 2 Key Laboratory of Surveillance and Early-warning on Infectious Disease, Chinese Center for Disease Control and Prevention, Beijing, China. 3 Research Base of Key Laboratory of Surveil-lance and Early-warning on Infectious Disease in China CDC, West China School of Public Health, Sichuan University, Chengdu, China. 4 Department of Geography and Environment, University of Southampton, Southampton, UK. 5 McGill University, Montreal, Canada. AcknowledgementsWe thank the clinicians in the sentinel hospitals for their assistance in data collection.Availability of data and materialsOriginal data are available upon request from the first author.Competing interestsWe confirm that none of the authors have any competing interests.Consent for publicationNot applicable as the manuscript does not contain any individual persons data.Ethics approval and consent to participateThe surveillance was approved by Shanghai Pudong New Area Center for Disease Control and Prevention Review Board. The patient information was anonymized and de-identified prior to analysis.FundingThis study was supported by the Grants from the National Science and Technology Key Projects (No. 2009ZX10004-201, No. 2012ZX10004-201) and Ministry of Health, China (No. 201202006).These funding offices had no involvement in the design, data collection analysis, write up and decision for the results to be published.Received: 2 December 2015   Accepted: 23 May 2016References 1. Chretien JP, Burkom HS, Sedyaningsih ER, Larasati RP, Lescano AG, Mun-daca CC, et al. Syndromic surveillance: adapting innovations to develop-ing settings. PLoS Med. 2008;5(3):e72. 2. Wu TS, Shih FY, Yen MY, Wu JS, Lu SW, Chang KC, et al. Establishing a nationwide emergency department-based syndromic surveillance system for better public health responses in Taiwan. Bmc Pub Health. 2008;8:18. 3. Abubakar I, Gautret P, Brunette GW, Blumberg L, Johnson D, Poumerol G, et al. Global perspectives for prevention of infectious diseases associated with mass gatherings. Lancet Infect Dis. 2012;12(1):66\u201374. 4. Yan WR, Nie SF, Xu B, Dong HJ, Palm L, Diwan VK. Establishing a web-based integrated surveillance system for early detection of infectious disease epidemic in rural China: a field experimental study. BMC Med Inform Decis Mak. 2012;12:4. 5. Khan K, McNabb SJ, Memish ZA, Eckhardt R, Hu W, Kossowsky D, et al. Infectious disease surveillance and modelling across geographic frontiers and scientific specialties. Lancet Infect Dis. 2012;12(3):222\u201330. 6. May LS, Griffin BA, Bauers NM, Jain A, Mitchum M, Sikka N, et al. Emergency department chief complaint and diagnosis data to detect influenza-like illness with an electronic medical record. West J Emerg Med. 2010;11(1):1\u20139. 7. Moore KM, Edgar BL, McGuinness D. Implementation of an auto-mated, real-time public health surveillance system linking emergency departments and health units: rationale and methodology. CJEM. 2008;10(2):114\u20139. 8. Khan K, Freifeld CC, Wang J, Mekaru SR, Kossowsky D, Sonricker AL, et al. Preparing for infectious disease threats at mass gatherings: the case of the Vancouver 2010 Olympic Winter Games. CMAJ. 2010;182(6):579\u201383. 9. Chapman WW, Christensen LM, Wagner MM, Haug PJ, Ivanov O, Dowl-ing JN, et al. Classifying free-text triage chief complaints into syndro-mic categories with natural language processing. Artif Intell Med. 2005;33(1):31\u201340. 10. South BR, Chapman WW, Delisle S, Shen S, Kalp E, Perl T, et al. Optimiz-ing A syndromic surveillance text classifier for influenza-like illness: does document source matter? AMIA Annu Symp Proc. 2008;692\u20136. 11. May L, Chretien JP, Pavlin JA. Beyond traditional surveillance: applying syndromic surveillance to developing settings\u2013opportunities and chal-lenges. BMC Pub Health. 2009;9:242.Page 9 of 9Ye et al. BMC Res Notes  (2016) 9:315 \u2022  We accept pre-submission inquiries \u2022  Our selector tool helps you to find the most relevant journal\u2022  We provide round the clock customer support \u2022  Convenient online submission\u2022  Thorough peer review\u2022  Inclusion in PubMed and all major indexing services \u2022  Maximum visibility for your researchSubmit your manuscript atwww.biomedcentral.com/submitSubmit your next manuscript to BioMed Central and we will help you at every step: 12. Wang JF, Reis BY, Hu MG, Christakos G, Yang WZ, Sun Q, et al. Area disease estimation based on sentinel hospital records. PLoS One. 2011;6(8):e23428. 13. Fricker RD Jr, Hegler BL, Dunfee DA. Comparing syndromic surveillance detection methods: EARS\u2019 versus a CUSUM-based methodology. Stat Med. 2008;27(17):3407\u201329. 14. Rogerson PA, Yamada I. Approaches to syndromic surveillance when data consist of small regional counts. MMWR Morb Mortal Wkly Rep. 2004;53(Suppl):79\u201385. 15. National health and family planning commission of China. Guideline for hand, foot and mouth disease outbreaks disposal (2012 edition). 2012. http://www.nhfpc.gov.cn/zhuzhan/wsbmgz/201304/2455757fe843447c8289e1431b20a1a9.shtml. Accessed 18 May 2016. 16. Thackway S, Churches T, Fizzell J, Muscatello D, Armstrong P. Should cities hosting mass gatherings invest in public health surveillance and plan-ning? reflections from a decade of mass gatherings in Sydney, Australia. BMC Pub Health. 2009;9:324. 17. Ding Y, Fei Y, Xu B, Yang J, Yan W, Diwan VK, et al. Measuring costs of data collection at village clinics by village doctors for a syndromic surveil-lance system\u2014a cross sectional survey from China. Bmc Health Serv Res. 2015;15:287. 18. Fan Y, Wang Y, Jiang H, Yang W, Yu M, Yan W, et al. Evaluation of outbreak detection performance using multi-stream syndromic surveillance for influenza-like illness in rural Hubei Province, China: a temporal simulation model based on healthcare-seeking behaviors. PLoS One. 2014;9(11):e112255. 19. Lu HM, Chen H, Zeng D, King CC, Shih FY, Wu TS, et al. Multilingual chief complaint classification for syndromic surveillance: an experiment with Chinese chief complaints. Int J Med Inform. 2009;78(5):308\u201320. 20. Chapman WW, Dowling JN, Wagner MM. Classification of emergency department chief complaints into 7 syndromes: a retrospective analysis of 527,228 patients. Ann Emerg Med. 2005;46(5):445\u201355. 21. Dafni UG, Tsiodras S, Panagiotakos D, Gkolfinopoulou K, Kouvatseas G, Tsourti Z, et al. Algorithm for statistical detection of peaks\u2013syndromic surveillance system for the Athens 2004 Olympic Games. MMWR Morb Mortal Wkly Rep. 2004;53(Suppl):86\u201394. 22. Meyer N, McMenamin J, Robertson C, Donaghy M, Allardice G, Cooper DA. Multi-data source surveillance system to detect a bioterrorism attack during the G8 summit in Scotland. Epidemiol Infect. 2008;136(7):876\u201385. 23. Yan W, Palm L, Lu X, Nie S, Xu B, Zhao Q, et al. ISS\u2014an electronic syndro-mic surveillance system for infectious disease in rural China. PLoS One. 2013;8(4):e62749. 24. Harcourt SE, Fletcher J, Loveridge P, Bains A, Morbey R, Yeates A, et al. Developing a new syndromic surveillance system for the London 2012 Olympic and Paralympic Games. Epidemiol Infect. 2012;140(12):2152\u20136. 25. Nordin JD, Goodman MJ, Kulldorff M, Ritzwoller DP, Abrams AM, Klein-man K, et al. Simulated anthrax attacks and syndromic surveillance. Emerg Infect Dis. 2005;11(9):1394\u20138.",
      "id": 26543327,
      "identifiers": [
        {
          "identifier": "46577051",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:eprints.soton.ac.uk:397868",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1186/s13104-016-2098-z",
          "type": "DOI"
        }
      ],
      "title": "a practical tool to implement hospital-based syndromic surveillance: SCM",
      "magId": null,
      "oaiIds": [
        "oai:eprints.soton.ac.uk:397868"
      ],
      "publisher": "'Springer Science and Business Media LLC'",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [],
      "updatedDate": "2022-06-27T06:18:31",
      "yearPublished": null,
      "journals": [],
      "links": [
        {
          "type": "display",
          "url": "https://core.ac.uk/works/26543327"
        }
      ]
    },
    {
      "arxivId": null,
      "authors": [
        {
          "name": "Buckeridge, David"
        },
        {
          "name": "Clements, Archie"
        },
        {
          "name": "Lai, Shengjie"
        },
        {
          "name": "Lan, Yajia"
        },
        {
          "name": "Li, Zhongjie"
        },
        {
          "name": "Liu, Jizeng"
        },
        {
          "name": "Ma, Jiaqi"
        },
        {
          "name": "Pittayawonganan, Chakrarat"
        },
        {
          "name": "Wang, Liping"
        },
        {
          "name": "Yu, Hongjie"
        },
        {
          "name": "Zhang, Honglong"
        },
        {
          "name": "Zhou, Dinglun"
        }
      ],
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/156678541"
      ],
      "createdDate": "2018-04-26T01:05:04",
      "dataProviders": [
        {
          "id": 2793,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/2793",
          "logo": "https://api.core.ac.uk/data-providers/2793/logo"
        }
      ],
      "abstract": "Objective To evaluate the performance of China's infectious disease automated alert and response system in the detection of outbreaks of hand, foot and mouth (HFM) disease. Methods We estimated size, duration and delay in reporting HFM disease outbreaks from cases notified between 1 May 2008 and 30 April 2010 and between 1 May 2010 and 30 April 2012, before and after automatic alert and response included HFM disease. Sensitivity, specificity and timeliness of detection of aberrations in the incidence of HFM disease outbreaks were estimated by comparing automated detections to observations of public health staff. Findings The alert and response system recorded 106 005 aberrations in the incidence of HFM disease between 1 May 2010 and 30 April 2012 - a mean of 5.6 aberrations per 100 days in each county that reported HFM disease. The response system had a sensitivity of 92.7% and a specificity of 95.0%. The mean delay between the reporting of the first case of an outbreak and detection of that outbreak by the response system was 2.1 days. Between the first and second study periods, the mean size of an HFM disease outbreak decreased from 19.4 to 15.8 cases and the mean interval between the onset and initial reporting of such an outbreak to the public health emergency reporting system decreased from 10.0 to 9.1 days. Conclusion The automated alert and response system shows good sensitivity in the detection of HFM disease outbreaks and appears to be relatively rapid. Continued use of this system should allow more effective prevention and limitation of such outbreaks in China",
      "documentType": "",
      "doi": "10.2471/blt.13.130666",
      "downloadUrl": "https://core.ac.uk/download/156678541.pdf",
      "fieldOfStudy": null,
      "fullText": "Bull World Health Organ 2014;92:656\u2013663 | doi: http://dx.doi.org/10.2471/BLT.13.130666Research656Hand, foot and mouth disease in China: evaluating an automated system for the detection of outbreaksZhongjie Li,a Shengjie Lai,a Honglong Zhang,a Liping Wang,a Dinglun Zhou,b Jizeng Liu,c Yajia Lan,b Jiaqi Ma,a Hongjie Yu,a David L Buckeridge,d Chakrarat Pittayawonganan,e Archie CA Clements,f Wenbiao Hug & Weizhong YangaIntroductionTo improve control of infectious disease outbreaks, it is criti-cal to establish early detection and warning systems. In recent decades, technological advances in computing and communi-cation and mathematical aberrancy-detection algorithms have been applied to high-volume data sets, to generate alerts and draw the attention of epidemiologists to statistical anomalies that may indicate a localized outbreak or the elevated risk of such an outbreak.1\u20133 Several national public health agencies have successfully developed and operated automated early warning systems for the prompt detection of disease out-breaks.4\u20138 Some epidemiologists have simulated outbreaks to evaluate the performance of such systems and the associated outbreak-detection algorithms.9,10 However, there have been few prospective evaluations of the performance of early warn-ing systems in operational settings.11,12In April 2008, a web-based automated system for the early detection of \u2013 and rapid response to \u2013 outbreaks of infectious disease was implemented across China.13 This system \u2013 the China infectious disease automated alert and response system (hereafter referred to as the response system) \u2013 was developed by the Chinese Centre for Disease Control and Prevention, with the support of the Chinese Ministry of Health and the World Health Organization. The response system was based on surveillance data on dozens of notifiable diseases and on several statistical algorithms for the automated and routine detection of aberrations in such data, at county level, that might indicate the early stages of potential outbreaks.Although hand, foot and mouth (HFM) disease can be caused by serotypes of several enteroviruses, it is most fre-quently caused by coxsackie virus A16 and human enterovirus 71. Most affected people develop only mild symptoms but some cases may result in serious and even fatal complications.14\u201316 In China, HFM disease is frequently detected in children aged less than five years17 and there have been over a million cases of the disease, including hundreds of fatal cases, reported an-nually over recent years.18,19In this study, we aimed to evaluate the performance of the response system by analysing the sensitivity, specificity and timeliness in the detection of HFM disease outbreaks. We also wished to evaluate the response system\u2019s effective-ness by comparing the size and duration of HFM disease outbreaks \u2013 and the post-onset delay in reporting such outbreaks \u2013 before and after HFM disease was included in the response system.Objective To evaluate the performance of China\u2019s infectious disease automated alert and response system in the detection of outbreaks of hand, foot and mouth (HFM) disease.Methods We estimated size, duration and delay in reporting HFM disease outbreaks from cases notified between 1 May 2008 and 30 April 2010 and between 1 May 2010 and 30 April 2012, before and after automatic alert and response included HFM disease. Sensitivity, specificity and timeliness of detection of aberrations in the incidence of HFM disease outbreaks were estimated by comparing automated detections to observations of public health staff.Findings The alert and response system recorded 106 005 aberrations in the incidence of HFM disease between 1 May 2010 and 30 April 2012 \u2013 a mean of 5.6 aberrations per 100 days in each county that reported HFM disease. The response system had a sensitivity of 92.7% and a specificity of 95.0%. The mean delay between the reporting of the first case of an outbreak and detection of that outbreak by the response system was 2.1 days. Between the first and second study periods, the mean size of an HFM disease outbreak decreased from 19.4 to 15.8 cases and the mean interval between the onset and initial reporting of such an outbreak to the public health emergency reporting system decreased from 10.0 to 9.1 days.Conclusion The automated alert and response system shows good sensitivity in the detection of HFM disease outbreaks and appears to be relatively rapid. Continued use of this system should allow more effective prevention and limitation of such outbreaks in China.a Key Laboratory of Surveillance and Early-warning on Infectious Disease, Chinese Centre for Disease Control and Prevention, 155 Changbai Road, Changping District, Beijing, 102206, China.b West China School of Public Health, Sichuan University, Chengdu, China.c Sinosoft Company, Beijing, China.d Department of Epidemiology, Biostatistics and Occupational Health, McGill University, Montreal, Canada.e International Field Epidemiology Training Programme, Ministry of Public Health, Nonthaburi, Thailand.f Research School of Population Health, The Australian National University, Canberra, Australia.g School of Public Health and Social Work, Queensland University of Technology, Brisbane, Australia.Correspondence to Weizhong Yang (email: yangwz@chinacdc.cn).(Submitted: 23 September 2013 \u2013 Revised version received: 9 April 2014 \u2013 Accepted: 23 April 2014 \u2013 Published online: 23 June 2014 )Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666 657ResearchDetecting outbreaks of hand, foot and mouth disease in ChinaZhongjie Li et al.MethodsCase reporting systemAll HFM disease cases that occurred in China after May 2008 \u2013 when HFM disease became a notifiable disease in China20 \u2013 should have been reported, by attending clinicians, via the nationwide notifiable infectious diseases reporting information system (hereafter referred to as the case reporting system). This system enables health-care institutes across China to report information on each case of a notifiable infectious disease rapidly, via the Internet, to the Chinese Centre for Disease Control and Prevention. For our study, we used the information on each laboratory-confirmed or clinically diagnosed case of HFM disease that was reported to the case reporting system between 1 May 2008 and 30 April 2012.Automated detection of outbreaksCurrently, the automated alert and response system searches the data col-lected in the case reporting system for aberrations in the incidence of HFM dis-ease and another 29 notifiable infectious diseases.13 HFM disease has only been included in the response system since 1 May 2010. In the response system, an aberration in incidence at county level leads to the automated generation of a warning signal and that signal\u2019s dis-semination to the relevant county-level Centre for Disease Control and Preven-tion. Each signal is then investigated further by epidemiologists in the specific county (Fig. 1).Aberration detectionAberration detection of HFM disease outbreak in the response system is based on the C3 algorithm of the early aber-ration reporting system developed by the United States Centers for Disease Control and Prevention.2,9,21\u201324 C3 com-pares the count of cases in the current day \u2013 day 0 \u2013 with the corresponding mean count and standard deviation for seven earlier days \u2013 days \u22129 to \u22123. If the calculated value of C3 surpasses a preset threshold, a warning signal is gener-ated. Following the advice of senior epidemiologists and statisticians in the response system\u2019s research group, the preset threshold was given a value of 1.3 for HFM disease in May 2010. This value took estimates of the response system\u2019s general sensitivity, timeliness, specificity and positive predictive value in outbreak detection into account.Signal generation and disseminationOnce a day, the response system searches for aberrations in the county-level inci-dence of HFM disease. Any warning sig-nals generated are then automatically dis-seminated via short message service texts sent to the mobile phones of designated staff in the Centres for Disease Control and Prevention in the relevant counties.13,25Investigation and feedbackA health-care professional who receives a warning signal as a text message is ex-pected to review the HFM disease cases that triggered the signal, further assess the possibility of an outbreak \u2013 by integrating information from other sources, such as information collected by direct contact with the reporting clinical and health-care agencies and \u2013 if there then seems to be a real threat of an outbreak (which meant that the warning signal became an alert signal) \u2013 conduct a field investigation.13,25 If an HFM disease outbreak is confirmed after field investigation, it should be reported to the public health emergency reporting system.The health-care professionals who receive warning signals are expected to complete two simple, web-based forms, as soon as possible, so that details of how the professionals proceeded with signal verifica-tion and \u2013 if appropriate \u2013 field investigation can be viewed promptly by epidemiologists at higher levels.13 In this way, high-level epidemiologists can carefully monitor and assess the risk of outbreak spread.Reporting confirmed outbreaksThe Chinese public health emergency reporting system was initiated in 2004, to record outbreaks of infectious dis-eases identified by local epidemiologists. Aside from the procedures that form part of the response system, staff from local health departments are instructed to conduct a field investigation if, within 1 week, at least five HFM disease cases occur in the same setting \u2013 e.g. kinder-garten or school \u2013 or at least three cases of the disease occur in the same village or community. Any outbreak confirmed by a field investigation should be re-ported to the public health emergency reporting system.20,26Evaluating the response system\u2019s effectivenessThe main objectives of our study were to evaluate the response system\u2019s capacity Fig. 1. The operational flow of information on hand, foot and mouth disease to and from the response systemaAlertInformation feedbackEnd of signal responseOther sources of outbreak detectionCase reporting systemaResponse systembPublic health emergency reporting systemOutbreakCase reporting (by clinical and health-care departments)Aberration detection (automatically, by C3 algorithm)Signal generation and dissemination (automatically, via SMS texts)Signal verification (by local epidemiologist at county level)Field investigation (by epidemiologist at county or higher level)Outbreak reporting (by epidemiologist at county or higher level)NoNoYesYesa  China Infectious Disease Automated Alert and Response System. b  Notifiable Infectious Diseases Reporting Information System.Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666658ResearchDetecting outbreaks of hand, foot and mouth disease in China Zhongjie Li et al.for identifying HFM disease outbreaks and the response system\u2019s impacts on the mean size and duration of an HFM disease outbreak and on the mean delays in the recording of an HFM disease outbreak to the public health emergency reporting system. The HFM disease outbreaks recorded in the pub-lic health emergency reporting system were used as the gold standard in our estimations of the response system\u2019s sensitivity, specificity and timeliness. The number of cases detected was used as the measure of the size of an outbreak. The number of days between the onset of symptoms in the first and last known cases that were related to the outbreak was used as the estimate of outbreak duration. Sensitivity was estimated by dividing the number of HFM disease outbreaks detected by the response system, by the corresponding number of such outbreaks recorded in the public health emergency reporting system.9,27 Specificity was estimated by dividing the number of non-outbreak days on which no warning signal was generated for HFM disease \u2013 by the response system \u2013 by the total number of non-outbreak days. Time to detection was defined as the interval between the first case related to the outbreak being reported to the re-porting system and the generation of the first warning signal about the outbreak by the response system.27 Time from detection to report was defined as the interval between the generation of the first warning signal about the outbreak by the response system and the report of the outbreak to the public health emergency reporting system. Time to report \u2013 which was investigated both before and after the response system was implemented \u2013 was defined as the interval between symptom onset in the first case related to the outbreak and the report of the outbreak to the public health emergency reporting system.The mean size, duration and time to report of an HFM disease outbreak were estimated for the period 1 May 2008\u201330 April 2010 \u2013 i.e. before HFM disease was covered by the response system \u2013 and for the period 1 May 2010\u201330 April 2012 \u2013 i.e. after HFM disease was included in the response system\u2019s remit.Statistical analysesWe used Pearson\u2019s \u03c72 test to evaluate the significance of the response system\u2019s sen-sitivity in the detection of HFM disease outbreaks in three size categories: 3\u201310, 11\u201320 and more than 20 cases. Time to detection was investigated by one-way analysis of variance. Student\u2019s t-test was used to examine whether the mean size, duration and time to report of outbreaks were significantly different before and after HFM disease was included in the response system. All analyses were implemented in version 2.14.1 of the R statistical software package (R Founda-tion for Statistical Computing, Vienna, Austria).ResultsBetween 1 May 2008 and 30 April 2012, 5 471 108 cases and 1209 outbreaks of HFM disease were reported in China (Table 1). The number of HFM disease cases per month ranged from 7512 cases in January 2009 to 353 104 cases in May 2010, with a mean value of 113 981 (95% confidence interval, CI: 87 444\u2013140 186). Over this period, HFM disease inci-dence showed marked seasonality, with a major peak \u2013 comprising almost half of all cases \u2013in April\u2013June and a smaller secondary peak \u2013 comprising 18.0% of cases \u2013 in September\u2013November. Re-ported outbreaks, warning signals and alerts showed a similar seasonal pattern.The number of outbreaks reported per year ranged from 211 for the period 1 May 2008\u201330 April 2009 to 380 for the period 1 May 2009\u201330 April 2010. Between 1 May 2010 and 30 April 2012, 106 005 warning signals in a total of 2608 counties were generated by the response system for HFM disease (Table 1). This represents a mean of 5.6 such signals Table 1. Outbreaks of hand, foot and mouth disease in China, 2008\u20132012Indicator Period1 May 2008\u201330 April 20091 May 2009\u201330 April 20101 May 2010\u201330 April 20111 May 2011\u201330 April 2012OverallCasesCases reported in the case reporting systema 757 141 1 256 320 1 576 918 1 880 729 5 471 108Outbreaks recorded by the public health emergency reporting system211 380 298 320 1 209Ratio of all reported casesb to outbreaks recorded in the public health emergency reporting system3 588:1 3 306:1 5 292:1 5 877:1 4 525:1No. of cases related to outbreaks 4 077 7 376 4 795 4 956 21 204Ratio of all reported casesb to cases related to outbreaks186:1 170:1 329:1 379:1 258:1SignalsWarning signals generated by the response systemc\u2013 \u2013 48 916 57 089 106 005Ratio of all cases to warning signalb \u2013 \u2013 32:1 33:1 33:1Alerts recorded in response systemc \u2013 \u2013 1 117 1 244 2 361Ratio of warning signals to alertsb \u2013 \u2013 44:1 46:1 45:1Detected outbreaks \u2013 \u2013 278 295 573Ratio of alerts to detected outbreaksb \u2013 \u2013 4:1 4:1 4:1a  Notifiable Infectious Diseases Reporting Information System.b  Rounded to an integer.c  China Infectious Disease Automated Alert and Response System.Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666 659ResearchDetecting outbreaks of hand, foot and mouth disease in ChinaZhongjie Li et al.every 100 days in each of the coun-ties that had at least one signal. Initial verification indicated that 2361 (2.2%) of the signals merited being raised to alert status and field investigation. Field investigation of the response system\u2019s signals led to 573 HFM disease out-breaks being confirmed. The response system received the initial verification results for 94 920 (89.5%) of the signals within 24 h.As 618 HFM disease outbreaks were recorded in the public health emergency reporting system in the period when 573 such outbreaks were identified in the response system, the overall sensitivity of the response system in the detection of HFM disease outbreaks was 92.7% (Table 2). The response system\u2019s sensi-tivity was significantly higher for large outbreaks involving more than 20 cases than for small outbreaks that involved no more than 10 cases (99.3% versus 84.6%; P < 0.001). In the detection of HFM disease outbreaks, the overall specificity of the response system was 95.0% (19 74 324/2 078 361) and the overall mean time to detection was 2.1 days (95% CI: 1.8\u20132.3). The mean time to detection was 1.7 days for outbreaks that involved no more than 10 cases but 2.7 days for outbreaks that involved more than 20 cases. The mean time from detection to report in the public health emergency reporting system was 4.5 days (95% CI: 4.1\u20135.0).In our investigation of the data recorded before HFM disease was in-cluded in the response system, the mean size (P = 0.982), duration (P = 0.572) and time to report (P = 0.358) of the HFM disease outbreaks detected be-tween 1 May 2008 and 30 April 2009 were similar to those of the outbreaks detected in the following 12 months. Similarly, in our investigation of the data recorded after HFM disease was in-cluded in the response system, the mean size (P = 0.443), duration (P = 0.370) and time to report (P = 0.840) of the HFM disease outbreaks detected between 1 May 2010 and 30 April 2011 were similar to those of the outbreaks detected in the following 12 months. The outbreaks recorded in the two years immediately after HFM disease was included in the response system were generally smaller than those recorded over the previous two years, with mean sizes of 15.8 and 19.4 cases, respectively (Table 3). The mean size of outbreaks that involved more than 20 cases was significantly less in the two years immediately after HFM disease was included in the response system than the corresponding value for the previous two years (29.2 versus 55 cases; P = 0.015).The overall mean duration of an HFM disease outbreak was estimated to be 15.2 days for the study periods before and after HFM disease was included in Table 2. Detection of outbreaks of hand, foot and mouth disease in China, 1 May 2010\u201330 April 2012No. of cases in outbreakNo. of outbreaks Performance of response systemaReported in public health emergency reporting systemDetected by response systemaSensitivity, %bMean time to outbreak detection, daysc (95% CI)3\u201310 156 132 84.6 1.7 (1.3\u20132.1)11\u201320 326 306 93.9 1.9 (1.7\u20132.2)> 20 136 135 99.3 2.7 (1.9\u20133.5)Overall 618 573 92.7 2.1 (1.8\u20132.3)CI: confidence interval. a  China Infectious Disease Automated Alert and Response System.b  Values differ significantly according to size of outbreak (P < 0.001).c  The time between the reporting of the first known case of an outbreak and the response system\u2019s generation of the first warning signal about that outbreak. Values do not differ significantly according to size of outbreak (one-way analysis of variance; P = 0.28).Table 3. Size, duration and reporting times of hand, foot and mouth (HFM) disease outbreaks before and after response systema application, China, 2008\u20132012No. of cases before/after inclusion of HFM disease in response systemaOutbreaks of HFM disease reported to public health emergency reporting systemNo. reported Mean size, cases  (95% CI)Mean duration, days (95% CI)Mean time to report, days  (95% CI)Before inclusionb3\u201310 161 6.7 (6.3\u20137.1) 9.1 (8.2\u201310.0) 8.1 (7.4\u20138.7)11\u201320 328 14.5 (14.2\u201314.8) 14.0 (13.1\u201314.9) 10.1 (9.5\u201310.7)> 20 102 55.0 (34.3\u201375.8) 28.7 (24.4\u201332.9) 12.7 (11.1\u201314.3)Overall 591 19.4 (15.6\u201323.2) 15.2 (14.1\u201316.2) 10.0 (9.5\u201310.5)After inclusionc3\u201310 156 6.4 (5.9\u20136.8) 8.4 (7.6\u20139.2) 7.3 (6.8\u20137.8)11\u201320 326 14.7 (14.4\u201315.0) 14.0 (13.2\u201314.7) 9.4 (8.9\u20139.8)> 20 136 29.2 (27.2\u201331.1)d 26.0 (23.5\u201328.5) 10.5 (9.5\u201311.5)eOverall 618 15.8 (15.0\u201316.5) 15.2 (14.4\u201316.1) 9.1 (8.7\u20139.5)fCI: confidence interval.a  China Infectious Disease Automated Alert and Response System; b  For the period 1 May 2008\u201330 April 2010.c  For the period 1 May 2010\u201330 April 2012.d  Significantly lower than corresponding value for the study period before HFM disease was included in CIDARS (P = 0.015).e  Significantly lower than corresponding value for the study period before HFM disease was included in CIDARS (P = 0.020)f  Significantly lower than corresponding value for the study period before HFMD disease was included in CIDARS (P = 0.004).Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666660ResearchDetecting outbreaks of hand, foot and mouth disease in China Zhongjie Li et al.the response system. However, the mean duration of outbreaks that involved more than 20 cases fell from 28.7 days in the two years before HFM disease was included in the response system to 26.0 days in the following two-year period. The corresponding falls in the mean number of days taken to report an HFM disease outbreak of any size \u2013 from 10.0 to 9.1 (P = 0.004) \u2013 and an HFM disease outbreak that involved more than 20 cases \u2013 from 12.7 to 10.5 (P = 0.020) \u2013 were significant.DiscussionOur observations indicate that the response system had good sensitivity and specificity in the detection of HFM disease outbreaks and could lead to a reduction in the eventual size of an out-break \u2013 by shortening the reporting time and so permitting an earlier response.Our results are consistent with previous research that has found the C3 algorithm to be useful for the detection of aberrancy in the incidence of influ-enza, bacillary dysentery, HFM disease and other diseases.22,23,27 We found that the response system\u2019s sensitivity in de-tecting outbreaks of HFM disease that became relatively large \u2013 i.e. 99.3% for outbreaks with more than 20 cases \u2013 was significantly higher than that for outbreaks that remained small \u2013 i.e. 84.6% for outbreaks with no more than 10 cases. Perhaps the outbreaks that grow large expand relatively rapidly and quickly present a large enough deviation from the baseline value for incidence to be easily detected. However, we made no attempt to investigate how responses to the detected outbreaks affected their final size. Overall, 45 HFM disease out-breaks \u2013 that were confirmed by health professionals at a time when HFM dis-ease was included in the response system \u2013 were not detected by the response sys-tem. All 45 remained relatively small and occurred in kindergartens, elementary schools or rural villages. Efforts should be made to increase the sensitivity of the response system \u2013 e.g. by using high-resolution spatial detection methods28\u201330 \u2013 to improve the prompt detection of outbreaks while they are small.Although use of a C3 threshold of 1.3 resulted in good sensitivity, specificity and timeliness in the response system\u2019s detection of HFM disease out-breaks, it also resulted in a low positive predictive value. The health profes-sionals who checked the data decided that only 2.2% of the warning signals that the response system generated for HFM disease merited field investigation. One cause of the low positive predictive value is that almost all of the HFM dis-ease cases seen in China \u2013 over 99.6% according to the data that we analysed \u2013 are sporadic and never form part of an outbreak. A temporal cluster of sporadic cases may easily trigger a false-positive warning signal in the response system. Such false signals need to be reduced by optimizing the algorithms and thresholds used for outbreak detec-tion \u2013 perhaps according to the relevant baseline incidence of HFM disease.31 The procedures for the verification of warn-ing signals at county level also need to be simplified, to reduce the detrimental effects of so many false-positive signals on the morale and workloads of health professionals.The early detection of potential outbreaks is important in minimizing the impact of HFM disease.19 Inclusion of HFM disease in the national response system cut the time taken to report an outbreak of the disease by almost a day. Since the corresponding warning signals were generated a mean of 4.5 days before the outbreaks were reported, there is clearly scope to further reduce the mean time taken to report a confirmed out-break. Early detection allows the early implementation of outbreak control measures \u2013 such as health surveys for the detection of other cases, case isolation, disinfection of affected settings, health education, promotion of hand hygiene, and closure of affected classes or schools \u2013 as well as the early treatment of cases and the prevention of the more severe complications of HFM disease.One limitation of our study was that, for calculating the sensitivity, specificity and timeliness of the response system, we used the outbreaks reported to the public health emergency report-ing system as the gold standard. It seems likely that some outbreaks of HFM disease are either never recorded by the public health emergency reporting system or are reported a long time after they have occurred. These issues need investigation. However, at the time of our study, we believed that the public health emergency reporting system was the best-functioning system for the collection of data on HFM disease outbreaks in China.Our findings demonstrate that \u2013 if well designed and operated \u2013 an automated early warning system for outbreaks of infectious disease can help local epidemiologists identify outbreaks rapidly, thereby facilitating the prevention of outbreak spread. The response system\u2019s design framework and methods could provide a useful example for institutes of public health in many countries. \u25a0AcknowledgementsWe thank the staff members of the World Health Organization\u2019s country office in China and the county-level Centres for Disease Control and Prevention, and the trainers of the International Field Epi-demiology Training Programme in the Ministry of Public Health of Thailand. Zhongjie Li and Shengjie Lai contrib-uted equally to this study.Funding: This work was supported by grants from the Ministry of Science and Tech-nology of China (2012ZX10004-201), the Ministry of Health of China (201202006), the National Health and Medical Re-search Council of Australia (1002608), and the China\u2013WHO regular budget cooperation project (WPCHN0801617 and WPCHN1002405).Competing interests: None declared.\u0645\u0644\u062e\u0635\u0645\u0631\u0636 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645 \u064a\u0641 \u0627\u0644\u0635\u0646\u064a: \u062a\u0642\u064a\u064a\u0645 \u0623\u062d\u062f \u0627\u0644\u0646\u0638\u0645 \u0627\u0622\u0644\u0644\u064a\u0629 \u0627\u0644\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0641\u0627\u0634\u064a\u0627\u062a\u0627\u0644\u063a\u0631\u0636 \u062a\u0642\u064a\u064a\u0645 \u0623\u062f\u0627\u0621 \u0646\u0638\u0627\u0645 \u0627\u0625\u0644\u0646\u0630\u0627\u0631 \u0648\u0627\u0627\u0644\u0633\u062a\u062c\u0627\u0628\u0629 \u0627\u0622\u0644\u064a\u0644 \u0644\u0623\u0644\u0645\u0631\u0627\u0636 \u0627\u0645\u0644\u0639\u062f\u064a\u0629 \u064a\u0641 \u0627\u0643\u062a\u0634\u0627\u0641 \u0641\u0627\u0634\u064a\u0627\u062a \u0645\u0631\u0636 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645 \u064a\u0641 \u0627\u0644\u0635\u0646\u064a.\u0627\u0644\u0637\u0631\u064a\u0642\u0629 \u0642\u0645\u0646\u0627 \u0628\u062a\u0642\u062f\u064a\u0631 \u0627\u062d\u0644\u062c\u0645 \u0648\u0627\u0645\u0644\u062f\u0629 \u0648\u0627\u0644\u062a\u0623\u062e\u0631\u064a \u064a\u0641 \u0627\u0625\u0644\u0628\u0627\u0644\u063a \u0639\u0646 \u0641\u0627\u0634\u064a\u0627\u062a  1 \u0645\u0631\u0636 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645 \u0645\u0646 \u0627\u062d\u0644\u0627\u0627\u0644\u062a \u0627\u0644\u062a\u064a \u062a\u0645 \u0627\u0625\u0644\u062e\u0637\u0627\u0631 \u0647\u0628\u0627 \u0628\u0646\u064a \u0623\u064a\u0627\u0631/\u0645\u0627\u064a\u0648   1 \u0648\u0628\u0646\u064a   2010 \u0646\u064a\u0633\u0627\u0646/\u0623\u0628\u0631\u064a\u0644  \u064830   2008 \u0623\u064a\u0627\u0631/\u0645\u0627\u064a\u0648 \u0648\u0627\u0644\u0642\u062f\u0645  \u0627\u0644\u064a\u062f  \u062f\u0627\u0621  \u0625\u062f\u0631\u0627\u062c  \u0642\u0628\u0644   \u060c2012 \u0646\u064a\u0633\u0627\u0646/\u0623\u0628\u0631\u064a\u0644  \u064830   2010Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666 661ResearchDetecting outbreaks of hand, foot and mouth disease in ChinaZhongjie Li et al.\u062d\u0633\u0627\u0633\u064a\u0629  \u062a\u0642\u062f\u064a\u0631  \u0648\u062a\u0645  \u0648\u0628\u0639\u062f\u0647.  \u0627\u0622\u0644\u0644\u064a\u0629  \u0648\u0627\u0627\u0644\u0633\u062a\u062c\u0627\u0628\u0629  \u0627\u0625\u0644\u0646\u0630\u0627\u0631  \u064a\u0641  \u0648\u0627\u0644\u0641\u0645 \u0627\u0625\u0644\u0635\u0627\u0628\u0629  \u0645\u0639\u062f\u0644  \u064a\u0641  \u0648\u062a\u0648\u0642\u064a\u062a\u0647\u0627  \u0648\u0646\u0648\u0639\u064a\u062a\u0647\u0627  \u0627\u0627\u0644\u0646\u062d\u0631\u0627\u0641\u0627\u062a  \u0627\u0643\u062a\u0634\u0627\u0641 \u0628\u0641\u0627\u0634\u064a\u0627\u062a \u0645\u0631\u0636 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645 \u0639\u0646 \u0637\u0631\u064a\u0642 \u0645\u0642\u0627\u0631\u0646\u0629 \u0627\u0627\u0644\u0643\u062a\u0634\u0627\u0641\u0627\u062a \u0648\u0627\u0645\u0644\u0627\u0644\u062d\u0638\u0627\u062a \u0627\u0622\u0644\u0644\u064a\u0629 \u0645\u0646 \u0642\u0628\u0644 \u0645\u0648\u0638\u0641\u064a \u0627\u0644\u0635\u062d\u0629 \u0627\u0644\u0639\u0645\u0648\u0645\u064a\u0629.\u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0633\u062c\u0644 \u0646\u0638\u0627\u0645 \u0627\u0625\u0644\u0646\u0630\u0627\u0631 \u0648\u0627\u0627\u0644\u0633\u062a\u062c\u0627\u0628\u0629 106005 \u0627\u0646\u062d\u0631\u0627\u0641\u064b\u0627 \u064a\u0641 \u0645\u0639\u062f\u0644 2010 \u064830  \u0623\u064a\u0627\u0631/\u0645\u0627\u064a\u0648   1 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645 \u0628\u0646\u064a  \u0627\u0625\u0644\u0635\u0627\u0628\u0629 \u0628\u0645\u0631\u0636 \u064a\u0641  \u064a\u0648\u0645   100 \u0644\u0643\u0644  \u0627\u0646\u062d\u0631\u0627\u0641\u064b\u0627   5.6 \u0627\u0645\u0644\u062a\u0648\u0633\u0637   - \u0646\u064a\u0633\u0627\u0646/\u0623\u0628\u0631\u064a\u06442012 \u0643\u0644 \u0645\u0642\u0627\u0637\u0639\u0629 \u0623\u0628\u0644\u063a\u062a \u0639\u0646 \u0645\u0631\u0636 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645. \u0648\u0643\u0627\u0646\u062a \u062d\u0633\u0627\u0633\u064a\u0629 \u0646\u0638\u0627\u0645 \u0627\u0627\u0644\u0633\u062a\u062c\u0627\u0628\u0629 92.7 % \u0648\u0646\u0648\u0639\u064a\u062a\u0647 95.0 %. \u0648\u0643\u0627\u0646 \u0645\u062a\u0648\u0633\u0637 \u0627\u0644\u062a\u0623\u062e\u0631\u064a \u062a\u0644\u0643  \u0648\u0627\u0643\u062a\u0634\u0627\u0641  \u0627\u0644\u0641\u0627\u0634\u064a\u0627\u062a  \u0625\u0644\u062d\u062f\u0649  \u0627\u0623\u0644\u0648\u0649\u0644  \u0627\u062d\u0644\u0627\u0644\u0629  \u0639\u0646  \u0627\u0625\u0644\u0628\u0627\u0644\u063a  \u0628\u0646\u064a \u0645\u062a\u0648\u0633\u0637  \u0648\u0627\u0646\u062e\u0641\u0636  \u064a\u0648\u0645.   2.1 \u0627\u0627\u0644\u0633\u062a\u062c\u0627\u0628\u0629  \u0646\u0638\u0627\u0645  \u0637\u0631\u064a\u0642  \u0639\u0646  \u0627\u0644\u0641\u0627\u0634\u064a\u0629 \u0627\u0644\u062f\u0631\u0627\u0633\u064a\u062a\u0646\u064a  \u0627\u0644\u0641\u0631\u062a\u062a\u0646\u064a  \u0628\u0646\u064a  \u0648\u0627\u0644\u0641\u0645  \u0648\u0627\u0644\u0642\u062f\u0645  \u0627\u0644\u064a\u062f  \u0645\u0631\u0636  \u0641\u0627\u0634\u064a\u0629  \u062d\u062c\u0645 15.8 \u062d\u0627\u0644\u0629 \u0648\u0627\u0646\u062e\u0641\u0636 \u0645\u062a\u0648\u0633\u0637  \u0627\u0623\u0644\u0648\u0649\u0644 \u0648\u0627\u0644\u062b\u0627\u0646\u064a\u0629 \u0645\u0646 19.4 \u062d\u0627\u0644\u0629 \u0625\u0649\u0644 \u0627\u0644\u0641\u0627\u0635\u0644 \u0628\u0646\u064a \u0628\u062f\u0627\u064a\u0629 \u0647\u0630\u0647 \u0627\u0644\u0641\u0627\u0634\u064a\u0629 \u0648\u0627\u0625\u0644\u0628\u0627\u0644\u063a \u0627\u0623\u0644\u0648\u064a\u0644 \u0639\u0646\u0647\u0627 \u0625\u0649\u0644 \u0646\u0638\u0627\u0645 \u0627\u0625\u0644\u0628\u0627\u0644\u063a \u0639\u0646 \u062d\u0627\u0627\u0644\u062a \u0627\u0644\u0637\u0648\u0627\u0631\u0626 \u064a\u0641 \u0627\u0644\u0635\u062d\u0629 \u0627\u0644\u0639\u0645\u0648\u0645\u064a\u0629 \u0645\u0646 10.0 \u0625\u0649\u0644 9.1 \u064a\u0648\u0645\u064b\u0627.\u0627\u0627\u0644\u0633\u062a\u0646\u062a\u0627\u062c \u064a\u0634\u0631\u064a \u0646\u0638\u0627\u0645 \u0627\u0625\u0644\u0646\u0630\u0627\u0631 \u0648\u0627\u0627\u0644\u0633\u062a\u062c\u0627\u0628\u0629 \u0627\u0622\u0644\u064a\u0644 \u0625\u0649\u0644 \u062d\u0633\u0627\u0633\u064a\u0629 \u062c\u064a\u062f\u0629 \u064a\u0641 \u0627\u0643\u062a\u0634\u0627\u0641 \u0641\u0627\u0634\u064a\u0627\u062a \u0645\u0631\u0636 \u0627\u0644\u064a\u062f \u0648\u0627\u0644\u0642\u062f\u0645 \u0648\u0627\u0644\u0641\u0645 \u0648\u064a\u0628\u062f\u0648 \u0623\u0646\u0647 \u0631\u0633\u064a\u0639 \u0646\u0633\u0628\u064a\u064b\u0627. \u0641\u0639\u0627\u0644\u064a\u0629  \u0628\u0632\u064a\u0627\u062f\u0629  \u0627\u0644\u0646\u0638\u0627\u0645  \u0647\u0644\u0630\u0627  \u0627\u0645\u0644\u062a\u0648\u0627\u0635\u0644  \u0627\u0627\u0644\u0633\u062a\u062e\u062f\u0627\u0645  \u064a\u0633\u0645\u062d  \u0623\u0646  \u0648\u064a\u0646\u0628\u063a\u064a \u0627\u0644\u0648\u0642\u0627\u064a\u0629 \u0648\u062a\u0642\u064a\u064a\u062f \u0647\u0630\u0647 \u0627\u0644\u0641\u0627\u0634\u064a\u0627\u062a \u064a\u0641 \u0627\u0644\u0635\u0646\u064a.\u6458\u8981\u4e2d\u56fd\u624b\u8db3\u53e3\u75c5\u7206\u53d1\u81ea\u52a8\u63a2\u6d4b\u9884\u8b66\u7cfb\u7edf\u8bc4\u4ef7\u7814\u7a76\u76ee\u7684 \u8bc4\u4ef7\u4e2d\u56fd\u4f20\u67d3\u75c5\u81ea\u52a8\u9884\u8b66\u4e0e\u54cd\u5e94\u7cfb\u7edf\u5728\u63a2\u6d4b\u624b\u8db3\u53e3\u75be\u75c5\uff08HFM\uff09\u7206\u53d1\u65b9\u9762\u7684\u8868\u73b0\u3002\u65b9\u6cd5 \u6211\u4eec\u5229\u7528 2008 \u5e74 5 \u6708 1 \u65e5\u548c 2010 \u5e74 4 \u6708 30 \u65e5\u4e4b\u95f4\u4ee5\u53ca 2010 \u5e74 5 \u6708 1 \u65e5\u548c 2012 \u5e74 4 \u6708 30 \u65e5\u4e4b\u95f4\uff08\u5373\u81ea\u52a8\u9884\u8b66\u4e0e\u54cd\u5e94\u7cfb\u7edf\u5c06\u624b\u8db3\u53e3\u75c5\u7eb3\u5165\u4e4b\u524d\u548c\u4e4b\u540e\uff09\u62a5\u544a\u7684\u75c5\u4f8b\u4f30\u7b97\u4e86\u884c\u6bd4\u8f83\uff0c\u8bc4\u4f30\u8be5\u7cfb\u7edf\u7528\u4e8e\u63a2\u6d4b\u624b\u53e3\u8db3\u75c5\u7206\u53d1\u7684\u7075\u654f\u5ea6\u3001\u7279\u5f02\u5ea6\u548c\u53ca\u65f6\u6027\u3002\u7ed3\u679c \u5728 2010 \u5e74 5 \u6708 1 \u65e5\u81f3 2012 \u5e74 4 \u6708 30 \u65e5\u671f\u95f4\uff0c\u9884\u8b66\u548c\u54cd\u5e94\u7cfb\u7edf\u53d1\u51fa\u4e86 106005 \u6761\u9884\u8b66\u4fe1\u53f7\uff0c\u2014\u2014\u5728\u6bcf\u4e2a\u6709\u624b\u8db3\u53e3\u75c5\u75c5\u4f8b\u62a5\u544a\u7684\u53bf\uff0c\u5e73\u5747\u6bcf 100 \u5929\u4ea7\u751f 5.6 \u6761\u624b\u8db3\u53e3\u75c5\u9884\u8b66\u4fe1\u53f7\u3002\u54cd\u5e94\u7cfb\u7edf\u654f\u611f\u5ea6\u4e3a 92.7%\uff0c\u7279\u5f02\u5ea6\u4e3a 95.0%\u3002\u4ece\u7206\u53d1\u7684\u7b2c\u4e00\u4f8b\u75c5\u4f8b\u62a5\u544a\u81f3\u81ea\u52a8\u9884\u8b66\u4e0e\u54cd\u5e94\u4f8b\u53d1\u75c5\u81f3\u5411\u7a81\u53d1\u516c\u5171\u536b\u751f\u4e8b\u4ef6\u62a5\u544a\u7cfb\u7edf\u8fdb\u884c\u62a5\u544a\u4e4b\u95f4\u7684\u5e73\u5747\u65f6\u95f4\u95f4\u9694\u4ece 10.0 \u5929\u4e0b\u964d\u5230 9.1 \u5929\u3002\u7ed3\u8bba \u81ea\u52a8\u9884\u8b66\u4e0e\u54cd\u5e94\u7cfb\u7edf\u5728\u63a2\u6d4b\u624b\u8db3\u53e3\u75c5\u7206\u53d1\u65b9\u9762\u5177\u6709\u826f\u597d\u7684\u7075\u654f\u5ea6\u548c\u53ca\u65f6\u6027\u3002\u6301\u7eed\u4f7f\u7528\u8be5\u7cfb\u7edf\u5e94\u8be5\u80fd\u591f\u66f4\u6709\u6548\u5730\u9884\u9632\u548c\u63a7\u5236\u4e2d\u56fd\u624b\u8db3\u53e3\u75c5\u7684\u7206\u53d1\u3002R\u00e9sum\u00e9Maladie des mains, pieds et bouche en Chine: \u00e9valuation d\u2019un syst\u00e8me automatis\u00e9 pour ur les maladies infectieuses de la Chine en mati\u00e8re de d\u00e9tection des \u00e9pid\u00e9mies de maladie des mains, pieds et bouche (MMPB).M\u00e9thodes Nous avons estim\u00e9 la taille, la dur\u00e9e et le retard du signalement des \u00e9pid\u00e9mies de MMPB \u00e0 partir des cas notifi\u00e9s entre le 1er mai 2008 et le 30 avril 2010 et entre le 1er mai 2010 et le 30 avril 2012, c\u2019est-\u00e0-dire avant et apr\u00e8s l\u2019int\u00e9gration de la MMPB dans le syst\u00e8me automatis\u00e9 d\u2019alerte et d\u2019action. La sensibilit\u00e9, la sp\u00e9cificit\u00e9 et la rapidit\u00e9 de la d\u00e9tection des aberrations dans l\u2019incidence des \u00e9pid\u00e9mies de MMPB ont \u00e9t\u00e9 estim\u00e9es en comparant les d\u00e9tections automatis\u00e9es aux observations du personnel des services de sant\u00e9 publique.R\u00e9sultats Le syst\u00e8me d\u2019alerte et d\u2019action a enregistr\u00e9 106 005 aberrations dans l\u2019incidence de la MMPB entre le 1er mai 2010 et le 30 avril 2012 \u2013 une moyenne de 5,6 erreurs pour 100 jours dans chaque comt\u00e9 qui avait signal\u00e9 la MMPB. Le syst\u00e8me d\u2019action avait une sensibilit\u00e9 de 92,7% et une sp\u00e9cificit\u00e9 de 95,0%. Le retard moyen entre le signalement du premier cas d\u2019une \u00e9pid\u00e9mie et la d\u00e9tection de cette \u00e9pid\u00e9mie par le syst\u00e8me d\u2019action \u00e9tait de 2,1 jours. Entre les p\u00e9riodes de la premi\u00e8re et de la seconde \u00e9tude, la taille moyenne d\u2019une \u00e9pid\u00e9mie de MMPB a diminu\u00e9 de 19,4 \u00e0 15,8 cas, et l\u2019intervalle moyen entre le d\u00e9but et le signalement initial d\u2019une telle \u00e9pid\u00e9mie au syst\u00e8me de notification d\u2019urgence des services de sant\u00e9 publique a diminu\u00e9, passant de 10,0 \u00e0 9,1 jours.Conclusion Le syst\u00e8me automatis\u00e9 d\u2019alerte et d\u2019action pr\u00e9sente une bonne sensibilit\u00e9 en mati\u00e8re de d\u00e9tection des \u00e9pid\u00e9mies de MMPB et semble \u00eatre relativement rapide. L\u2019utilisation continue de ce syst\u00e8me devrait permettre de pr\u00e9venir et de limiter plus efficacement ces \u00e9pid\u00e9mies en Chine.\u0420\u0435\u0437\u044e\u043c\u0435\u0412\u0438\u0440\u0443\u0441\u043d\u0430\u044f \u043f\u0443\u0437\u044b\u0440\u0447\u0430\u0442\u043a\u0430 \u043f\u043e\u043b\u043e\u0441\u0442\u0438 \u0440\u0442\u0430 \u0438 \u043a\u043e\u043d\u0435\u0447\u043d\u043e\u0441\u0442\u0435\u0439 \u0432 \u041a\u0438\u0442\u0430\u0435: \u043e\u0446\u0435\u043d\u043a\u0430 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0432\u0441\u043f\u044b\u0448\u0435\u043a \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u044f\u0426\u0435\u043b\u044c \u041e\u0446\u0435\u043d\u0438\u0442\u044c \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u044c \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u043e\u043f\u043e\u0432\u0435\u0449\u0435\u043d\u0438\u044f \u0438 \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0432 \u041a\u0438\u0442\u0430\u0435, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u043e\u0439 \u0434\u043b\u044f \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0432\u0441\u043f\u044b\u0448\u0435\u043a \u0432\u0438\u0440\u0443\u0441\u043d\u043e\u0439 \u043f\u0443\u0437\u044b\u0440\u0447\u0430\u0442\u043a\u0438 \u043f\u043e\u043b\u043e\u0441\u0442\u0438 \u0440\u0442\u0430 \u0438 \u043a\u043e\u043d\u0435\u0447\u043d\u043e\u0441\u0442\u0435\u0439 (HFM \u2014 \u043e\u0442 \u0430\u043d\u0433\u043b. hand, foot and mouth disease).\u041c\u0435\u0442\u043e\u0434\u044b \u0420\u0430\u0437\u043c\u0435\u0440, \u043f\u0440\u043e\u0434\u043e\u043b\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0432\u0441\u043f\u044b\u0448\u0435\u043a \u0438 \u0437\u0430\u0434\u0435\u0440\u0436\u043a\u0430 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439 \u043e \u0432\u0441\u043f\u044b\u0448\u043a\u0430\u0445 HFM \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u043b\u0438\u0441\u044c \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0441\u043b\u0443\u0447\u0430\u0435\u0432, \u0437\u0430\u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0432 \u043f\u0435\u0440\u0438\u043e\u0434 \u0441 1 \u043c\u0430\u044f 2008 \u0433\u043e\u0434\u0430 \u043f\u043e 30 \u0430\u043f\u0440\u0435\u043b\u044f 2010 \u0433\u043e\u0434\u0430 \u0438 \u0432 \u043f\u0435\u0440\u0438\u043e\u0434 \u0441 1 \u043c\u0430\u044f 2010 \u0433\u043e\u0434\u0430 \u043f\u043e 30 \u0430\u043f\u0440\u0435\u043b\u044f 2012 \u0433\u043e\u0434\u0430, \u043a\u0430\u043a \u0434\u043e, \u0442\u0430\u043a \u0438 \u043f\u043e\u0441\u043b\u0435 \u043d\u0430\u0447\u0430\u043b\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043e\u043f\u043e\u0432\u0435\u0449\u0435\u043d\u0438\u044f \u0438 \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043e \u0434\u0430\u043d\u043d\u043e\u043c \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u0438. \u0427\u0443\u0432\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c, \u0441\u043f\u0435\u0446\u0438\u0444\u0438\u0447\u043d\u043e\u0441\u0442\u044c \u0438 \u0441\u0432\u043e\u0435\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0439 \u0432 \u0443\u0440\u043e\u0432\u043d\u0435 \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438 HFM \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u043b\u0438\u0441\u044c \u043f\u0443\u0442\u0435\u043c \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0441 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u044f \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u0438\u0441\u0442\u043e\u0432 \u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0437\u0434\u0440\u0430\u0432\u043e\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0421\u0438\u0441\u0442\u0435\u043c\u043e\u0439 \u043e\u043f\u043e\u0432\u0435\u0449\u0435\u043d\u0438\u044f \u0438 \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0431\u044b\u043b\u043e Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666662ResearchDetecting outbreaks of hand, foot and mouth disease in China Zhongjie Li et al.\u0437\u0430\u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043e 106 005 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0439 \u0432 \u0443\u0440\u043e\u0432\u043d\u0435 \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438 HFM \u0432 \u043f\u0435\u0440\u0438\u043e\u0434 \u0441 1 \u043c\u0430\u044f 2010 \u0433\u043e\u0434\u0430 \u043f\u043e 30 \u0430\u043f\u0440\u0435\u043b\u044f 2012 \u0433\u043e\u0434\u0430, \u0447\u0442\u043e \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u043e \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c 5,6 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0439 \u043d\u0430 100 \u0434\u043d\u0435\u0439 \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u043e\u043a\u0440\u0443\u0433\u0435, \u0441\u043e\u043e\u0431\u0449\u0438\u0432\u0448\u0435\u043c \u043e \u0441\u043b\u0443\u0447\u0430\u044f\u0445 \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u044f HFM. \u0427\u0443\u0432\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0438 \u0441\u043f\u0435\u0446\u0438\u0444\u0438\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u043b\u0438 92,7% \u0438 95,0% \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0435\u043d\u043d\u043e. \u0421\u0440\u0435\u0434\u043d\u044f\u044f \u0437\u0430\u0434\u0435\u0440\u0436\u043a\u0430 \u043c\u0435\u0436\u0434\u0443 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435\u043c \u043e \u043f\u0435\u0440\u0432\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0432\u0441\u043f\u044b\u0448\u043a\u0438 \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u044f \u0438 \u0432\u044b\u044f\u0432\u043b\u0435\u043d\u0438\u0435\u043c \u0434\u0430\u043d\u043d\u043e\u0439 \u0432\u0441\u043f\u044b\u0448\u043a\u0438 \u0441\u0438\u0441\u0442\u0435\u043c\u043e\u0439 \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 2,1 \u0434\u043d\u044f. \u041c\u0435\u0436\u0434\u0443 \u043f\u0435\u0440\u0432\u044b\u043c \u0438 \u0432\u0442\u043e\u0440\u044b\u043c \u043f\u0435\u0440\u0438\u043e\u0434\u0430\u043c\u0438 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u0441\u043f\u044b\u0448\u043a\u0438 HFM \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043b\u0441\u044f \u0441 19,4 \u0434\u043e 15,8 \u0441\u043b\u0443\u0447\u0430\u0435\u0432, \u0430 \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0438\u043d\u0442\u0435\u0440\u0432\u0430\u043b \u043c\u0435\u0436\u0434\u0443 \u043d\u0430\u0447\u0430\u043b\u043e\u043c \u0432\u0441\u043f\u044b\u0448\u043a\u0438 \u0438 \u043f\u0435\u0440\u0432\u043e\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u043c \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435\u043c \u043e \u0434\u0430\u043d\u043d\u043e\u0439 \u0432\u0441\u043f\u044b\u0448\u043a\u0435 \u0432 \u0441\u0438\u0441\u0442\u0435\u043c\u0443 \u0430\u0432\u0430\u0440\u0438\u0439\u043d\u043e\u0439 \u043e\u0442\u0447\u0435\u0442\u043d\u043e\u0441\u0442\u0438 \u0437\u0434\u0440\u0430\u0432\u043e\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043b\u0441\u044f \u0441 10,0 \u0434\u043e 9,1 \u0434\u043d\u0435\u0439.\u0412\u044b\u0432\u043e\u0434 \u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043e\u0432\u0435\u0449\u0435\u043d\u0438\u044f \u0438 \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0435\u043c\u043e\u043d\u0441\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u043b\u0430 \u0445\u043e\u0440\u043e\u0448\u0443\u044e \u0447\u0443\u0432\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438 \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u0438 \u0432\u0441\u043f\u044b\u0448\u0435\u043a \u0432\u0438\u0440\u0443\u0441\u043d\u043e\u0439 \u043f\u0443\u0437\u044b\u0440\u0447\u0430\u0442\u043a\u0438 \u043f\u043e\u043b\u043e\u0441\u0442\u0438 \u0440\u0442\u0430 \u0438 \u043a\u043e\u043d\u0435\u0447\u043d\u043e\u0441\u0442\u0435\u0439 \u0438 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0432\u044b\u0441\u043e\u043a\u0443\u044e \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0440\u0435\u0430\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f. \u0414\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u044d\u0442\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u0434\u043e\u043b\u0436\u043d\u043e \u043e\u0431\u0435\u0441\u043f\u0435\u0447\u0438\u0442\u044c \u0431\u043e\u043b\u0435\u0435 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0435 \u043f\u0440\u0435\u0434\u043e\u0442\u0432\u0440\u0430\u0449\u0435\u043d\u0438\u0435 \u0438 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0435 \u0432\u0441\u043f\u044b\u0448\u0435\u043a \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u044f \u0432 \u041a\u0438\u0442\u0430\u0435.ResumenLa enfermedad boca-mano-pie en China: evaluaci\u00f3n de un sistema automatizado para la detecci\u00f3n de brotesObjetivo Evaluar el rendimiento del sistema de alerta y respuesta autom\u00e1tica a enfermedades infecciosas de China en la detecci\u00f3n de brotes de la enfermedad boca-mano-pie (EBMP).M\u00e9todos Calculamos la magnitud, la duraci\u00f3n y la demora en la notificaci\u00f3n de brotes de la enfermedad BMP a partir de casos notificados entre el 1 de mayo de 2008 y el 30 de abril de 2010, y entre el 1 de mayo de 2010 y el 30 de abril 2012, antes y despu\u00e9s de que el sistema de alerta y respuesta autom\u00e1ticas incluyera la enfermedad BMP. Se estim\u00f3 la sensibilidad, especificidad y oportunidad de la detecci\u00f3n de aberraciones en la incidencia de los brotes de enfermedad BMP mediante la comparaci\u00f3n de las detecciones autom\u00e1ticas con las observaciones del personal de salud p\u00fablica.Resultados El sistema de alerta y respuesta registr\u00f3 106 005 aberraciones en la incidencia de la EBMP entre el 1 de mayo de 2010 y el 30 de abril de 2012 - una media de 5,6 aberraciones por cada 100 d\u00edas en cada condado que notific\u00f3 dicha enfermedad. El sistema de respuesta tuvo una sensibilidad del 92,7 % y una especificidad del 95,0 %. La demora media entre la notificaci\u00f3n del primer caso de un brote y la detecci\u00f3n de ese brote por el sistema de respuesta fue de 2,1 d\u00edas. Entre el primer y el segundo per\u00edodo de estudio, las dimensiones medias de un brote de EBMP disminuyeron de 19,4 a 15,8 casos, y el intervalo medio entre el comienzo de un brote y el primer informe en el sistema de notificaci\u00f3n de emergencia de salud p\u00fablica se redujo de 10,0 a 9,1 d\u00edas.Conclusi\u00f3n El sistema de alerta y respuesta autom\u00e1tica muestra una buena sensibilidad en la detecci\u00f3n de los brotes de EBMP y parece ser relativamente r\u00e1pido. El uso continuado de este sistema deber\u00eda permitir una prevenci\u00f3n y limitaci\u00f3n m\u00e1s eficaces de dichos brotes en China.References1. Buckeridge DL, Okhmatovskaia A, Tu S, O\u2019Connor M, Nyulas C, Musen MA. Understanding detection performance in public health surveillance: modeling aberrancy-detection algorithms. J Am Med Inform Assoc. 2008;15(6):760\u20139. doi: http://dx.doi.org/10.1197/jamia.M2799 PMID: 187559922. Hutwagner L, Thompson W, Seeman GM, Treadwell T. The bioterrorism preparedness and response Early Aberration Reporting System (EARS). J Urban Health. 2003;80(2) Suppl 1:i89\u201396. PMID: 127917833. Reis BY, Kohane IS, Mandl KD. An epidemiological network model for disease outbreak detection. PLoS Med. 2007;4(6):e210. doi: http://dx.doi.org/10.1371/journal.pmed.0040210 PMID: 175938954. Lombardo J, Burkom H, Elbert E, Magruder S, Lewis SH, Loschen W, et al. A systems overview of the Electronic Surveillance System for the Early Notification of Community-Based Epidemics (ESSENCE II). J Urban Health. 2003;80(2) Suppl 1:i32\u201342. PMID: 127917775. Loonsk JW. BioSense\u2013a national initiative for early detection and quantification of public health emergencies. MMWR Morb Mortal Wkly Rep. 2004 ;53 Suppl:53\u20135. PMID: 157146296. Krause G, Altmann D, Faensen D, Porten K, Benzler J, Pfoch T, et al. SurvNet electronic surveillance system for infectious disease outbreaks, Germany. Emerg Infect Dis. 2007;13(10):1548\u201355. doi: http://dx.doi.org/10.3201/eid1310.070253 PMID: 182580057. Hulth A, Andrews N, Ethelberg S, Dreesman J, Faensen D, van Pelt W, et al. Practical usage of computer-supported outbreak detection in five European countries. Euro Surveill. 2010;15(36):15. PMID: 208434708. Cakici B, Hebing K, Gr\u00fcnewald M, Saretok P, Hulth A. CASE: a framework for computer supported outbreak detection. BMC Med Inform Decis Mak. 2010;10(1):14. doi: http://dx.doi.org/10.1186/1472-6947-10-14 PMID: 202260359. Hutwagner L, Browne T, Seeman GM, Fleischauer AT. Comparing aberration detection methods with simulated data. Emerg Infect Dis. 2005;11(2):314\u20136. doi: http://dx.doi.org/10.3201/eid1102.040587 PMID: 1575245410. Kuang J, Yang WZ, Zhou DL, Li ZJ, Lan YJ. Epidemic features affecting the performance of outbreak detection algorithms. BMC Public Health. 2012;12(1):418. doi: http://dx.doi.org/10.1186/1471-2458-12-418 PMID: 2268211011. Morse SS. Public health surveillance and infectious disease detection. Biosecur Bioterror. 2012;10(1):6\u201316. doi: http://dx.doi.org/10.1089/bsp.2011.0088 PMID: 2245567512. Brownstein JS, Freifeld CC, Madoff LC. Digital disease detection \u2013 harnessing the Web for public health surveillance. N Engl J Med. 2009;360(21):2153\u20135, 2157. doi: http://dx.doi.org/10.1056/NEJMp0900702 PMID: 1942386713. Yang WZ, Li ZJ, Lan YJ, Wang JF, Ma JQ, Jin LM, et al. A nationwide web-based automated system for early outbreak detection and rapid response in China. Western Pac Surveill Response J. 2011;2(1):10\u20135. doi: http://dx.doi.org/10.5365/wpsar.2010.1.1.009 PMID: 2390887814. Chan KP, Goh KT, Chong CY, Teo ES, Lau G, Ling AE. Epidemic hand, foot and mouth disease caused by human enterovirus 71, Singapore. Emerg Infect Dis. 2003;9(1):78\u201385. doi: http://dx.doi.org/10.3201/eid1301.020112 PMID: 1253328515. Zhang Y, Zhu Z, Yang W, Ren J, Tan X, Wang Y, et al. An emerging recombinant human enterovirus 71 responsible for the 2008 outbreak of hand foot and mouth disease in Fuyang city of China. Virol J. 2010;7(1):94. doi: http://dx.doi.org/10.1186/1743-422X-7-94 PMID: 2045985116. Zhang Y, Tan XJ, Wang HY, Yan DM, Zhu SL, Wang DY, et al. An outbreak of hand, foot, and mouth disease associated with subgenotype C4 of human enterovirus 71 in Shandong, China. J Clin Virol. 2009;44(4):262\u20137. doi: http://dx.doi.org/10.1016/j.jcv.2009.02.002 PMID: 1926988817. Heymann DL. Control of communicable diseases manual. 19th ed. Washington: American Public Health Association; 2008. pp. 151\u20134.18. Chang ZR, Zhang J, Sun JL, Zhang WD, Wang ZJ. Epidemiological features of hand, foot and mouth disease in China, 2008 - 2009. Zhonghua Liu Xing Bing Xue Za Zhi. 2011;32(7):676\u201380. Chinese. PMID: 2193353819. A guide to clinical management and public health response for hand, foot and mouth disease [Internet]. Manila: World Health Organization; 2011. Available from: http://www.wpro.who.int/publications/PUB_9789290615255/en/ [cited 2013 Jan 15].20. The declaration of hand, foot and mouth disease as a notifiable disease in China [Internet]. Beijing: Chinese Ministry of Health; 2008. Chinese. Available from: http://www.chinacdc.cn/jkzt/crb/szkb/jszl_2275/200805/t20080506_24699.htm [cited 2013 Feb 1]. Bull World Health Organ 2014;92:656\u2013663| doi: http://dx.doi.org/10.2471/BLT.13.130666 663ResearchDetecting outbreaks of hand, foot and mouth disease in ChinaZhongjie Li et al.21. Hutwagner L, Barson JV. Use of the early aberration reporting system (EARS) for detection of bioterrorism agent attacks. Aviat Space Environ Med. 2005;76(10):1001\u20132. PMID: 1623588822. Yang P, Duan W, Lv M, Shi W, Peng X, Wang X, et al. Review of an influenza surveillance system, Beijing, People\u2019s Republic of China. Emerg Infect Dis. 2009;15(10):1603\u20138. doi: http://dx.doi.org/10.3201/eid1510.081040 PMID: 1986105323. Wang X, Zeng D, Seale H, Li S, Cheng H, Luan R, et al. Comparing early outbreak detection algorithms based on their optimized parameter values. J Biomed Inform. 2010;43(1):97\u2013103. doi: http://dx.doi.org/10.1016/j.jbi.2009.08.003 PMID: 1968306924. Fricker RD Jr, Hegler BL, Dunfee DA. Comparing syndromic surveillance detection methods: EARS\u2019 versus a CUSUM-based methodology. Stat Med. 2008;27(17):3407\u201329. doi: http://dx.doi.org/10.1002/sim.3197 PMID: 1824012825. Yang WZ, Lan YJ, Li ZJ, Ma JQ, Jin LM, Sun Q, et al. The application of national outbreak automatic detection and response system, China. Zhonghua Liu Xing Bing Xue Za Zhi. 2010;31(11):1240\u20134. Chinese. PMID:21176684 PMID: 2117668426. Guideline for hand, foot and mouth disease control and prevention (2009 edition) [Internet]. Beijing: Chinese Ministry of Health; 2009. Chinese. Available from: http://www.chinacdc.cn/jkzt/crb/szkb/jszl_2275/200906/t20090612_24707.htm [cited 2013 Feb 1].27. Li Z, Lai S, Buckeridge DL, Zhang H, Lan Y, Yang W. Adjusting outbreak detection algorithms for surveillance during epidemic and non-epidemic periods. J Am Med Inform Assoc. 2012;19 e1:e51\u20133. doi: http://dx.doi.org/10.1136/amiajnl-2011-000126 PMID: 2183615728. Li XZ, Wang JF, Yang WZ, Li ZJ, Lai SJ. A spatial scan statistic for multiple clusters. Math Biosci. 2011;233(2):135\u201342. doi: http://dx.doi.org/10.1016/j.mbs.2011.07.004 PMID: 2182777129. Mammen MP, Pimgate C, Koenraadt CJ, Rothman AL, Aldstadt J, Nisalak A, et al. Spatial and temporal clustering of dengue virus transmission in Thai villages. PLoS Med. 2008;5(11):e205. doi: http://dx.doi.org/10.1371/journal.pmed.0050205 PMID: 1898620930. Huang SS, Yokoe DS, Stelling J, Placzek H, Kulldorff M, Kleinman K, et al. Automated detection of infectious disease outbreaks in hospitals: a retrospective cohort study. PLoS Med. 2010;7(2):e1000238. doi: http://dx.doi.org/10.1371/journal.pmed.1000238 PMID: 2018627431. Zhang H, Lai S, Wang L, Zhao D, Zhou D, Lan Y, et al. Improving the performance of outbreak detection algorithms by classifying the levels of disease incidence. PLoS ONE. 2013;8(8):e71803. doi: http://dx.doi.org/10.1371/journal.pone.0071803 PMID: 23977146",
      "id": 136306823,
      "identifiers": [
        {
          "identifier": "156678541",
          "type": "CORE_ID"
        },
        {
          "identifier": "10.2471/blt.13.130666",
          "type": "DOI"
        },
        {
          "identifier": "oai:openresearch-repository.anu.edu.au:1885/75192",
          "type": "OAI_ID"
        }
      ],
      "title": "Hand, foot and mouth disease in China: Evaluating an automated system for the detection of outbreaks",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:openresearch-repository.anu.edu.au:1885/75192"
      ],
      "publishedDate": "2015-12-11T08:59:45",
      "publisher": "'WHO Press'",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://openresearch-repository.anu.edu.au/bitstream/1885/75192/2/01_Li_Hand,_foot_and_mouth_disease_2014.pdf"
      ],
      "updatedDate": "2022-12-15T08:22:45",
      "yearPublished": 2015,
      "journals": [
        {
          "title": "Bulletin of the World Health Organization",
          "identifiers": [
            "0042-9686",
            "issn:0042-9686"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/156678541.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/156678541"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/156678541/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/156678541/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/136306823"
        }
      ]
    }
  ]
}
